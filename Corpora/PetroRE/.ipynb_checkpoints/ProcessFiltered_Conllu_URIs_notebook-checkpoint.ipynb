{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import operator as op\n",
    "import warnings \n",
    "from owlready2 import * #\n",
    "import random\n",
    "import unicodedata\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar ontologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto_name = \"OntoGeoLogicaInstanciasRelacoes\"\n",
    "onto = get_ontology(\"../../KnowledgeGraph/OntoGeoLogicaInstanciasRelacoes.owl\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para procurar na ontologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_between_uris(uri_1, uri_2): \n",
    "    #funcao que acessa a ontologia e procura relacao entre URIs\n",
    "    dict_relation_uris = {}\n",
    "    #Pega as relacoes que a URI1 tem\n",
    "    relation_query_results = list(default_world.sparql(\"\"\"\n",
    "            SELECT DISTINCT ?rel\n",
    "            WHERE{?uri ?rel ?obj\n",
    "                 FILTER(contains(str(?rel), \"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\"))\n",
    "                 FILTER (contains(str(?uri), \"\"\" + '\"' + uri_1 + '\"' + \"\"\"))\n",
    "                 }\n",
    "            \"\"\"))\n",
    "    \n",
    "    relations_str = []\n",
    "    for relation_uris in relation_query_results:\n",
    "        relations_str.append(str(relation_uris[0]).rsplit(\".\",1)[-1])\n",
    "        \n",
    "    # Para cada tipo de relação procura se existe match entre URI1 e URI2\n",
    "    for relation in relations_str:\n",
    "        relation_between_words = list(default_world.sparql(\"\"\"\n",
    "                PREFIX prefix: <http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#>\n",
    "                SELECT distinct ?y ?x2\n",
    "                WHERE{?y prefix:\"\"\" +  relation  +  \"\"\" ?x1\n",
    "\n",
    "                      FILTER (contains(str(?y), \"\"\" + '\"' + uri_1  + '\"' + \"\"\"))        \n",
    "\n",
    "                      ?x2 rdf:type ?j                                   \n",
    "                      FILTER (contains(str(?x2), \"\"\" + '\"' + uri_2  + '\"' + \"\"\"))\n",
    "\n",
    "                      FILTER ( ?x2 = ?x1 )\n",
    "                    }\n",
    "                \"\"\"))\n",
    "        dict_relation_uris[relation] = relation_between_words\n",
    "    return dict_relation_uris\n",
    "\n",
    "def go_through_relations(uri1,uri2):\n",
    "    relation_uris = get_relations_between_uris(uri1, uri2)            \n",
    "    if relation_uris != {}: #talvez exista relacao entre URIs, dicionario pode vir vazio -> []\n",
    "        for x, y in relation_uris.items():#procurar por relacao\n",
    "            if y != []: #existe alguma relacao\n",
    "#                 print(x)\n",
    "                return x\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para printar informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence_text(sentence):\n",
    "    #printa e retorna o texto original da sentenca\n",
    "    size_sentence = int(sentence.iloc[-1][\"end\"])\n",
    "    text = \" \"*size_sentence\n",
    "    for index, row in sentence.iterrows():\n",
    "        text = text[:int(row[\"start\"])] + row[\"form\"] +text[int(row[\"end\"]):]\n",
    "    print(text)\n",
    "    print(\"-------------\")\n",
    "    return text\n",
    "\n",
    "def print_relation_entities(word1,word2,ent1,ent2,URI_1,URI_2,relation_type,text):\n",
    "    #printa as entidades e relacao entre elas\n",
    "    print('Token 1 = ', word1, '--- Class 1 = ', ent1, '--- URI 1 = ', URI_1)\n",
    "    print('Token 2 = ', word2, '--- Class 2 = ', ent2,'--- URI 2 = ',URI_2)\n",
    "    print('Relation Type = ', relation_type)\n",
    "    print(text)\n",
    "    print(\"-------------\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para gerar Jsons a serem lidos no labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultRelationJson(object):\n",
    "    def __init__(self, from_id, to_id, relations, direction = \"right\"):\n",
    "        self.dict = {\n",
    "            \"from_id\": str(from_id),\n",
    "            \"to_id\": str(to_id),\n",
    "            \"type\": \"relation\",\n",
    "            \"direction\": direction,\n",
    "            \"labels\": relations\n",
    "        }\n",
    "    def get_dict(self):\n",
    "        return self.dict\n",
    "class ResultNERJson(object):\n",
    "    def __init__(self, row):     \n",
    "        self.result_dict = {\n",
    "            \"value\": {\n",
    "            \"start\": row[\"start_word\"],\n",
    "            \"end\": row[\"end_word\"],\n",
    "            \"text\": row[\"word_join\"],\n",
    "            \"labels\": [\n",
    "              row[\"label_word\"]\n",
    "            ],\n",
    "            \"URI\": row[\"URI\"]\n",
    "            },\n",
    "            \n",
    "            \"id\": row[\"index_e\"],\n",
    "            \"from_name\": \"label\",\n",
    "            \"to_name\": \"text\",\n",
    "            \"type\": \"labels\",\n",
    "            \"origin\": \"prediction\"\n",
    "        }\n",
    "    def get_dict(self):\n",
    "        return self.result_dict  \n",
    "class CreateOutput(object):\n",
    "    def __init__(self, text, filtred_sentence, entity_name_new):\n",
    "        self.filtred_sentence = filtred_sentence\n",
    "        self.entity_name_new = entity_name_new\n",
    "        self.main_dict = {\n",
    "            \"id\": 1,\n",
    "            \"data\": {\n",
    "              \"text\": text #sentenca inteira\n",
    "            },\n",
    "            \"annotations\": []\n",
    "        }\n",
    "        self._add_annotations()      \n",
    "    def _add_annotations(self):\n",
    "        results = []\n",
    "        count = 0        \n",
    "        for index, row in self.entity_name_new.iterrows(): \n",
    "            results.append(ResultNERJson(row).get_dict())        \n",
    "        item = [{\n",
    "              \"id\": 1,\n",
    "              \"created_username\": \" null, 0\",\n",
    "              \"created_ago\": \"\",\n",
    "              \"result\": results\n",
    "            }]\n",
    "        self.main_dict[\"annotations\"] = item\n",
    "    def get_output(self):\n",
    "        return self.main_dict\n",
    "    def add_relationship(self, from_id, to_id, relations, direction):\n",
    "        results = self.main_dict.get(\"annotations\")[0].get(\"result\")\n",
    "        relation = ResultRelationJson(from_id, to_id, [relations], direction).get_dict()\n",
    "        results.append(relation)\n",
    "        self.main_dict[\"annotations\"][0][\"result\"] = results   \n",
    "        \n",
    "def combine_itens_from_lists_add_in_json(from_id_vec, to_id_vec, relation_from_vec, output):\n",
    "    for idxRelation in range(0,len(from_id_vec)):\n",
    "        direction = \"right\"\n",
    "        output.add_relationship(from_id=from_id_vec[idxRelation], to_id=to_id_vec[idxRelation], relations = relation_from_vec[idxRelation], direction=direction)\n",
    "    return output\n",
    "def saveJsonFiles(df,from_id,to_id, lista_relacoes_sentence,sentence,SentenceNum,path):\n",
    "    #cria e salva o arquivo Json para labelstudio\n",
    "    text = sentence.iloc[0]['text']\n",
    "    print('Saved Json ->', True)\n",
    "    output = CreateOutput(text,sentence, df)\n",
    "    combine_itens_from_lists_add_in_json(from_id, to_id, lista_relacoes_sentence, output)\n",
    "    print(\"-------------\")\n",
    "    with open(os.path.join(path,f\"{SentenceNum}.json\"), \"w\") as outfile: \n",
    "        json.dump(output.get_output(), outfile) \n",
    "        \n",
    "def get_df_forJsons(sentence,idxTokens):\n",
    "    #retorna um dataframe com as informações das entidades e uma string contendo o nome completo da entidade\n",
    "    df_save_words = pd.DataFrame(columns=['index_e', \"LABEL\", \"START\", \"END\",\\\n",
    "                                      \"TEXT\", \"word_join\", \"start_word\", \"end_word\", \"label_word\",\"URI\"])\n",
    "\n",
    "    index_e = sentence.iloc[idxTokens]['index_e']\n",
    "    label = sentence.iloc[idxTokens]['deps']\n",
    "    start = int(sentence.iloc[idxTokens]['word_join_start'])\n",
    "    end = start + len(sentence.iloc[idxTokens]['form'])\n",
    "    text_ent = sentence.iloc[idxTokens]['form']\n",
    "    word_join = sentence.iloc[idxTokens]['word_join']\n",
    "    start_word = sentence.iloc[idxTokens]['word_join_start']\n",
    "    end_word = sentence.iloc[idxTokens]['word_join_end']\n",
    "    label_word = label.replace(\"B=\",\"\")\n",
    "    URI = sentence.iloc[idxTokens]['grafo']\n",
    "\n",
    "    df_save_words.loc[len(df_save_words.index)] = [index_e, label, start, end, text_ent, word_join,\n",
    "                                                   start_word,\n",
    "                                                   end_word,\n",
    "                                                   label_word,\n",
    "                                                   URI]\n",
    "\n",
    "    return df_save_words, word_join\n",
    "        \n",
    "def create_df_JsonFiles(df_entity,x,token,token2,URI_1,URI_2,idxTokens,idxTokens2,from_id,to_id,sentence):\n",
    "    #retorna o dataframe utilizado para criacao dos arquivos Json para labelstudio\n",
    "    entity_name_new_token1,wordjoin_1 = get_df_forJsons(sentence,idxTokens)\n",
    "    entity_name_new_token2,wordjoin_2 = get_df_forJsons(sentence,idxTokens2)\n",
    "    if idxTokens not in from_id and idxTokens not in to_id:\n",
    "        df_entity = pd.concat([df_entity, entity_name_new_token1])\n",
    "    if idxTokens2 not in from_id and idxTokens2 not in to_id:\n",
    "        df_entity = pd.concat([df_entity, entity_name_new_token2])\n",
    "\n",
    "#     print_relation_entities(wordjoin_1,wordjoin_2,token.replace('B=',''),token2.replace('B=',''),URI_1,URI_2,x)\n",
    "    return df_entity  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para criar dataframe para modelo BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_moddedText_BERT(text,start1,end1,start2,end2,Ent1_inic,Ent1_end,Ent2_inic,Ent2_end):\n",
    "    new_end_ent1 = int(end1) + len(Ent1_inic)\n",
    "    new_start_ent2 = int(start2) + len(Ent1_inic) + len(Ent1_end)\n",
    "    new_end_ent2 = int(end2) + len(Ent1_inic) + len(Ent1_end) + len(Ent2_inic)      \n",
    "    #adicionando [E1] e [/E1]\n",
    "    text_new = text[:int(start1)] + Ent1_inic + text[int(start1):]\n",
    "    text_new = text_new[:new_end_ent1] + Ent1_end + text_new[new_end_ent1:]\n",
    "    #adicionando [E2] e [/E2]\n",
    "    text_new2 = text_new[:new_start_ent2] + Ent2_inic + text_new[new_start_ent2:]\n",
    "    text_new2 = text_new2[:new_end_ent2] + Ent2_end + text_new2[new_end_ent2:]\n",
    "    \n",
    "    return text_new2\n",
    "\n",
    "def createText_sentence_BERT(text,start_1,end_1,start_2,end_2):\n",
    "    #funcao que retorna um novo texto para sentenca com [E1] e [E2] adicionados junto de cada entidade\n",
    "    start_ent1, start_ent2 = start_1, start_2\n",
    "    end_ent1, end_ent2 = end_1, end_2\n",
    "    Ent1_inic, Ent1_end = '[E1] ', ' [/E1]'\n",
    "    Ent2_inic, Ent2_end = '[E2] ', ' [/E2]'\n",
    "    \n",
    "    if start_ent1 < start_ent2: #[E1] vem antes de [E2]\n",
    "        text_new = create_moddedText_BERT(text,start_ent1,end_ent1,start_ent2,end_ent2,\\\n",
    "                                  Ent1_inic,Ent1_end,Ent2_inic,Ent2_end)\n",
    "    else: #[E2] vem antes de [E1]      \n",
    "        text_new = create_moddedText_BERT(text,start_ent2,end_ent2,start_ent1,end_ent1,\\\n",
    "                                      Ent2_inic,Ent2_end,Ent1_inic,Ent1_end)  \n",
    "    return text_new\n",
    "\n",
    "def create_bert_dataframe(df_bert,idxTokens,idxTokens2,sentence,URI_1,URI_2,has_relation,relation_type,SentenceNumber):\n",
    "    #retorna o dataframe com as informacoes de cada sentenca para utilizar no modelo BERT\n",
    "    df_bert_temp = pd.DataFrame(columns=['#Sentence','sentence','Ent1','Ent2','URI_1','URI_2','has_relation','relation'])\n",
    "    text = sentence.iloc[0]['text']\n",
    "    wordjoin_1, wordjoin_2 = sentence.iloc[idxTokens]['word_join'], sentence.iloc[idxTokens2]['word_join']\n",
    "    ent1, ent2 = sentence.iloc[idxTokens]['deps'], sentence.iloc[idxTokens2]['deps']\n",
    "    ent1, ent2 = ent1.replace(\"B=\",\"\"), ent2.replace(\"B=\",\"\")\n",
    "    start_1, start_2 = sentence.iloc[idxTokens]['word_join_start'], sentence.iloc[idxTokens2]['word_join_start']\n",
    "    end_1, end_2 = sentence.iloc[idxTokens]['word_join_end'], sentence.iloc[idxTokens2]['word_join_end']\n",
    "    text_bert_ents = createText_sentence_BERT(text,start_1,end_1,start_2,end_2)\n",
    "    df_bert_temp.loc[0] = [SentenceNumber,\n",
    "                           text_bert_ents,\n",
    "                           ent1,\n",
    "                           ent2,\n",
    "                           URI_1,\n",
    "                           URI_2,\n",
    "                           has_relation,\n",
    "                           relation_type]\n",
    "    df_bert = pd.concat([df_bert, df_bert_temp])\n",
    "    if relation_type!='no_relation':\n",
    "        print_relation_entities(wordjoin_1,wordjoin_2,ent1,ent2,URI_1,URI_2,relation_type,text_bert_ents)\n",
    "    return df_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para processar as sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def create_relations_dataframe(df_relation,token,token2,URI_1,URI_2,x,originalSentenceNumber):\n",
    "    #retorna dataframe das entidades e suas relações em cada linha\n",
    "    #importante para contabilizar os tipos de relação\n",
    "    df_relation_new = pd.DataFrame(columns=['Relation','Ent1','Ent2','URI_1','URI_2','#Sentence'])\n",
    "    df_relation_new.loc[0] = [x,\n",
    "                            token.replace('B=',''),\n",
    "                            token2.replace('B=',''),\n",
    "                            URI_1,\n",
    "                            URI_2,\n",
    "                            originalSentenceNumber]\n",
    "    df_relation = pd.concat([df_relation, df_relation_new])\n",
    "    return df_relation\n",
    "\n",
    "def verifica_pares_entidade_interesse(ENT_1, ENT_2,relation_type):\n",
    "    #verifica se a relacao encontrada vai ser do tipo temporal_relation CRONO->CRONO\n",
    "    #funcao talvez precise ser atualizada no futuro conforme a ontologia for povoada\n",
    "    \n",
    "    if 'UNIDADE_CRONO' == ENT_1 and 'UNIDADE_CRONO' == ENT_2:\n",
    "             return 'has_temporal_relation'\n",
    "    else:\n",
    "        return relation_type\n",
    "    \n",
    "    # lista_from = ['POÇO','UNIDADE_LITO','UNIDADE_LITO','CAMPO','POÇO','POÇO','UNIDADE_LITO','UNIDADE_LITO']\n",
    "    # lista_to = ['UNIDADE_LITO','NÂOCONSOLID','ROCHA','BACIA','BACIA','CAMPO','BACIA','UNIDADE_CRONO']        \n",
    "    # for idx in range(0,len(lista_to)):\n",
    "    #     if lista_from[idx] == ENT_1 and lista_to[idx] == ENT_2:\n",
    "    #         return relation_type\n",
    "    # return 'has_temporal_relation'\n",
    "    \n",
    "    \n",
    "\n",
    "#def go_through_sentence(sentence_df, df_relation,df_bert,sent_numb):\n",
    "def go_through_sentence(sentence_df, df_relation, df_bert, originalSentenceNumber): \n",
    "    #percorre a sentenca em busca de relacoes entre entidades anotadas com URIs\n",
    "    df_entity = pd.DataFrame()\n",
    "    from_id, to_id = [], []\n",
    "    relation_from, relation_to = [], []\n",
    "    lista_relacoes_sentence = []\n",
    "    lista_relacoes, lista_uris, lista_classes = [], [], []\n",
    "    \n",
    "    is_to_save = False\n",
    "#     df_bert.to_csv(save_csv_name, encoding='utf-8',index=False)\n",
    "#     df_relation.to_csv('df_relation.csv', encoding='utf-8',index=False)\n",
    "    for idxTokens in range(len(sentence_df)):\n",
    "        token, URI_1 = sentence_df.iloc[idxTokens]['deps'], sentence_df.iloc[idxTokens]['grafo']\n",
    "        for idxTokens2 in range(len(sentence_df)):\n",
    "            if idxTokens != idxTokens2:\n",
    "                token2, URI_2 = sentence_df.iloc[idxTokens2]['deps'], sentence_df.iloc[idxTokens2]['grafo']\n",
    "                has_relation = False\n",
    "                relation_type = go_through_relations(URI_1,URI_2)\n",
    "                if relation_type: \n",
    "                    print(\"-------------\")\n",
    "                    print('sentence =', originalSentenceNumber)\n",
    "                    is_to_save = True\n",
    "                    has_relation = True\n",
    "                    Ent1, Ent2 = token.replace(\"B=\",\"\"), token2.replace(\"B=\",\"\")\n",
    "                    relation_type = verifica_pares_entidade_interesse(Ent1,Ent2,relation_type)\n",
    "                    lista_relacoes_sentence.append(relation_type)\n",
    "\n",
    "                    #criar df_bert para BERT RE com codigo do Fabio\n",
    "                    df_bert = create_bert_dataframe(df_bert,idxTokens,idxTokens2,sentence_df,\n",
    "                                                    URI_1,URI_2,\n",
    "                                                    has_relation,relation_type,originalSentenceNumber)\n",
    "\n",
    "                    #para contabilizar os pares de entidade por relacao\n",
    "                    df_relation = create_relations_dataframe(df_relation,token,token2,\n",
    "                                                             URI_1,URI_2,relation_type,originalSentenceNumber)\n",
    "                    #listas para contabilizar relacoes, uris e classes\n",
    "                    lista_relacoes.append(relation_type)\n",
    "                    lista_uris.append(URI_1)\n",
    "                    lista_uris.append(URI_2)         \n",
    "                    lista_classes.append(Ent1)\n",
    "                    lista_classes.append(Ent2)\n",
    "\n",
    "                    if is_to_createJsons: #se quiser criar Jsons para LabelStudio\n",
    "                        df_entity = create_df_JsonFiles(df_entity,relation_type,token,token2,URI_1,URI_2,\n",
    "                                                        idxTokens,idxTokens2,from_id,to_id,sentence_df)\n",
    "                        from_id.append(idxTokens)\n",
    "                        to_id.append(idxTokens2) \n",
    "\n",
    "                else: #nao achou relacao\n",
    "                    relation_type = 'no_relation'\n",
    "\n",
    "                    df_bert = create_bert_dataframe(df_bert,idxTokens,idxTokens2,sentence_df,\n",
    "                                                    URI_1,URI_2,has_relation,relation_type,originalSentenceNumber)\n",
    "                        \n",
    "    return lista_relacoes,lista_uris,lista_classes,\\\n",
    "            df_bert, df_relation, df_entity, \\\n",
    "            lista_relacoes_sentence, from_id, to_id, is_to_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler arquivo csv (ou pkl) com as sentenças pós filtragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero total de sentenças de treino pos-filtragem ->  3466\n",
      "Numero total de sentenças de validação pos-filtragem ->  461\n",
      "Numero total de sentenças de teste pos-filtragem ->  775\n"
     ]
    }
   ],
   "source": [
    "# Treino\n",
    "df_filtred_sentences_treino = pickle.load(open('df_filtred_petroner_uri_treino.conllu.pkl', 'rb'))\n",
    "#df_filtred_sentences_treino = pd.read_csv('df_filtred_petroner_uri_treino_conllu.csv')\n",
    "\n",
    "df_group_treino = df_filtred_sentences_treino.groupby('sentence')\n",
    "print('Numero total de sentenças de treino pos-filtragem -> ',len(df_group_treino))\n",
    "\n",
    "# Valid\n",
    "df_filtred_sentences_valid = pickle.load(open('df_filtred_petroner_uri_valid.conllu.pkl', 'rb'))\n",
    "#df_filtred_sentences_valid = pd.read_csv('df_filtred_petroner_uri_valid_conllu.csv')\n",
    "\n",
    "df_group_valid = df_filtred_sentences_valid.groupby('sentence')\n",
    "print('Numero total de sentenças de validação pos-filtragem -> ',len(df_group_valid))\n",
    "\n",
    "# Teste\n",
    "df_filtred_sentences_teste = pickle.load(open('df_filtred_petroner_uri_teste.conllu.pkl', 'rb'))\n",
    "#df_filtred_sentences_teste = pd.read_csv('df_filtred_petroner_uri_teste_conllu.csv')\n",
    "\n",
    "df_group_teste = df_filtred_sentences_teste.groupby('sentence')\n",
    "print('Numero total de sentenças de teste pos-filtragem -> ',len(df_group_teste))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolher se deseja criar Jsons para labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_to_createJsons = True\n",
    "# is_to_createJsons = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_folder_path = \"./JSONs_04_05\" #local onde são salvos os Jsons para labelstudio\n",
    "save_folder_path_treino = \"./JSONs_treino\"\n",
    "save_csv_name_bert_treino = 'df_bert_sentences_treino.csv'\n",
    "save_csv_name_relation_treino = 'df_relation_treino.csv'\n",
    "lista_relacoes_treino = 'lista_relacoes_treino.pkl'\n",
    "lista_uris_treino = 'lista_uris_treino.pkl'\n",
    "lista_classes_treino = 'lista_classes_treino.pkl'\n",
    "\n",
    "save_folder_path_valid = \"./JSONs_valid\"\n",
    "save_csv_name_bert_valid = 'df_bert_sentences_valid.csv'\n",
    "save_csv_name_relation_valid = 'df_relation_valid.csv'\n",
    "lista_relacoes_valid = 'lista_relacoes_valid.pkl'\n",
    "lista_uris_valid = 'lista_uris_valid.pkl'\n",
    "lista_classes_valid = 'lista_classes_valid.pkl'\n",
    "\n",
    "save_folder_path_teste = \"./JSONs_teste\"\n",
    "save_csv_name_bert_teste = 'df_bert_sentences_teste.csv'\n",
    "save_csv_name_relation_teste = 'df_relation_teste.csv'\n",
    "lista_relacoes_teste = 'lista_relacoes_teste.pkl'\n",
    "lista_uris_teste = 'lista_uris_teste.pkl'\n",
    "lista_classes_teste = 'lista_classes_teste.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotina para processar as sentenças já filtradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def processar_sentencas_filtradas(df_filtred_sentences, \n",
    "                                  df_group, \n",
    "                                  save_csv_name_bert, \n",
    "                                  save_csv_name_relation, \n",
    "                                  save_folder_path, \n",
    "                                  lista_relacoes_file, \n",
    "                                  lista_uris_file, \n",
    "                                  lista_classes_file):\n",
    "\n",
    "    #%%time\n",
    "\n",
    "    numberSentences = df_filtred_sentences.iloc[-1]['sentence'] #numero de sentencas diferentes no arquivo ja filtrado\n",
    "    lista_relacoes, lista_uris, lista_classes, list_sentences_dict = [], [], [], []\n",
    "    df_relation, df_bert = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    countJsons=0\n",
    "    for idx in range(1,len(df_group)):\n",
    "        filtred_sentence = df_group.get_group(idx)#aqui filtred_sentence é um dataframe da sentenca\n",
    "        originalSentenceNumber = filtred_sentence.iloc[0]['#sentence_original']\n",
    "        text = filtred_sentence.iloc[0]['text']\n",
    "        new_relacoes,new_uris,new_classes,df_bert,\\\n",
    "        df_relation,df_entity,lista_relacoes_sentence,\\\n",
    "        from_id,to_id, is_to_save = go_through_sentence(filtred_sentence,df_relation,df_bert,originalSentenceNumber) \n",
    "                                    #go_through_sentence(sentence_df,df_relation,df_bert,sent_numb)\n",
    "        \n",
    "        lista_relacoes = lista_relacoes + new_relacoes\n",
    "        lista_uris = lista_uris + new_uris\n",
    "        lista_classes = lista_classes + new_classes\n",
    "        \n",
    "        df_bert.to_csv(save_csv_name_bert, encoding='utf-8',index=False)\n",
    "        df_relation.to_csv(save_csv_name_relation, encoding='utf-8',index=False)\n",
    "        if is_to_save and is_to_createJsons:#Jsons somente criados para sentencas com relacao\n",
    "            countJsons+=1\n",
    "            saveJsonFiles(df_entity,from_id,to_id, \n",
    "                          lista_relacoes_sentence,filtred_sentence,originalSentenceNumber,save_folder_path)\n",
    "                \n",
    "    print(\"-------------\")\n",
    "    print(\"Number of Jsons saved = \", countJsons)\n",
    "\n",
    "    # pickle.dump(df_relation, open('df_relation.pkl','wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    df_relation.to_csv(save_csv_name_relation, encoding='utf-8',index=False)\n",
    "    df_bert.to_csv(save_csv_name_bert, encoding='utf-8',index=False)\n",
    "\n",
    "    relacoes = np.unique(lista_relacoes, return_counts = True)\n",
    "    pickle.dump(relacoes, open(lista_relacoes_file,'wb'),protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    uris = np.unique(lista_uris, return_counts = True)\n",
    "    pickle.dump(uris,open(lista_uris_file,'wb'),protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    classes = np.unique(lista_classes, return_counts = True)\n",
    "    pickle.dump(classes,open(lista_classes_file,'wb'),protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 2\n",
      "Token 1 =   Campo de Curimã --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0352\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "Quando aplicados    [E1] Campo de Curimã [/E1] — localizado    [E2] Bacia    Ceará [/E2] e produtor de óleo em arenitos flúvio-deltaicos de idade aptiana — permitiram melhor compreensão    distribuição lateral e vertical     fácies permoporosas e, consequentemente, uma caracterização mais precisa de suas propriedades médias..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 16\n",
      "Token 1 =   Campo de Curimã --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0352\n",
      "Token 2 =   Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "O [E1] Campo de Curimã [/E1]                plataforma continental    [E2] Ceará [/E2],    porção central    Sub-bacia de Mundaú, a 75 km de Fortaleza e 50 km    linha de costa, em lâmina d'água de 50 metros (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 16\n",
      "Token 1 =   Campo de Curimã --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0352\n",
      "Token 2 =   Sub-bacia de Mundaú --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "O [E1] Campo de Curimã [/E1]                plataforma continental    Ceará,    porção central    [E2] Sub-bacia de Mundaú [/E2], a 75 km de Fortaleza e 50 km    linha de costa, em lâmina d'água de 50 metros (fig. 1)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 17\n",
      "Token 1 =   formações Mundaú --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_296\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "Seus principais reservatórios são arenitos fl[E2] úvio-del [/E2]taicos com boas características permoporosas, lateralmente contínuos, subdivididos em sete zonas produtoras pertencentes    [E1] formações Mundaú [/E1] e Paracuru (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 17\n",
      "Token 1 =   Paracuru --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_200\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "Seus principais reservatórios são arenitos fl[E2] úvio-del [/E2]taicos com boas características permoporosas, lateralmente contínuos, subdivididos em sete zonas produtoras pertencentes    formações Mundaú e [E1] Paracuru [/E1] (fig. 2)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 18\n",
      "Token 1 =   Curima --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0352\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "- Fig. t= Localizagao-do-campo de [E1] Curima [/E1]; [E2] Bacia    Ceará [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   Campo de Curimã --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0352\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "--.==Q Campo de Cu[E1] rimã, descôbert [/E1]o em janeiro de 1978,            produtor de óleo     arenitos de idade aptiana pertencentes    formações Mundaú e Paracuru    [E2] Bacia    Ceará [/E2], Sub-bacia de Mundaú (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   Campo de Curimã --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0352\n",
      "Token 2 =   Sub-bacia de Mundaú --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "--.==Q Campo de Cu[E1] rimã, descôbert [/E1]o em janeiro de 1978,            produtor de óleo     arenitos de idade aptiana pertencentes    formações Mundaú e Paracuru    Bacia    Ceará, [E2] Sub-bacia de Mundaú [/E2] (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   formações Mundaú --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_296\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "--.==Q Campo de Curimã, descôberto em janeiro de 1978,            produtor de óleo     arenitos de[E2]  idade a [/E2]ptiana pertencentes    [E1] formações Mundaú [/E1] e Paracuru    Bacia    Ceará, Sub-bacia de Mundaú (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   formações Mundaú --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_296\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "--.==Q Campo de Curimã, descôberto em janeiro de 1978,            produtor de óleo     arenitos de idade aptiana pertencentes    [E1] formações Mundaú [/E1] e Paracuru    [E2] Bacia    Ceará [/E2], Sub-bacia de Mundaú (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   formações Mundaú --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_296\n",
      "Token 2 =   Sub-bacia de Mundaú --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "--.==Q Campo de Curimã, descôberto em janeiro de 1978,            produtor de óleo     arenitos de idade aptiana pertencentes    [E1] formações Mundaú [/E1] e Paracuru    Bacia    Ceará, [E2] Sub-bacia de Mundaú [/E2] (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   Paracuru --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_200\n",
      "Token 2 =   óleo --- Class 2 =  FLUIDODATERRA_i --- URI 2 =  #oil\n",
      "Relation Type =  constituted_by\n",
      "--.==Q Campo de Curimã, descôberto em janeiro de 1978,            produtor de óleo     ar[E2] enit [/E2]os de idade aptiana pertencentes    formações Mundaú e [E1] Paracuru [/E1]    Bacia    Ceará, Sub-bacia de Mundaú (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   Paracuru --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_200\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "--.==Q Campo de Curimã, descôberto em janeiro de 1978,            produtor de óleo     arenitos de[E2]  idade a [/E2]ptiana pertencentes    formações Mundaú e [E1] Paracuru [/E1]    Bacia    Ceará, Sub-bacia de Mundaú (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   Paracuru --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_200\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "--.==Q Campo de Curimã, descôberto em janeiro de 1978,            produtor de óleo     arenitos de idade aptiana pertencentes    formações Mundaú e [E1] Paracuru [/E1]    [E2] Bacia    Ceará [/E2], Sub-bacia de Mundaú (fig. 2)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 25\n",
      "Token 1 =   Paracuru --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_200\n",
      "Token 2 =   Sub-bacia de Mundaú --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "--.==Q Campo de Curimã, descôberto em janeiro de 1978,            produtor de óleo     arenitos de idade aptiana pertencentes    formações Mundaú e [E1] Paracuru [/E1]    Bacia    Ceará, [E2] Sub-bacia de Mundaú [/E2] (fig. 2)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 180\n",
      "Token 1 =   Carbonifero Inferior --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   carboniferas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  has_temporal_relation\n",
      "A presença de formas chesterianas (Carbonifero[E1]  Inferior)    Bacia  [/E1]   Amazonas,    faixa sul de afloramentos, e sua ausência    região    Arco de Purus, sugerem que as primeiras transgressões marinhas [E2] carboniferas [/E2] não eram provenientes    Bacia    Solimões, passando sobre o referido arco, ou que os sedimentos representativos       idade foram erodidos juntamente com parte    Devoniano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 180\n",
      "Token 1 =   carboniferas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   Carbonifero Inferior --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  has_temporal_relation\n",
      "A presença de formas chesterianas (Carbonifero[E2]  Inferior)    Bacia  [/E2]   Amazonas,    faixa sul de afloramentos, e sua ausência    região    Arco de Purus, sugerem que as primeiras transgressões marinhas [E1] carboniferas [/E1] não eram provenientes    Bacia    Solimões, passando sobre o referido arco, ou que os sedimentos representativos       idade foram erodidos juntamente com parte    Devoniano..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 183\n",
      "Token 1 =   Formação Itaituba --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_187\n",
      "Token 2 =   Bacia Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "[E2] Bacia    Amazonas [/E2], em carbonatos de afloramentos atribuídos    intervalo basal    [E1] Formação Itaituba [/E1] (Fúlfaro, 1965),    Rio Tapajós, Pará, ocorrem os conodontes Gnathodus billineatus, Gnathodus girtyi e Lochriea mononodosa (fig.1)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 350\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   idades Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "O [E1] Membro Mucuri [/E1]              de sedimentos de [E2] idades Alagoas [/E2] e pré-Alagoas depositados em ambiente alúvio-flúvio-deltaico, sob clima árido, durante a fase rift     bacias    Espirito Santo e Mucuri..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 350\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "O [E1] Membro Mucuri [/E1]              de sedimentos de idades Alagoas e [E2] pré-Alagoas [/E2] depositados em ambiente alúvio-flúvio-deltaico, sob clima árido, durante a fase rift     bacias    Espirito Santo e Mucuri..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 350\n",
      "Token 1 =   idades Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "O Membro Mucuri              de sedimentos de [E1] idades Alagoas [/E1] e [E2] pré-Alagoas [/E2] depositados em ambiente alúvio-flúvio-deltaico, sob clima árido, durante a fase rift     bacias    Espirito Santo e Mucuri..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 350\n",
      "Token 1 =   pré-Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   idades Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "O Membro Mucuri              de sedimentos de [E2] idades Alagoas [/E2] e [E1] pré-Alagoas [/E1] depositados em ambiente alúvio-flúvio-deltaico, sob clima árido, durante a fase rift     bacias    Espirito Santo e Mucuri..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 352\n",
      "Token 1 =   idade Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   idade pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "modo, os sedimentos de idade Alago[E1] as têm água d [/E1]e formação composicionalmente distinta        sedimentos de [E2] idade pré-Alagoas [/E2] (continental), causando modificações diagenéticas diferentes     dois pacotes..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 352\n",
      "Token 1 =   idade pré-Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   idade Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "modo, os sedimentos de idade Alago[E2] as têm água d [/E2]e formação composicionalmente distinta        sedimentos de [E1] idade pré-Alagoas [/E1] (continental), causando modificações diagenéticas diferentes     dois pacotes..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 354\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   idade Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "A maioria     reservatórios    [E1] Membro Mucuri [/E1] são de [E2] idade Alagoas [/E2], e, devido a sua melhor amostragem, estes reservatórios foram descritos mais detalhadamente..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 377\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "modo, foi considerada a divisão    [E1] Membro Mucuri [/E1] em [E2] Alagoas [/E2] e pré-Alagoas para considerar separadamente a evolução diagenética     sedimentos areno-conglomeráticos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 377\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "modo, foi considerada a divisão    [E1] Membro Mucuri [/E1] em Alagoas e [E2] pré-Alagoas [/E2] para considerar separadamente a evolução diagenética     sedimentos areno-conglomeráticos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 377\n",
      "Token 1 =   Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "modo, foi considerada a divisão    Membro Mucuri em [E1] Alagoas [/E1] e [E2] pré-Alagoas [/E2] para considerar separadamente a evolução diagenética     sedimentos areno-conglomeráticos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 377\n",
      "Token 1 =   pré-Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "modo, foi considerada a divisão    Membro Mucuri em [E2] Alagoas [/E2] e [E1] pré-Alagoas [/E1] para considerar separadamente a evolução diagenética     sedimentos areno-conglomeráticos..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 383\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "Os [E2] arenitos [/E2] e conglomerados    [E1] Membro Mucuri [/E1] são arcóseos líticos conforme a classificação composicional proposta por McBride (1963) (fig. 3)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 383\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   conglomerados --- Class 2 =  ROCHA --- URI 2 =  #conglomerate\n",
      "Relation Type =  constituted_by\n",
      "Os arenitos e [E2] conglomerados [/E2]    [E1] Membro Mucuri [/E1] são arcóseos líticos conforme a classificação composicional proposta por McBride (1963) (fig. 3)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 385\n",
      "Token 1 =   Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "O estudo realizado a diferentes profundidades, em diferentes poços     bacias    Espírito Santo” e de Mucuri e em pacotes de diferentes idades ([E1] Alagoas [/E1] e [E2] pré-Alagoas [/E2]) permitiu identificar as variações diagenéticas    Membro Mucuri como um todo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 385\n",
      "Token 1 =   pré-Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "O estudo realizado a diferentes profundidades, em diferentes poços     bacias    Espírito Santo” e de Mucuri e em pacotes de diferentes idades ([E2] Alagoas [/E2] e [E1] pré-Alagoas [/E1]) permitiu identificar as variações diagenéticas    Membro Mucuri como um todo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 385\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "O estudo realizado a diferentes profundidades, em diferentes poços     bacias    Espírito Santo” e de Mucuri e em pacotes de diferentes idades ([E2] Alagoas [/E2] e pré-Alagoas) permitiu identificar as variações diagenéticas    [E1] Membro Mucuri [/E1] como um todo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 385\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "O estudo realizado a diferentes profundidades, em diferentes poços     bacias    Espírito Santo” e de Mucuri e em pacotes de diferentes idades (Alagoas e [E2] pré-Alagoas [/E2]) permitiu identificar as variações diagenéticas    [E1] Membro Mucuri [/E1] como um todo..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 402\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "[E2] arenitos [/E2]    [E1] Membro Mucuri [/E1], foram encontradas cutículas formadas por lamelas de argila dispostas paralelamente   superfície     grãos, apresentando pontes e meniscos (foto 1)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 448\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "[E2] arenitos [/E2]    [E1] Membro Mucuri [/E1], o processo de iltização foi reconhecido, em seção delgada,      aumento    birrefringência     argilo-minerais..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 453\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "A transformação de caulinita em ilta é bem representada por booklets com birrefrigência amarela de primeira ordem, preenchendo os poros de [E2] arenitos [/E2] e conglomerados    . [E1] Membro Mucuri [/E1] a profundidades superiores a 2 500 m..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 558\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "tendência    aumento    conteúdo de cimento de quartzo com a profundidade     [E2] arenitos [/E2]    [E1] Membro Mucuri [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 576\n",
      "Token 1 =   idade Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "Constitui, em média, 2,5% e 1,5%     litologias de [E1] idade Alagoas [/E1] e [E2] pré-Alagoas [/E2], respectivamente..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 576\n",
      "Token 1 =   pré-Alagoas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Alagoas_Age\n",
      "Token 2 =   idade Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_temporal_relation\n",
      "Constitui, em média, 2,5% e 1,5%     litologias de [E2] idade Alagoas [/E2] e [E1] pré-Alagoas [/E1], respectivamente..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 588\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   anidrita --- Class 2 =  ROCHA --- URI 2 =  #anhydrite\n",
      "Relation Type =  constituted_by\n",
      "Os cimentos: evaporíticos anidrita e [E2] gipsita  [/E2]não possuem expressão volumétrica     reservatórios siliciclásticos    [E1] Membro Mucuri [/E1]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 588\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   gipsita --- Class 2 =  ROCHA --- URI 2 =  #gipsita\n",
      "Relation Type =  constituted_by\n",
      "Os cimentos: evaporíticos anidrita e gipsita não[E2]  possue [/E2]m expressão volumétrica     reservatórios siliciclásticos    [E1] Membro Mucuri [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 603\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   anidrita --- Class 2 =  ROCHA --- URI 2 =  #anhydrite\n",
      "Relation Type =  constituted_by\n",
      "exposto,            a associação     três cimentos encontrados    [E1] Membro Mucuri [/E1]: [E2] anidrita [/E2], calcita e dolomita..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 621\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   idade pré-Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "Os plagioclásios com feições de albitzação    Membro Mucu[E1] ri foram enco [/E1]ntrados     sedimentos a profundidades superiores a 2 500 m, em geral, de [E2] idade pré-Alagoas [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 636\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "A porosidade primária     [E2] arenitos [/E2]    [E1] Membro Mucuri [/E1] foi profundamente afetada      diagênese..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 639\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "Entre os mecanismos sugeridos para a geração de porosidade secundária sob regime eodiagenético, a dissolução por influxo de água meteórica (Bjdriykke, 1984) e mixing corrosion (Bogli, 1964, apud Giles e Marshall, 1986) são os mais prováveis de terem ocorrido     [E2] arenitos [/E2] e     conglomerados    [E1] Membro Mucuri [/E1]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 639\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   conglomerados --- Class 2 =  ROCHA --- URI 2 =  #conglomerate\n",
      "Relation Type =  constituted_by\n",
      "Entre os mecanismos sugeridos para a geração de porosidade secundária sob regime eodiagenético, a dissolução por influxo de água meteórica (Bjdriykke, 1984) e mixing corrosion (Bogli, 1964, apud Giles e Marshall, 1986) são os mais prováveis de terem ocorrido     arenitos e     [E2] conglomerados [/E2]    [E1] Membro Mucuri [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 642\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   idade Alagoas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Alagoas_Age\n",
      "Relation Type =  has_age\n",
      "A associação de porosidade móldica e intragranular a tais cimentos induz   conclusão de que sejam resultantes    lixiviação meteórica. “Os principais reservatórios    [E1] Membro Mucuri [/E1] são de [E2] idade Alagoas [/E2] e tiveram longos tempos de residência B. Geoci..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 655\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "Os reservatórios    [E1] Membro Mucuri [/E1], compostos por [E2] arenitos [/E2] e conglomerados arcoseanos, estiveram submetidos a intensa diagênese, principalmente sob regime eodiagenético..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 708\n",
      "Token 1 =   campos de Rio Preto --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0861\n",
      "Token 2 =   Bacia Espírito Santo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_270\n",
      "Relation Type =  located_in\n",
      "LEITE, M.P. Deposição e evolução diagenética     reservatórios    Membro Mucuri (Cretáceo Inferior),     [E1] campos de Rio Preto [/E1] e São Mateus, [E2] Bacia    Espírito Santo [/E2], Brasil..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 708\n",
      "Token 1 =   São Mateus --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0912\n",
      "Token 2 =   Bacia Espírito Santo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_270\n",
      "Relation Type =  located_in\n",
      "LEITE, M.P. Deposição e evolução diagenética     reservatórios    Membro Mucuri (Cretáceo Inferior),     campos de Rio Preto e [E1] São Mateus [/E1], [E2] Bacia    Espírito Santo [/E2], Brasil..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 711\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   Formação Mariricu --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_013\n",
      "Relation Type =  part_of\n",
      "MAINO, V.M., WINTER, W.R., MILANEZ, D., NOVAIS, B.C., PIMENTEL, A.M.P., ALVES, D.B., ANJOS, S.M.C. Sistema deposicional, litofácies e fácies-reservatório    [E1] Membro Mucuri [/E1]    [E2] Formação Mariricu [/E2],    Campo de Rio Itaúnas..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 738\n",
      "Token 1 =   poço 7-ICA-4 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_021985\n",
      "Token 2 =   Campo de Ilha Caçamba --- Class 2 =  CAMPO --- URI 2 =  #CAMP_CD_CAMPO_0545\n",
      "Relation Type =  located_in\n",
      "Análise de testemunhos    [E1] poço 7-ICA-4 [/E1]- | BA, [E2] Campo de Ilha    Caçamba [/E2], Bacia de Mucuri..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 738\n",
      "Token 1 =   poço 7-ICA-4 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_021985\n",
      "Token 2 =   Bacia de Mucuri --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_260\n",
      "Relation Type =  located_in\n",
      "Análise de testemunhos    [E1] poço 7-ICA-4 [/E1]- | BA, Campo de Ilha    Caçamba, [E2] Bacia de Mucuri [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 738\n",
      "Token 1 =   Campo de Ilha Caçamba --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0545\n",
      "Token 2 =   Bacia de Mucuri --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_260\n",
      "Relation Type =  located_in\n",
      "Análise de testemunhos    poço 7-ICA-4- | BA, [E1] Campo de Ilha    Caçamba [/E1], [E2] Bacia de Mucuri [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 779\n",
      "Token 1 =   Campo de Ubarana --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0975\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "A partir       estudo regional,            uma campanha de perfuração    porção submersa    Bacia Potig[E2] uar, e já    t [/E2]erceiro poço              o [E1] Campo de Ubarana [/E1], em 1973..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 819\n",
      "Token 1 =   Formação Pendência --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "É       contexto que se originou o Rift Potiguar, p[E2] reenchid [/E2]o por espessos pacotes sedimentares associados   [E1] Formação Pendência [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 847\n",
      "Token 1 =   Membro Galinhos --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_045\n",
      "Token 2 =   Formação Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      ", portanto,      elaboração     seguintes mapas de isópacas: [E2] Formação Alagamar [/E2] ([E1] Membro Galinhos [/E1] e CPT), formações Açu (unidade Açu-1) e Alagamar (Membro Galinhos), e unidade Açu-2 (Formação Ponta    Mel)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 847\n",
      "Token 1 =   Membro Galinhos --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_045\n",
      "Token 2 =   Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      ", portanto,      elaboração     seguintes mapas de isópacas: Formação Alagamar (Membro Gali[E1] nhos e CPT), fo [/E1]rmações Açu (unidade Açu-1) e [E2] Alagamar [/E2] (Membro Galinhos), e unidade Açu-2 (Formação Ponta    Mel)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 847\n",
      "Token 1 =   Membro Galinhos --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_045\n",
      "Token 2 =   Formação Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      ", portanto,      elaboração     seguintes mapas de isópacas: Formação Al[E2] agamar (Membro Ga [/E2]linhos e CPT), formações Açu (unidade Açu-1) e Alagamar ([E1] Membro Galinhos [/E1]), e unidade Açu-2 (Formação Ponta    Mel)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 847\n",
      "Token 1 =   Membro Galinhos --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_045\n",
      "Token 2 =   Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      ", portanto,      elaboração     seguintes mapas de isópacas: Formação Alagamar (Membro Galinhos e CPT), formações Açu (unidade Açu-1) e [E2] Alagamar [/E2] ([E1] Membro Galinhos [/E1]), e unidade Açu-2 (Formação Ponta    Mel)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 848\n",
      "Token 1 =   Membro Upanema --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_050\n",
      "Token 2 =   Formação Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      "O mapa de isópacas    [E2] Formação Alagamar [/E2] ([E1] Membro Upanema [/E1] e CPT) representa os primeiros sedimentos depositados    fase pós-rift    Bacia B. Geoci..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 852\n",
      "Token 1 =   Membro Galinhos --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_045\n",
      "Token 2 =   Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      "A princípio mapeadas individualmente, as formações Açu (unidade Açu-1) e [E2] Alagamar [/E2] ([E1] Membro Galinhos [/E1]) apresentaram tendência bastante semelhante    distribuição     espessuras..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 855\n",
      "Token 1 =   Membro Galinhos --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_045\n",
      "Token 2 =   Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      "A dificuldade    mapeamento    topo       formação fez com que se optasse      apresentação     espessuras     formações Açu (unidade Açu-1) e [E2] Alagamar [/E2] ([E1] Membro Galinhos [/E1])     único mapa de isópacas (fig. 8)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 891\n",
      "Token 1 =   Formação Pendência --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "Com o final    fase rift, processos erosivos de caráter regional dominaram a Bacia Potig[E2] uar, formando  [/E2]a discordância    topo    [E1] Formação Pendência [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 893\n",
      "Token 1 =   Membro Upanema --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_050\n",
      "Token 2 =   Formação Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      "Os primeiros sedimentos depositados                [E1] Membro Upanema [/E1]    [E2] Formação Alagamar [/E2], sobrepostos       calcilutitos e folhelhos     Camadas Ponta    Tubarão (CPT)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 893\n",
      "Token 1 =   Membro Upanema --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_050\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "Os primeiros sedimentos depositados                Membro Upan[E1] ema    Formaçã [/E1]o Alagamar, sobrepostos       calcilutitos e [E2] folhelhos [/E2]     Camadas Ponta    Tubarão (CPT)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 893\n",
      "Token 1 =   Formação Alagamar --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_056\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "Os primeiros sedimentos depositados                Membro Upanema    Formação Al[E1] agamar, sobrepost [/E1]os       calcilutitos e [E2] folhelhos [/E2]     Camadas Ponta    Tubarão (CPT)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 893\n",
      "Token 1 =   Camadas Ponta Tubarão --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_028\n",
      "Token 2 =   Formação Alagamar --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_056\n",
      "Relation Type =  part_of\n",
      "Os primeiros sedimentos depositados                Membro Upanema    Formação Al[E2] agamar, sobrepost [/E2]os       calcilutitos e folhelhos     [E1] Camadas Ponta    Tubarão [/E1] (CPT)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 893\n",
      "Token 1 =   Camadas Ponta Tubarão --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_028\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "Os primeiros sedimentos depositados                Membro Upanema    Formação Alagamar, sobrepostos       calcilutitos e [E2] folhelhos [/E2]     [E1] Camadas Ponta    Tubarão [/E1] (CPT)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 931\n",
      "Token 1 =   Formação Macau --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_050\n",
      "Token 2 =   basaltos --- Class 2 =  ROCHA --- URI 2 =  #basalt\n",
      "Relation Type =  constituted_by\n",
      "Teixeira (1991), em estudo sobre a porção submersa    Bacia Potiguar, constatou a presença de fortes dobramentos de direção NE-SW afetando os [E2] basaltos [/E2]    [E1] Formação Macau [/E1], depositados    Eoceno/Oligoceno,     proximidades    Campo de Agulha..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 931\n",
      "Token 1 =   Campo de Agulha --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0012\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "Teixeira (1991), em estudo sobre a porção submersa    Bacia Potig[E2] uar, constatou [/E2] a presença de fortes dobramentos de direção NE-SW afetando os basaltos    Formação Macau, depositados    Eoceno/Oligoceno,     proximidades    [E1] Campo de Agulha [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 945\n",
      "Token 1 =   Formação Alagamar --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_056\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "Durante o estágio pós-rift a Bacia Potig[E2] uar passou por [/E2] um período de relativa calmaria tectônica, quando foram depositados os sedimentos    [E1] Formação Alagamar [/E1], sobrepostos por uma megassequência transgressiva composta       unidades Açu-1, Açu-2, Açu-4 e Jandaíra..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 945\n",
      "Token 1 =   Açu-1 --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_253\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "Durante o estágio pós-rift a Bacia Potig[E2] uar passou por [/E2] um período de relativa calmaria tectônica, quando foram depositados os sedimentos    Formação Alagamar, sobrepostos por uma megassequência transgressiva composta       unidades [E1] Açu-1 [/E1], Açu-2, Açu-4 e Jandaíra..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 945\n",
      "Token 1 =   Açu-2 --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_253\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "Durante o estágio pós-rift a Bacia Potig[E2] uar passou por [/E2] um período de relativa calmaria tectônica, quando foram depositados os sedimentos    Formação Alagamar, sobrepostos por uma megassequência transgressiva composta       unidades Açu-1, [E1] Açu-2 [/E1], Açu-4 e Jandaíra..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 945\n",
      "Token 1 =   Açu-4 --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_253\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "Durante o estágio pós-rift a Bacia Potig[E2] uar passou por [/E2] um período de relativa calmaria tectônica, quando foram depositados os sedimentos    Formação Alagamar, sobrepostos por uma megassequência transgressiva composta       unidades Açu-1, Açu-2, [E1] Açu-4 [/E1] e Jandaíra..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 945\n",
      "Token 1 =   Jandaíra --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_158\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "Durante o estágio pós-rift a Bacia Potig[E2] uar passou por [/E2] um período de relativa calmaria tectônica, quando foram depositados os sedimentos    Formação Alagamar, sobrepostos por uma megassequência transgressiva composta       unidades Açu-1, Açu-2, Açu-4 e [E1] Jandaíra [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 950\n",
      "Token 1 =   Formações Ubarana --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_210\n",
      "Token 2 =   basaltos --- Class 2 =  ROCHA --- URI 2 =  #basalt\n",
      "Relation Type =  constituted_by\n",
      ", foram depositados em ambiente - Fegressivo os sedimentos associados    Formações U[E1] barana, Tibau, Gu [/E1]amaré e Barreiras e os [E2] basaltos [/E2]    Formação Macau..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 950\n",
      "Token 1 =   Guamaré --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_003\n",
      "Token 2 =   basaltos --- Class 2 =  ROCHA --- URI 2 =  #basalt\n",
      "Relation Type =  constituted_by\n",
      ", foram depositados em ambiente - Fegressivo os sedimentos associados    Formações Ubarana, Tibau, Guamaré e B[E1] arreira [/E1]s e os [E2] basaltos [/E2]    Formação Macau..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 950\n",
      "Token 1 =   Barreiras --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_016\n",
      "Token 2 =   basaltos --- Class 2 =  ROCHA --- URI 2 =  #basalt\n",
      "Relation Type =  constituted_by\n",
      ", foram depositados em ambiente - Fegressivo os sedimentos associados    Formações Ubarana, Tibau, Guamaré e [E1] Barreiras [/E1] e os [E2] basaltos [/E2]    Formação Macau..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 950\n",
      "Token 1 =   Formação Macau --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_050\n",
      "Token 2 =   basaltos --- Class 2 =  ROCHA --- URI 2 =  #basalt\n",
      "Relation Type =  constituted_by\n",
      ", foram depositados em ambiente - Fegressivo os sedimentos associados    Formações Ubarana, Tibau, Guamaré e Barreiras e os [E2] basaltos [/E2]    [E1] Formação Macau [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 995\n",
      "Token 1 =   Ubarana --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0975\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "CREMONINI, O. A. Caracterização estrutural e evolução tectônica    Área de Ubarana, po[E1] rção su [/E1]bmersa    [E2] Bacia Potiguar [/E2], Brasil..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1057\n",
      "Token 1 =   Formação Ponta Mel --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_278\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "TERRA, G. J. S. Facies, modelo deposicional e diagênese    segiiência carbonática Albo-Cenomaniana ([E1] Formação Ponta    Mel [/E1])    [E2] Bacia Potiguar [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1066\n",
      "Token 1 =   Campo de Pargo --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0760\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "O objetivo, aqui, é promover uma modelagem geológica    escala adequada, incluindo as heterogeneidades inerentes    reservatório, para a compreensão    comportamento de produção de dois reservatórios    [E1] Campo de Pargo [/E1] ([E2] Bacia de Campos [/E2]), com as caracteristicas citadas..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2034\n",
      "Token 1 =   Membro Água Grande --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_125\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "MENEZES, G. M. N. Análise faciológica ambiental e de reservatórios     [E2] arenitos [/E2]    [E1] Membro Água Grande [/E1] Formação Itaparica    Campo de Fazenda Alvorada, Bacia    Recôncavo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2034\n",
      "Token 1 =   Formação Itaparica --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_229\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "MENEZES, G. M. N. Análise faciológica ambiental e de reservatórios     arenitos   [E2]  Membro  [/E2]Água Grande [E1] Formação Itaparica [/E1]    Campo de Fazenda Alvorada, Bacia    Recôncavo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2034\n",
      "Token 1 =   Campo de Fazenda Alvorada --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0403\n",
      "Token 2 =   Bacia Recôncavo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_240\n",
      "Relation Type =  located_in\n",
      "MENEZES, G. M. N. Análise faciológica ambiental e de reservatórios     arenitos    Membro Água Grande Formação Itaparica    [E1] Campo de Fazenda Alvorada [/E1], [E2] Bacia    Recôncavo [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2040\n",
      "Token 1 =   Campo de Namorado --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0734\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "264 p. MENEZES, S. X. Geometria de reservatório    [E1] Campo de Namorado [/E1], [E2] Bacia de Campos [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2167\n",
      "Token 1 =   formações Ponta Grossa --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_157\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "final    Siluriano ou    Devoniano            uma fase de sedimentação marinha, representada       folhelhos c[E2] inza-escu [/E2]ros     [E1] formações Ponta Grossa [/E1], Pimenteiras, Maecuru e Bokkeweld..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2167\n",
      "Token 1 =   Pimenteiras --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_061\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "final    Siluriano ou    Devoniano            uma fase de sedimentação marinha, representada       folhelhos c[E2] inza-escu [/E2]ros     formações Ponta Grossa, [E1] Pimenteiras [/E1], Maecuru e Bokkeweld..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2167\n",
      "Token 1 =   Maecuru --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_246\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "final    Siluriano ou    Devoniano            uma fase de sedimentação marinha, representada       folhelhos c[E2] inza-escu [/E2]ros     formações Ponta Grossa, Pimenteiras, [E1] Maecuru [/E1] e Bokkeweld..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2181\n",
      "Token 1 =   Serraria --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_216\n",
      "Token 2 =   Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Essa área, aparentemente,            positiva e submetida a erosão até o Jurássico Superior, quando se formou a “Depressão Afro-brasileira” (fig. 4), uma calha rasa e alongada onde se depositaram os sedimentos continentais     formações Aliança e Sergi,    Recôncavo, e [E1] Serraria [/E1] em [E2] Alagoas [/E2]/Sergipe, Missão Velha    Araripe, e suas correlatas M’Vone e N’Dombo,    Gabão,    África..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2181\n",
      "Token 1 =   Serraria --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_216\n",
      "Token 2 =   Sergipe --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Essa área, aparentemente,            positiva e submetida a erosão até o Jurássico Superior, quando se formou a “Depressão Afro-brasileira” (fig. 4), uma calha rasa e alongada onde se depositaram os sedimentos continentais     formações Aliança e Sergi,    Recôncavo, e [E1] Serraria [/E1] em Alagoas/[E2] Sergipe [/E2], Missão Velha    Araripe, e suas correlatas M’Vone e N’Dombo,    Gabão,    África..\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "processar_sentencas_filtradas(df_filtred_sentences_treino, \n",
    "                              df_group_treino, \n",
    "                              save_csv_name_bert_treino, \n",
    "                              save_csv_name_relation_treino, \n",
    "                              save_folder_path_treino,\n",
    "                              lista_relacoes_treino, \n",
    "                              lista_uris_treino, \n",
    "                              lista_classes_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "processar_sentencas_filtradas(df_filtred_sentences_valid, \n",
    "                              df_group_valid, \n",
    "                              save_csv_name_bert_valid, \n",
    "                              save_csv_name_relation_valid, \n",
    "                              save_folder_path_valid,\n",
    "                              lista_relacoes_valid, \n",
    "                              lista_uris_valid, \n",
    "                              lista_classes_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "processar_sentencas_filtradas(df_filtred_sentences_teste, \n",
    "                              df_group_teste, \n",
    "                              save_csv_name_bert_teste, \n",
    "                              save_csv_name_relation_teste, \n",
    "                              save_folder_path_teste,\n",
    "                              lista_relacoes_teste, \n",
    "                              lista_uris_teste, \n",
    "                              lista_classes_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Contabilização das relações encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contabilizar(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    for i in range(len(data[0])):\n",
    "        print(data[0][i], ' - ', data[1][i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contabilizar(lista_relacoes_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contabilizar(lista_relacoes_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contabilizar(lista_relacoes_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das classes encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contabilizar(lista_classes_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contabilizar(lista_classes_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contabilizar(lista_classes_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das URIs encontradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "contabilizar(lista_uris_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "contabilizar(lista_uris_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "contabilizar(lista_uris_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação de pares de entidades por tipo de relação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtred = pickle.load(open('df_relation.pkl', 'rb'))\n",
    "#df_relations = pd.read_csv('df_relation.csv')\n",
    "#df_grp = df_relations.groupby('Relation')\n",
    "#relations_groups = df_grp.groups\n",
    "#relations = list(relations_groups)\n",
    "#lista_pares = []\n",
    "#for relation in relations:\n",
    "#    df_rel = df_grp.get_group(relation)\n",
    "#    list_rel = []\n",
    "#    for idx_rel in range(0,len(df_rel)):\n",
    "#        par = df_rel.iloc[idx_rel]['Ent1'] + ' + ' + df_rel.iloc[idx_rel]['Ent2']\n",
    "#        list_rel.append(par)\n",
    "#    lista_pares.append(list_rel)\n",
    "#print('Number of types of relations ->', len(lista_pares))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliar idx_pair de 0 ao tamanho apresentado acima para verificar os pares de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = 0\n",
    "#pares, numb_pares = np.unique(lista_pares[idx], return_counts = True)\n",
    "#print('Relation -> ',relations[idx])\n",
    "#print('Entities pair -> ',pares.tolist())\n",
    "#print('Number of ocorrences -> ',numb_pares.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
