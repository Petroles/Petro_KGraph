{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import operator as op\n",
    "import warnings \n",
    "from owlready2 import * #\n",
    "import random\n",
    "import unicodedata\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar ontologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto_name = \"OntoGeoLogicaPovoadaInstanciasRelacoes\"\n",
    "onto = get_ontology(\"../../KnowledgeGraph/OntoGeoLogicaInstanciasRelacoes.owl\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder_path = \"./JSONs\"\n",
    "save_csv_name = 'df_bert_sentences.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para gerar Jsons a serem lidos no labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultRelationJson(object):\n",
    "    def __init__(self, from_id, to_id, relations, direction = \"right\"):\n",
    "        self.dict = {\n",
    "            \"from_id\": str(from_id),\n",
    "            \"to_id\": str(to_id),\n",
    "            \"type\": \"relation\",\n",
    "            \"direction\": direction,\n",
    "            \"labels\": relations\n",
    "        }\n",
    "    def get_dict(self):\n",
    "        return self.dict\n",
    "    \n",
    "class ResultNERJson(object):\n",
    "    def __init__(self, row):     \n",
    "        self.result_dict = {\n",
    "            \"value\": {\n",
    "            \"start\": row[\"start_word\"],\n",
    "            \"end\": row[\"end_word\"],\n",
    "            \"text\": row[\"word_join\"],\n",
    "            \"labels\": [\n",
    "              row[\"label_word\"]\n",
    "            ],\n",
    "            \"URI\": row[\"URI\"]\n",
    "            },\n",
    "            \n",
    "            \"id\": row[\"index_e\"],\n",
    "            \"from_name\": \"label\",\n",
    "            \"to_name\": \"text\",\n",
    "            \"type\": \"labels\",\n",
    "            \"origin\": \"prediction\"\n",
    "        }\n",
    "    def get_dict(self):\n",
    "        return self.result_dict\n",
    "    \n",
    "    \n",
    "class CreateOutput(object):\n",
    "    def __init__(self, text, filtred_sentence, entity_name_new):\n",
    "        self.filtred_sentence = filtred_sentence\n",
    "        self.entity_name_new = entity_name_new\n",
    "        self.main_dict = {\n",
    "            \"id\": 1,\n",
    "            \"data\": {\n",
    "              \"text\": text #sentenca inteira\n",
    "            },\n",
    "            \"annotations\": []\n",
    "        }\n",
    "        self._add_annotations()\n",
    "        \n",
    "    def _add_annotations(self):\n",
    "        results = []\n",
    "        count = 0        \n",
    "        for index, row in self.entity_name_new.iterrows(): \n",
    "            results.append(ResultNERJson(row).get_dict())        \n",
    "        item = [{\n",
    "              \"id\": 1,\n",
    "              \"created_username\": \" null, 0\",\n",
    "              \"created_ago\": \"\",\n",
    "              \"result\": results\n",
    "            }]\n",
    "        self.main_dict[\"annotations\"] = item\n",
    "    \n",
    "    def get_output(self):\n",
    "        return self.main_dict\n",
    "    \n",
    "    def add_relationship(self, from_id, to_id, relations, direction):\n",
    "        results = self.main_dict.get(\"annotations\")[0].get(\"result\")\n",
    "        relation = ResultRelationJson(from_id, to_id, [relations], direction).get_dict()\n",
    "        results.append(relation)\n",
    "        print('-----------')\n",
    "        print(\"relation\")\n",
    "        print(relation)\n",
    "        self.main_dict[\"annotations\"][0][\"result\"] = results\n",
    "        \n",
    "def combine_itens_from_lists_add_in_json(from_id_vec, to_id_vec, relation_from_vec, output):\n",
    "    for idxRelation in range(0,len(from_id_vec)):\n",
    "            direction = \"right\"\n",
    "            output.add_relationship(from_id=from_id_vec[idxRelation], to_id=to_id_vec[idxRelation], relations = relation_from_vec[idxRelation], direction=direction)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para processar as sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def check_I_entities(df_get_start_end, i,entity):\n",
    "    next_entity_is_I = (df_get_start_end.iloc[i][\"deps\"] == entity) or (df_get_start_end.iloc[i][\"deps\"] == None and df_get_start_end.iloc[i+1][\"deps\"] == entity)\n",
    "    return next_entity_is_I\n",
    "\n",
    "def get_words_by_entities(indexes, df_get_start_end):\n",
    "    df_save_words = pd.DataFrame(columns=['index_e', \"LABEL\", \"START\", \"END\", \"TEXT\", \"word_join\", \"start_word\", \"end_word\", \"label_word\",\"URI\"])\n",
    "    \n",
    "    for index in indexes:\n",
    "        entity = df_get_start_end.iloc[index]['deps']\n",
    "        entity_I = entity.replace(\"B=\",\"I=\")\n",
    "        count = 1\n",
    "        word_join = \"\"\n",
    "        row_main = df_get_start_end.iloc[index]\n",
    "        word_join = \" \".join([word_join, row_main['form']])\n",
    "        start_word = row_main['start']\n",
    "        end_word = row_main['end']\n",
    "        label_word = row_main['deps'].replace(\"B=\", \"\")\n",
    "        URI = df_get_start_end.iloc[index]['misc'].get('grafo')\n",
    "        while index+count != len(df_get_start_end) and (df_get_start_end.iloc[index+count][\"deps\"] == entity_I or check_I_entities(df_get_start_end, index+count,entity_I)):\n",
    "            row = df_get_start_end.iloc[index+count]\n",
    "            word_join = \" \".join([word_join, row['form']])\n",
    "            end_word = row['end']\n",
    "            count+=1\n",
    "\n",
    "        df_save_words.loc[len(df_save_words.index)] = [index, \n",
    "                                                       row_main['deps'],\n",
    "                                                       df_get_start_end.iloc[index]['start'], #so da primeira linha\n",
    "                                                       df_get_start_end.iloc[index]['end'], #so da primeira linha\n",
    "                                                       row_main['form'],\n",
    "                                                       word_join.strip(),\n",
    "                                                       start_word,\n",
    "                                                       end_word,\n",
    "                                                       label_word,\n",
    "                                                       URI]\n",
    "    return df_save_words, word_join\n",
    "\n",
    "def get_relations_between_uris(uri_1, uri_2):\n",
    "    dict_relation_uris = {}\n",
    "    \n",
    "    #Pega as relacoes que a URI1 tem\n",
    "    relation_query_results = list(default_world.sparql(\"\"\"\n",
    "            SELECT DISTINCT ?rel\n",
    "            WHERE{?uri ?rel ?obj\n",
    "                 FILTER(contains(str(?rel), \"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\"))\n",
    "                 FILTER (contains(str(?uri), \"\"\" + '\"' + uri_1 + '\"' + \"\"\"))\n",
    "                 }\n",
    "            \"\"\"))\n",
    "    \n",
    "    relations_str = []\n",
    "    for relation_uris in relation_query_results:\n",
    "        relations_str.append(str(relation_uris[0]).rsplit(\".\",1)[-1])\n",
    "        \n",
    "    # Para cada tipo de relação procura se existe match entre URI1 e URI2\n",
    "    for relation in relations_str:\n",
    "        relation_between_words = list(default_world.sparql(\"\"\"\n",
    "                PREFIX prefix: <http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#>\n",
    "                SELECT distinct ?y ?x2\n",
    "                WHERE{?y prefix:\"\"\" +  relation  +  \"\"\" ?x1\n",
    "\n",
    "                      FILTER (contains(str(?y), \"\"\" + '\"' + uri_1  + '\"' + \"\"\"))        \n",
    "\n",
    "                      ?x2 rdf:type ?j                                   \n",
    "                      FILTER (contains(str(?x2), \"\"\" + '\"' + uri_2  + '\"' + \"\"\"))\n",
    "\n",
    "                      FILTER ( ?x2 = ?x1 )\n",
    "                    }\n",
    "                \"\"\"))\n",
    "        dict_relation_uris[relation] = relation_between_words\n",
    "    return dict_relation_uris\n",
    "\n",
    "def create_relations_dataframe(df_relation,token,token2,URI_1,URI_2,x,originalSentenceNumber):\n",
    "    df_relation_new = pd.DataFrame(columns=['Relation','Ent1','Ent2','URI_1','URI_2','#Sentence'])\n",
    "    df_relation_new.loc[0] = [x,\n",
    "                            token.replace('B=',''),\n",
    "                            token2.replace('B=',''),\n",
    "                            URI_1,\n",
    "                            URI_2,\n",
    "                            originalSentenceNumber]\n",
    "    df_relation = pd.concat([df_relation, df_relation_new])\n",
    "    return df_relation\n",
    "\n",
    "def verifica_pares_entidade_interesse(ENT_1, ENT_2):  \n",
    "    lista_from = ['POÇO','UNIDADE_LITO','UNIDADE_LITO','CAMPO','POÇO','POÇO','UNIDADE_LITO','UNIDADE_LITO']\n",
    "    lista_to = ['UNIDADE_LITO','NÂOCONSOLID','ROCHA','BACIA','BACIA','CAMPO','BACIA','UNIDADE_CRONO']   \n",
    "#     lista_from = ['POÇO','UNIDADE_LITO','UNIDADE_LITO','CAMPO','POÇO','POÇO','UNIDADE_LITO','UNIDADE_CRONO']\n",
    "#     lista_to = ['UNIDADE_LITO','NÂOCONSOLID','ROCHA','BACIA','BACIA','CAMPO','BACIA','UNIDADE_CRONO']      \n",
    "    for idx in range(0,len(lista_to)):\n",
    "        if lista_from[idx] == ENT_1 and lista_to[idx] == ENT_2:\n",
    "            return True  \n",
    "    return False\n",
    "\n",
    "def createText_added_entities(text,df_1,df_2):\n",
    "    start_ent1, end_ent1, = int(df_1.iloc[-1]['start_word']), int(df_1.iloc[-1]['end_word'])\n",
    "    start_ent2, end_ent2 = int(df_2.iloc[-1]['start_word']), int(df_2.iloc[-1]['end_word'])\n",
    "    \n",
    "    Ent1_inic, Ent1_end = '[E1] ', ' [/E1]'\n",
    "    Ent2_inic, Ent2_end = '[E2] ', ' [/E2]'\n",
    "    \n",
    "    if start_ent1 < start_ent2: #[E1] vem antes de [E2]\n",
    "        new_end_ent1 = end_ent1 + len(Ent1_inic)\n",
    "        new_start_ent2 = start_ent2 + len(Ent1_inic) + len(Ent1_end)\n",
    "        new_end_ent2 = end_ent2 + len(Ent1_inic) + len(Ent1_end) + len(Ent2_inic)\n",
    "        \n",
    "        #adicionando [E1] e [/E1]\n",
    "        text_new = text[:start_ent1] + Ent1_inic + text[start_ent1:]\n",
    "        text_new = text_new[:new_end_ent1] + Ent1_end + text_new[new_end_ent1:]\n",
    "        #adicionando [E2] e [/E2]\n",
    "        text_new2 = text_new[:new_start_ent2] + Ent2_inic + text_new[new_start_ent2:]\n",
    "        text_new2 = text_new2[:new_end_ent2] + Ent2_end + text_new2[new_end_ent2:]\n",
    "    \n",
    "    else: #[E2] vem antes de [E1]      \n",
    "        new_end_ent2 = end_ent2 + len(Ent2_inic)\n",
    "        new_start_ent1 = start_ent1 + len(Ent2_inic) + len(Ent2_end)\n",
    "        new_end_ent1 = end_ent1 + len(Ent2_inic) + len(Ent2_end) + len(Ent1_inic)\n",
    "        \n",
    "        #adicionando [E2] e [/E2]\n",
    "        text_new = text[:start_ent2] + Ent2_inic + text[start_ent2:]\n",
    "        text_new = text_new[:new_end_ent2] + Ent2_end + text_new[new_end_ent2:]\n",
    "        #adicionando [E1] e [/E1]\n",
    "        text_new2 = text_new[:new_start_ent1] + Ent1_inic + text_new[new_start_ent1:]\n",
    "        text_new2 = text_new2[:new_end_ent1] + Ent1_end + text_new2[new_end_ent1:]\n",
    "        \n",
    "    return text_new2\n",
    "\n",
    "def print_sentence_text(sentence):\n",
    "    size_sentence = int(sentence.iloc[-1][\"end\"])\n",
    "    text = \" \"*size_sentence\n",
    "    for index, row in sentence.iterrows():\n",
    "        text = text[:int(row[\"start\"])] + row[\"form\"] +text[int(row[\"end\"]):]\n",
    "    print(text)\n",
    "    print(\"-------------\")\n",
    "    return text\n",
    "\n",
    "def create_bert_dataframe(df_bert,idxTokens,idxTokens2,sentence,text,has_relation,relation_type,SentenceNumber):\n",
    "    df_1, wordjoin_1_trash = get_words_by_entities([idxTokens],sentence)\n",
    "    df_2, wordjoin_2_trash = get_words_by_entities([idxTokens2],sentence)\n",
    "    ent1, ent2 = df_1.iloc[-1]['LABEL'], df_2.iloc[-1]['LABEL']\n",
    "    ent1, ent2 = ent1.replace('B=',''), ent2.replace('B=','')\n",
    "    text_bert_ents = createText_added_entities(text,df_1,df_2)\n",
    "#     print(text_bert_ents)\n",
    "    df_bert_temp = pd.DataFrame(columns=['index_e','sentence','Ent1','Ent2','has_relation','relation'])\n",
    "    df_bert_temp.loc[0] = [SentenceNumber,\n",
    "                           text_bert_ents,\n",
    "                           ent1,\n",
    "                           ent2,\n",
    "                           has_relation,\n",
    "                           relation_type]\n",
    "    df_bert = pd.concat([df_bert, df_bert_temp])\n",
    "    return df_bert\n",
    "\n",
    "def saveJsonFiles(df,text,from_id,to_id, lista_relaoces_sentence,sentence,SentenceNum,path):\n",
    "    print(\"-------------\")\n",
    "    print(df.head(50))\n",
    "    print(\"-------------\")\n",
    "    print(\"sentence-> \",SentenceNum)\n",
    "    print(\"-------------\")\n",
    "    print(text)\n",
    "    print(\"-------------\")\n",
    "    print('Saved Json ->', True)\n",
    "    output = CreateOutput(text,sentence, df)\n",
    "    combine_itens_from_lists_add_in_json(from_id, to_id, lista_relacoes_sentence, output)\n",
    "    print(\"-------------\")\n",
    "    with open(os.path.join(path,f\"{SentenceNum}.json\"), \"w\") as outfile: \n",
    "        json.dump(output.get_output(), outfile) \n",
    "        \n",
    "def create_df_JsonFiles(df_entity,x,token,token2,URI_1,URI_2,idxTokens,idxTokens2,from_id,to_id,sentence):\n",
    "    entity_name_new_token1, wordjoin_1 = get_words_by_entities([idxTokens],sentence)\n",
    "    if idxTokens not in from_id and idxTokens not in to_id:\n",
    "        df_entity = pd.concat([df_entity, entity_name_new_token1])\n",
    "    entity_name_new_token2, wordjoin_2 = get_words_by_entities([idxTokens2],sentence)\n",
    "    if idxTokens2 not in from_id and idxTokens2 not in to_id:\n",
    "        df_entity = pd.concat([df_entity, entity_name_new_token2])\n",
    "    print('Token 1 = ', wordjoin_1, '--- Class 1 = ', token.replace('B=',''), '--- URI 1 = ', URI_1)\n",
    "    print('Token 2 = ', wordjoin_2, '--- Class 2 = ', token2.replace('B=',''),'--- URI 2 = ',URI_2)\n",
    "    print('Relation Type = ', x)\n",
    "    print(\"-------------\")\n",
    "    return df_entity\n",
    "    \n",
    "def getDictBert(df,text,lista_relacoes_sentence,from_id,to_id,list_sentences_dict):\n",
    "    sentence_dict = []\n",
    "    list_tokens_dict = []\n",
    "    list_relations_dict = []\n",
    "    document = text\n",
    "    for idxTokenList in range(0,df.shape[0]):\n",
    "        word_join = df.iloc[idxTokenList]['word_join']\n",
    "        start = int(df.iloc[idxTokenList]['start_word'])\n",
    "        end = int(df.iloc[idxTokenList]['end_word'])\n",
    "        token_start = df.iloc[idxTokenList]['index_e'] #filtred_sentence.iloc[5]\n",
    "        token_end = token_start + op.countOf(word_join,\" \")\n",
    "        entity_label = df.iloc[idxTokenList]['LABEL'].replace('B=','')\n",
    "        tokens_dict = {'text': word_join,\n",
    "                       'start': start,\n",
    "                       'end': end,\n",
    "                       'token_start': token_start,\n",
    "                       'token_end': token_end,\n",
    "                       'entity_label': entity_label\n",
    "                      }\n",
    "        list_tokens_dict.append(tokens_dict)\n",
    "    for idxRelList in range(0,len(lista_relacoes_sentence)):\n",
    "        relation_from_id = from_id[idxRelList]\n",
    "        relation_to_id = to_id[idxRelList]\n",
    "        relation_label = lista_relacoes_sentence[idxRelList]\n",
    "        relations_dict = {'child': relation_from_id,\n",
    "                          'head': relation_to_id,\n",
    "                          'relationLabel': relation_label} \n",
    "        list_relations_dict.append(relations_dict)\n",
    "    sentence_dict = {'document': document,\n",
    "                     'tokens': list_tokens_dict,\n",
    "                     'relations': list_relations_dict\n",
    "                    }\n",
    "    list_sentences_dict.append(sentence_dict)\n",
    "    with open('file_sentencasBERT.json', 'w') as fout:\n",
    "        json.dump(list_sentences_dict , fout)\n",
    "        \n",
    "    return list_sentences_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler arquivo csv (ou pkl) com as sentenças pós filtragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero total de sentenças pos-filtragem ->  4542\n"
     ]
    }
   ],
   "source": [
    "df_filtred = pickle.load(open('df_filtred_petroner_uri_2023_04_05.conllu.pkl', 'rb'))\n",
    "#df_filtred = pd.read_csv('df_filtred_petroner_uri_2023_04_05_conllu.csv')\n",
    "df_group = df_filtred.groupby('sentence')\n",
    "print('Numero total de sentenças pos-filtragem -> ',len(df_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotina para processar as sentenças já filtradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 6\n",
      "idx in filtred file = 1\n",
      "Membro Mucuri, Eocretáceo    Bacia    Espirito Santo..\n",
      "-------------\n",
      "Token 1 =   Membro Mucuri --- Class 1 =  UNIDADE_LITO --- URI 1 =  #membro_010\n",
      "Token 2 =   Bacia Espirito Santo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_270\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e           LABEL START END    TEXT             word_join start_word  \\\n",
      "0       0  B=UNIDADE_LITO     0   6  Membro         Membro Mucuri          0   \n",
      "0       4         B=BACIA    29  34   Bacia  Bacia Espirito Santo         29   \n",
      "\n",
      "  end_word    label_word                 URI  \n",
      "0       13  UNIDADE_LITO         #membro_010  \n",
      "0       52         BACIA  #BASE_CD_BACIA_270  \n",
      "-------------\n",
      "sentence->  6\n",
      "-------------\n",
      "Membro Mucuri, Eocretáceo    Bacia    Espirito Santo..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '0', 'to_id': '4', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 36\n",
      "idx in filtred file = 2\n",
      "Ferreira 121 a Expressão de Reativações Pós-intrusão    Enxame de Diques Rio Ceará Mirim (Mesozóico): Implicações Evolução Tectônica    Bacia Potiguar .\n",
      "-------------\n",
      "-------------\n",
      "sentence = 49\n",
      "idx in filtred file = 3\n",
      "Esses conceitos foram inicialmente propostos para bacias marginais marinhas; todavia, seu sucesso foi tão grande, que os mesmos foram ajustados para outras classes de bacias..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 54\n",
      "idx in filtred file = 4\n",
      "Vail et al. (1977) observaram evidências de onlap sobre discordâncias regionais em seções sismicas dip através de bacias de margem passiva..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 66\n",
      "idx in filtred file = 5\n",
      "artigo, o autor propõe as bases que governam a sedimentação siliciclástica em bacias sedimentares: 1) sedimentos siliciclásticos devem ser trazidos até a margem    bacia por sistemas fluviais; 2) o preenchimento de uma bacia é alcançado      repetição de intervalos deposicionais e não-deposicionais; 3) em uma bacia sendo preenchida por sedimentos siliciclásticos, todos os pontos em uma superfície hiatal são diacrônicos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 83\n",
      "idx in filtred file = 6\n",
      "O tectonismo é responsável: 1)      gênese    depressão onde a bacia se instalará; 2)      modelamento    arcabouço estrutural    bacia; 3)      controle     principais sítios de acumulação de sedimentos; 4)      criação de barreiras e rotas preferenciais para entrada de sedimentos    bacia; 5)      controle    relevo    bacia de drenagem..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 84\n",
      "idx in filtred file = 7\n",
      "As flutuações climáticas controlam: 1) o volume de água e de sedimentos que entram    bacia; 2) o tipo de sedimento gerado, seja detrítico, biológico ou quimico; 3) a precipitação pluviométrica e cobertura vegetal..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 94\n",
      "idx in filtred file = 8\n",
      "Durante fases de nível (de base) baixo, fácies grossas             em canais fluviais     margens    bacia, em fan        adjacentes   falha de borda e em        progradantes de pequenas dimensões (fig. 4)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 97\n",
      "idx in filtred file = 9\n",
      "2.2 - Estratigrafia de Sequências    Formação Pendência, Bacia Potiguar  Della Favera et al. (1992) analisam a seção sin-rift    Bacia Potiguar,    qual identificaram quatro sequências balizadas por discordâncias e suas concordâncias relativas dentro    Formação Pendência..\n",
      "-------------\n",
      "Token 1 =   Formação Pendência --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "Token 1 =   Formação Pendência --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "Token 1 =   Formação Pendência --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "Token 1 =   Formação Pendência --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e           LABEL START  END      TEXT           word_join start_word  \\\n",
      "0       5  B=UNIDADE_LITO    37   45  Formação  Formação Pendência         37   \n",
      "0       8         B=BACIA    57   62     Bacia      Bacia Potiguar         57   \n",
      "0      21         B=BACIA   129  134     Bacia      Bacia Potiguar        129   \n",
      "0      36  B=UNIDADE_LITO   254  262  Formação  Formação Pendência        254   \n",
      "\n",
      "  end_word    label_word                 URI  \n",
      "0       55  UNIDADE_LITO       #formacao_319  \n",
      "0       71         BACIA  #BASE_CD_BACIA_100  \n",
      "0      143         BACIA  #BASE_CD_BACIA_100  \n",
      "0      272  UNIDADE_LITO       #formacao_319  \n",
      "-------------\n",
      "sentence->  97\n",
      "-------------\n",
      "2.2 - Estratigrafia de Sequências    Formação Pendência, Bacia Potiguar  Della Favera et al. (1992) analisam a seção sin-rift    Bacia Potiguar,    qual identificaram quatro sequências balizadas por discordâncias e suas concordâncias relativas dentro    Formação Pendência..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '5', 'to_id': '8', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '5', 'to_id': '21', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '36', 'to_id': '8', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '36', 'to_id': '21', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 103\n",
      "idx in filtred file = 10\n",
      "O autor justifica a introdução de nomenclatura nova, pois a existente, criada para bacias marginais marinhas, não abrange, de modo claro, o empilhamento vertical de fácies em uma bacia tectonicamente ativa..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 119\n",
      "idx in filtred file = 11\n",
      "modelo proposto      autor, são discutidos conceitos, apresentada nova terminologia para +ifts intracontinentais, e é aplicado    pacote sin-rift    Bacia    Recôncavo, onde o autor interpreta sistemas deposicionais, áreas-fonte, principais vias de ingresso de sedimentos    bacia e sucessão vertical dentro    que se denominou de tectono-sequência    Cretáceo Inferior    Bacia    Recôncavo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 121\n",
      "idx in filtred file = 12\n",
      "2.4 - Modelo de Prosser  Prosser (1993) reconhece a influência    tectonismo tanto    distribuição espacial como    evolução temporal de sistemas deposicionais presentes em bacias limitadas por falhamentos ativos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 141\n",
      "idx in filtred file = 13\n",
      "longo de margens divergentes, discordâncias regionais separam rochas depositadas sob diferentes regimes tectônicos (Uchupi e Emery, 1991)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 142\n",
      "idx in filtred file = 14\n",
      "As discordâncias    início    rift (rift onset unconformity, Falvey, 1974) e    separação continental (breakup unconformity, Falvey, 1974), reconhecidas em diferentes bacias rift    mundo, assinalam importantes mudangas de fases tectônicas, que resultam    evolução de placas litosféricas    longo    tempo geológico..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 143\n",
      "idx in filtred file = 15\n",
      "As sequências balizadas por discordâncias, conforme definidas por Sloss para bacias intracratônicas (Sloss, 1963; 1988), representam outro exemplo de discordâncias regionais que limitam pacotes sedimentares..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 147\n",
      "idx in filtred file = 16\n",
      "A análise sismoestratigráfica de bacias marginais marinhas parte    reconhecimento     superfícies erosionais de caráter regional e de suas concordâncias relativas, ou seja, a superfície erosional é reconhecida em áreas mais rasas e traçada em direção    talude/planicie abissal     bacias..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 149\n",
      "idx in filtred file = 17\n",
      "a mesma metodologia para a análise de bacias    tipo rift,         , inicialmente, buscar as discordâncias    margem flexural    riff e           em direção    depocentro    bacia..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 151\n",
      "idx in filtred file = 18\n",
      "Qual superficie erosiva representa o limite entre padrões sísmicos diferentes, associados a importantes mudanças    binômio bacia de drenagem/bacia deposicional?\n",
      "-------------\n",
      "-------------\n",
      "sentence = 153\n",
      "idx in filtred file = 19\n",
      "O intérprete deve ficar atento a essas peculiaridades, pois,       caso, a concordância relativa Finalizando, é importante observar que, durante fases de inundação    superfície de uma bacia, o aporte sedimentar é mínimo, e,     margens       bacia, erosões ou superfícies    tipo ravinamento são passíveis de ocorrer (Galloway, 1989, Swift et al. 1991)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 157\n",
      "idx in filtred file = 20\n",
      "O Novo Dicionário Aurélio    Lingua Portuguesa (Ferreira, 1986) define eustasia como variação    nível     mares, causada      aumento    quantidade de água (degelo     pólos), ou por motivos tectônicos    fundo    mar, ou      acúmulo progressivo de sedimentos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 180\n",
      "idx in filtred file = 21\n",
      "Della Fávera ef al. (1992), entretanto,    tentarem utilizar essa mesma terminologia para a análise    Formação Pendência (Bacia Potiguar), acabaram traduzindo esses termos de modo diferente..\n",
      "-------------\n",
      "Token 1 =   Formação Pendência --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e           LABEL START  END      TEXT           word_join start_word  \\\n",
      "0      18  B=UNIDADE_LITO   103  111  Formação  Formação Pendência        103   \n",
      "0      21         B=BACIA   123  128     Bacia      Bacia Potiguar        123   \n",
      "\n",
      "  end_word    label_word                 URI  \n",
      "0      121  UNIDADE_LITO       #formacao_319  \n",
      "0      137         BACIA  #BASE_CD_BACIA_100  \n",
      "-------------\n",
      "sentence->  180\n",
      "-------------\n",
      "Della Fávera ef al. (1992), entretanto,    tentarem utilizar essa mesma terminologia para a análise    Formação Pendência (Bacia Potiguar), acabaram traduzindo esses termos de modo diferente..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '18', 'to_id': '21', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 210\n",
      "idx in filtred file = 22\n",
      "Condições variáveis dentro de cada um     sistemas de nível (de base) controlam o desenvolvimento de rocha-reservatório, gerador, selo e estrutura, elementos essenciais para a ocorrência de jazidas de petróleo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 234\n",
      "idx in filtred file = 23\n",
      "DELLA FÁVERA, J. C., ROSSETI, E. L., GUZZO, J. MATSUDA, N., SOARES, V. M., HASHIMOTO, A. T. ALVES, D. B., CASTRO, J. C., AZAMBUJA, N. C. RODRIGUES, R. Estratigrafa de seqliéncias de Formação Pendéncia, Bacia Potiguar..\n",
      "-------------\n",
      "Token 1 =   Formação Pendéncia --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_319\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e           LABEL START  END      TEXT           word_join start_word  \\\n",
      "0      48  B=UNIDADE_LITO   182  190  Formação  Formação Pendéncia        182   \n",
      "0      51         B=BACIA   202  207     Bacia      Bacia Potiguar        202   \n",
      "\n",
      "  end_word    label_word                 URI  \n",
      "0      200  UNIDADE_LITO       #formacao_319  \n",
      "0      216         BACIA  #BASE_CD_BACIA_100  \n",
      "-------------\n",
      "sentence->  234\n",
      "-------------\n",
      "DELLA FÁVERA, J. C., ROSSETI, E. L., GUZZO, J. MATSUDA, N., SOARES, V. M., HASHIMOTO, A. T. ALVES, D. B., CASTRO, J. C., AZAMBUJA, N. C. RODRIGUES, R. Estratigrafa de seqliéncias de Formação Pendéncia, Bacia Potiguar..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '48', 'to_id': '51', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 329\n",
      "idx in filtred file = 24\n",
      "Porém este número não significa que os sedimentos cretáceos marinhos de qualquer bacia    margem brasileira possam ser subdivididos em,    máximo, 12 intervalos bioestratigraficos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 338\n",
      "idx in filtred file = 25\n",
      "que compõem o volume Bioestratigrafia     Bacias Mesozóicas-Cenozóicas Brasileiras, editado por Beurlen et al. (1992)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 350\n",
      "idx in filtred file = 26\n",
      "Cronoestratigrafia: Alagoas (parte superior), o qu corresponde, aproximadamente,   porção basal d Albiano (Beurlen et al. 1992)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 351\n",
      "idx in filtred file = 27\n",
      "Observações:  1.a biozona foi originalmente definida em depósitos    Bacia de Sergipe/Alagoas (testemunhos    poço 7-BRG-12-SE), por Beurlen et al (1987)..\n",
      "-------------\n",
      "Token 1 =   poço 7-BRG-12-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007553\n",
      "Token 2 =   Bacia de Sergipe/Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e    LABEL START  END   TEXT                 word_join start_word  \\\n",
      "0      14   B=POÇO   110  114   poço          poço 7-BRG-12-SE        110   \n",
      "0       9  B=BACIA    69   74  Bacia  Bacia de Sergipe/Alagoas         69   \n",
      "\n",
      "  end_word label_word                   URI  \n",
      "0      126       POÇO  #POCO_CD_POCO_007553  \n",
      "0       93      BACIA    #BASE_CD_BACIA_116  \n",
      "-------------\n",
      "sentence->  351\n",
      "-------------\n",
      "Observações:  1.a biozona foi originalmente definida em depósitos    Bacia de Sergipe/Alagoas (testemunhos    poço 7-BRG-12-SE), por Beurlen et al (1987)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '14', 'to_id': '9', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 357\n",
      "idx in filtred file = 28\n",
      "Como esta zona passou a ser registrada em poços de mais de uma bacia, a biounidade Nannoconus quadriangulus apertus caiu em desuso..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 364\n",
      "idx in filtred file = 29\n",
      "Cronoestratigrafia: Albiano, podendo, entretanto, englobar parte    Aptiano..\n",
      "-------------\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  interval_met_by\n",
      "-------------\n",
      "Token 1 =   Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  interval_meets\n",
      "-------------\n",
      "-------------\n",
      "  index_e            LABEL START END     TEXT word_join start_word end_word  \\\n",
      "0       2  B=UNIDADE_CRONO    20  27  Albiano   Albiano         20       27   \n",
      "0      10  B=UNIDADE_CRONO    68  75  Aptiano   Aptiano         68       75   \n",
      "\n",
      "      label_word      URI  \n",
      "0  UNIDADE_CRONO  #Albian  \n",
      "0  UNIDADE_CRONO  #Aptian  \n",
      "-------------\n",
      "sentence->  364\n",
      "-------------\n",
      "Cronoestratigrafia: Albiano, podendo, entretanto, englobar parte    Aptiano..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '2', 'to_id': '10', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '10', 'to_id': '2', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 367\n",
      "idx in filtred file = 30\n",
      "Cunha (1990a, b) poderia        valido para individualizar seu limite inferior    primeira ocorrência    espécie nominativa, o que a caracterizaria como uma zona de amplitude; 2. a biozona Nannoconus fragilis foi definida    Bacia    Ceará, tendo sido reconhecida posteriormente em alguns poços de Sergipe/Alagoas e Potiguar..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 368\n",
      "idx in filtred file = 31\n",
      "Embora verificada        bacias, ainda não foi formalmente incorporada     zoneamentos de Ceará e Potiguar (Viviers et al. 1992a, b; in Beurlen et al. 1992)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 376\n",
      "idx in filtred file = 32\n",
      "certas ocorrências    Zona Nannoconus fragilis    Bacia    Ceará, quando comparadas    informações bioestratigráficas de foraminíferos e palinomorfos, sugerem que      menos sua parte superior seja de idade albiana..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 377\n",
      "idx in filtred file = 33\n",
      "poço 1-CES-112, por exemplo,              que o limite superior    biozona de nanofósseis ocorre em estratos neoalbianos a eocenomanianos..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 380\n",
      "idx in filtred file = 34\n",
      "entanto, Trôelsen e Quadros (1971) já haviam fotografado - alguns de seus - exemplares (Bacia de Sergipe/Alagoas, poço 7-BRG-12-SE)..\n",
      "-------------\n",
      "Token 1 =   poço 7-BRG-12-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007553\n",
      "Token 2 =   Bacia de Sergipe/Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e    LABEL START  END   TEXT                 word_join start_word  \\\n",
      "0      22   B=POÇO   114  118   poço          poço 7-BRG-12-SE        114   \n",
      "0      18  B=BACIA    88   93  Bacia  Bacia de Sergipe/Alagoas         88   \n",
      "\n",
      "  end_word label_word                   URI  \n",
      "0      130       POÇO  #POCO_CD_POCO_007553  \n",
      "0      112      BACIA    #BASE_CD_BACIA_116  \n",
      "-------------\n",
      "sentence->  380\n",
      "-------------\n",
      "entanto, Trôelsen e Quadros (1971) já haviam fotografado - alguns de seus - exemplares (Bacia de Sergipe/Alagoas, poço 7-BRG-12-SE)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '22', 'to_id': '18', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 382\n",
      "idx in filtred file = 35\n",
      "Em termos ¢ronoestratigraficos, entretanto, Freitas et al. (op. cit.), preferiram não firmar posição quanto    andar em que as tais associações estavam inseridas,              a afirmar que as espécies reconhecidas não eram suficientes para distinguir o Aptiano    Albiano..\n",
      "-------------\n",
      "Token 1 =   Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  interval_meets\n",
      "-------------\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  interval_met_by\n",
      "-------------\n",
      "-------------\n",
      "  index_e            LABEL START  END     TEXT word_join start_word end_word  \\\n",
      "0      41  B=UNIDADE_CRONO   254  261  Aptiano   Aptiano        254      261   \n",
      "0      42  B=UNIDADE_CRONO   265  272  Albiano   Albiano        265      272   \n",
      "\n",
      "      label_word      URI  \n",
      "0  UNIDADE_CRONO  #Aptian  \n",
      "0  UNIDADE_CRONO  #Albian  \n",
      "-------------\n",
      "sentence->  382\n",
      "-------------\n",
      "Em termos ¢ronoestratigraficos, entretanto, Freitas et al. (op. cit.), preferiram não firmar posição quanto    andar em que as tais associações estavam inseridas,              a afirmar que as espécies reconhecidas não eram suficientes para distinguir o Aptiano    Albiano..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '41', 'to_id': '42', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '42', 'to_id': '41', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 395\n",
      "idx in filtred file = 36\n",
      "Em face     problemas mencionados,             que a delimitação entre os andares Aptiano e Albiano, com base em exemplares    gênero Nannoconus, seja uma tarefa difícil..\n",
      "-------------\n",
      "Token 1 =   andares Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  interval_meets\n",
      "-------------\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   andares Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  interval_met_by\n",
      "-------------\n",
      "-------------\n",
      "  index_e            LABEL START END     TEXT        word_join start_word  \\\n",
      "0      10  B=UNIDADE_CRONO    74  81  andares  andares Aptiano         74   \n",
      "0      13  B=UNIDADE_CRONO    92  99  Albiano          Albiano         92   \n",
      "\n",
      "  end_word     label_word      URI  \n",
      "0       89  UNIDADE_CRONO  #Aptian  \n",
      "0       99  UNIDADE_CRONO  #Albian  \n",
      "-------------\n",
      "sentence->  395\n",
      "-------------\n",
      "Em face     problemas mencionados,             que a delimitação entre os andares Aptiano e Albiano, com base em exemplares    gênero Nannoconus, seja uma tarefa difícil..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '10', 'to_id': '13', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '13', 'to_id': '10', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 400\n",
      "idx in filtred file = 37\n",
      "Contudo, a associação    biozona Nannoconus fragilis não foi registrada, até hoje,     carbonatos cretáceos     bacias mais investigadas    margem sudeste (Santos, Campos e Espirito Santo)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 401\n",
      "idx in filtred file = 38\n",
      "bacias, os carbonatos pertencem, quase sempre,   biozona Nannoconus truitti (descrita a seguir), e a nanoflora observada geralmente é - - pobre..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 408\n",
      "idx in filtred file = 39\n",
      "Contudo, a associação    biozona Nannoconus fragilis não foi registrada, até hoje,     carbonatos cretáceos     bacias mais investigadas    margem sudeste (Santos, Campos e Espírito Santo)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 409\n",
      "idx in filtred file = 40\n",
      "bacias, os carbonatos pertencem, quase sempre, a biozona Nannoconus truitti (descrita a seguir), e a nanoflora observada geralmente é :- - pobre..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 413\n",
      "idx in filtred file = 41\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato intra-albiano, correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n",
      "Token 1 =   intra-albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  interval_met_by\n",
      "-------------\n",
      "Token 1 =   intra-albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  interval_met_by\n",
      "-------------\n",
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   intra-albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  interval_meets\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 371\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  participates_in\n",
      "-------------\n",
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   intra-albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  interval_meets\n",
      "-------------\n",
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  participates_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e            LABEL START   END           TEXT      word_join  \\\n",
      "0      23  B=UNIDADE_CRONO   162   175  intra-albiano  intra-albiano   \n",
      "0      99  B=UNIDADE_CRONO   676   684       aptianos       aptianos   \n",
      "0     185  B=UNIDADE_CRONO  1229  1237       aptianos       aptianos   \n",
      "\n",
      "  start_word end_word     label_word      URI  \n",
      "0        162      175  UNIDADE_CRONO  #Albian  \n",
      "0        676      684  UNIDADE_CRONO  #Aptian  \n",
      "0       1229     1237  UNIDADE_CRONO  #Aptian  \n",
      "-------------\n",
      "sentence->  413\n",
      "-------------\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato intra-albiano, correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '23', 'to_id': '99', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '23', 'to_id': '185', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '99', 'to_id': '23', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '99', 'to_id': '185', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '185', 'to_id': '23', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '185', 'to_id': '99', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 415\n",
      "idx in filtred file = 42\n",
      "De acordo com os arcabouços bioestratigráficos elaborados    partir de outros grupos fósseis (palinomorfos, principalmente), o Albiano,    margem sudeste, é dividido em duas ou mais biozonas e as investigações não sugerem a existência de qualquer hiato intra-albiano de grande expressão geográfica (Azevedo et al. 1987a; Viviers et al. 1986; Oliveira et al. 1993)..\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 368\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   intra-albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  participates_in\n",
      "-------------\n",
      "Token 1 =   intra-albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  participates_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e            LABEL START  END           TEXT      word_join  \\\n",
      "0      19  B=UNIDADE_CRONO   127  134        Albiano        Albiano   \n",
      "0      41  B=UNIDADE_CRONO   253  266  intra-albiano  intra-albiano   \n",
      "\n",
      "  start_word end_word     label_word      URI  \n",
      "0        127      134  UNIDADE_CRONO  #Albian  \n",
      "0        253      266  UNIDADE_CRONO  #Albian  \n",
      "-------------\n",
      "sentence->  415\n",
      "-------------\n",
      "De acordo com os arcabouços bioestratigráficos elaborados    partir de outros grupos fósseis (palinomorfos, principalmente), o Albiano,    margem sudeste, é dividido em duas ou mais biozonas e as investigações não sugerem a existência de qualquer hiato intra-albiano de grande expressão geográfica (Azevedo et al. 1987a; Viviers et al. 1986; Oliveira et al. 1993)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '19', 'to_id': '41', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '41', 'to_id': '19', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 422\n",
      "idx in filtred file = 43\n",
      "É sabido; por exemplo, que a porção superior    Formação Macaé (Albiano/Turoniano    Bacia de (Campos) encerra níveis ricos em nanofósseis, observáveis somente com o auxílio    microscópio eletrônico de varredura (MEV, Spadini et al. 1988)..\n",
      "-------------\n",
      "Token 1 =   Formação Macaé --- Class 1 =  UNIDADE_LITO --- URI 1 =  #grupo_000\n",
      "Token 2 =   Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e           LABEL START  END      TEXT       word_join start_word  \\\n",
      "0      10  B=UNIDADE_LITO    48   56  Formação  Formação Macaé         48   \n",
      "0      17         B=BACIA    95  101    Campos          Campos         95   \n",
      "\n",
      "  end_word    label_word                 URI  \n",
      "0       62  UNIDADE_LITO          #grupo_000  \n",
      "0      101         BACIA  #BASE_CD_BACIA_281  \n",
      "-------------\n",
      "sentence->  422\n",
      "-------------\n",
      "É sabido; por exemplo, que a porção superior    Formação Macaé (Albiano/Turoniano    Bacia de (Campos) encerra níveis ricos em nanofósseis, observáveis somente com o auxílio    microscópio eletrônico de varredura (MEV, Spadini et al. 1988)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '10', 'to_id': '17', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 429\n",
      "idx in filtred file = 44\n",
      "E a maioria tende a reconhecer, a partir    comparação de associações fossiliferas, que tal contato        entre o Aptiano e o Cenomaniano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 432\n",
      "idx in filtred file = 45\n",
      "Entretanto, deve ser comentado que Dias-Brito (1994) sugere que esta circulação, já em tempos eoalbianos, seria mais abrangente e atingiria a Bacia de B. Geoci..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 440\n",
      "idx in filtred file = 46\n",
      "1. - Trôelsen e Quadros (1971),    definirem a biozona, preferiram nao separar as associações de Nannoconus que se sucedem     seções estratigráficas    Cretáceo “médio”     bacias marginais brasileiras (principalmente aquelas situadas    norte de Sergipe/Alagoas)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 447\n",
      "idx in filtred file = 47\n",
      "em sua concepção original, Trdelsen e Quadros (1971) haviam proposto para a Zona Nannoconus truitti o intervalo aptiano (parte superior)/cenomaniano (parte basal), sobretudo com base em investigações feitas    Bacia de Sergipe/Alagoas..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 451\n",
      "idx in filtred file = 48\n",
      "- Trôelsen e Quadros (1971),    definirem a biozona, preferiram nao separar as associações de Nannoconus que se sucedem     seções estratigráficas    Cretáceo “médio”     bacias marginais brasileiras (principalmente aquelas situadas    norte de Sergipe/Alagoas)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 455\n",
      "idx in filtred file = 49\n",
      "Aliás, esta observação foi o principal fator em que Cunha (1990a, b) se baseou para definir a Zona Nannoconus fragilis; Por outro lado, Wanderley (1987, 1988), em estudos referentes   Bacia Potiguar, considerou que o topo    Zona Nannoconus truitti seria um __ biorizonte mesocenomaniano, posicionado entre as últimas ocorrências     pólens Psilatricolpites papilioniformis (Regali et al.) e Gnetaceaepollenites diversus Stover, e abaixo    desaparecimento    foraminifero Rotalipora aff..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 457\n",
      "idx in filtred file = 50\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração 1-US-1-SE    Bacia de Sergipe/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "Token 1 =   poço 1-CES-75 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_012996\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Bacia de Sergipe --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e    LABEL START  END       TEXT         word_join start_word  \\\n",
      "0      19   B=POÇO   111  115       poço     poço 1-CES-75        111   \n",
      "0       0  B=BACIA     0    5      Bacia       Bacia Ceará          0   \n",
      "0      30   B=POÇO   174  183  1-US-1-SE         1-US-1-SE        174   \n",
      "0      31  B=BACIA   187  192      Bacia  Bacia de Sergipe        187   \n",
      "0      35  B=BACIA   204  211    Alagoas           Alagoas        204   \n",
      "\n",
      "  end_word label_word                   URI  \n",
      "0      124       POÇO  #POCO_CD_POCO_012996  \n",
      "0       14      BACIA    #BASE_CD_BACIA_096  \n",
      "0      183       POÇO  #POCO_CD_POCO_010471  \n",
      "0      203      BACIA    #BASE_CD_BACIA_116  \n",
      "0      211      BACIA    #BASE_CD_BACIA_116  \n",
      "-------------\n",
      "sentence->  457\n",
      "-------------\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração 1-US-1-SE    Bacia de Sergipe/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '19', 'to_id': '0', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '30', 'to_id': '31', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '30', 'to_id': '35', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 459\n",
      "idx in filtred file = 51\n",
      "Como ja abordado por Antunes (1987, 1990), a extinção    gênero Nannoconus     bacias    costa brasileira parece estar vinculada a fenômenos ecológicos, pois, de acordo com Déres e Achéritéguy (1980), a ocorrência       taxon, mais abundante e diversificado    Cretáceo Inferior, parece        estendido até o Campaniano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 460\n",
      "idx in filtred file = 52\n",
      "Provavelmente, tais fenômenos ecológicos estariam diretamente relacionados   mudança climática postulada por Dias-Brito (1987) e Viviers e Regali (1987), em investigações referentes    bacias de Campos e Potiguar, respectivamente..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 462\n",
      "idx in filtred file = 53\n",
      "A causa       mudança estaria associada    aumento    volume de água    Atlântico Sul, em decorrência de seu crescente contato com massas de água     oceanos posicionados    sul e    norte (Dias-Brito, op. cit.)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 464\n",
      "idx in filtred file = 54\n",
      "Por outro lado, Wanderley (1987, 1988), em estudos referentes   Bacia Potiguar, considerou que o topo    Zona Nannoconus truitti seria um __ biorizonte mesocenomaniano, posicionado entre as últimas ocorrências     pólens Psilatricolpites papilioniformis (Regali et al.) e Gnetaceaepollenites diversus Stover, e abaixo    desaparecimento    foraminifero Rotalipora aff..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 466\n",
      "idx in filtred file = 55\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração 1-US-1-SE    Bacia de Sergipe/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "Token 1 =   poço 1-CES-75 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_012996\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Bacia de Sergipe --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "-------------\n",
      "-------------\n",
      "  index_e    LABEL START  END       TEXT         word_join start_word  \\\n",
      "0      19   B=POÇO   111  115       poço     poço 1-CES-75        111   \n",
      "0       0  B=BACIA     0    5      Bacia       Bacia Ceará          0   \n",
      "0      30   B=POÇO   174  183  1-US-1-SE         1-US-1-SE        174   \n",
      "0      31  B=BACIA   187  192      Bacia  Bacia de Sergipe        187   \n",
      "0      35  B=BACIA   204  211    Alagoas           Alagoas        204   \n",
      "\n",
      "  end_word label_word                   URI  \n",
      "0      124       POÇO  #POCO_CD_POCO_012996  \n",
      "0       14      BACIA    #BASE_CD_BACIA_096  \n",
      "0      183       POÇO  #POCO_CD_POCO_010471  \n",
      "0      203      BACIA    #BASE_CD_BACIA_116  \n",
      "0      211      BACIA    #BASE_CD_BACIA_116  \n",
      "-------------\n",
      "sentence->  466\n",
      "-------------\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração 1-US-1-SE    Bacia de Sergipe/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '19', 'to_id': '0', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '30', 'to_id': '31', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '30', 'to_id': '35', 'type': 'relation', 'direction': 'right', 'labels': ['located_in']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 467\n",
      "idx in filtred file = 56\n",
      "\"  \" “testémunho”       poço, ” exemplares ~ de Nannoconus truitti sl. ocorrem em associação com foraminiferos planctônicos, interpretados por Koutsoukos (1989) como característicos    Turoniano (Zona Hedbergella (Whiteinella) archaeocretacea-Heteroelix reussi(T1) de Koutsoukos op. cit)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 471\n",
      "idx in filtred file = 57\n",
      "Iniciada    parte sul    costa brasileira, próximo    término do-Albiano, esta mudança teria migrado, gradativamente, para norte, atingindo as bacias de Sergipe/Alagoas, Potiguar e    Ceará somente em tempos cenomanianos/turonianos..\n",
      "-------------\n",
      "Token 1 =   cenomanianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   turonianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Turonian\n",
      "Relation Type =  interval_meets\n",
      "-------------\n",
      "Token 1 =   turonianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Turonian\n",
      "Token 2 =   cenomanianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  interval_met_by\n",
      "-------------\n",
      "-------------\n",
      "  index_e            LABEL START  END          TEXT     word_join start_word  \\\n",
      "0      33  B=UNIDADE_CRONO   208  220  cenomanianos  cenomanianos        208   \n",
      "0      35  B=UNIDADE_CRONO   221  231    turonianos    turonianos        221   \n",
      "\n",
      "  end_word     label_word          URI  \n",
      "0      220  UNIDADE_CRONO  #Cenomanian  \n",
      "0      231  UNIDADE_CRONO    #Turonian  \n",
      "-------------\n",
      "sentence->  471\n",
      "-------------\n",
      "Iniciada    parte sul    costa brasileira, próximo    término do-Albiano, esta mudança teria migrado, gradativamente, para norte, atingindo as bacias de Sergipe/Alagoas, Potiguar e    Ceará somente em tempos cenomanianos/turonianos..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '33', 'to_id': '35', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '35', 'to_id': '33', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 472\n",
      "idx in filtred file = 58\n",
      "Assim, o desaparecimento total     espécies de Nannoconus teria ocorrido primeiramente     bacias    margem sudeste, e posteriormente     bacias de Sergipe/Alagoas, Potiguar e Ceara, como observado, respectivamente, por Trôelsen e Quadros (1971), Wanderley (1987, 1988) e Cunha (1990a); 4. a ocorrência     zonas tipificadas por exemplares de nanoconídeos parecem ter forte conotação ambiental..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 476\n",
      "idx in filtred file = 59\n",
      "De fato, o emprego    Zona Nannoconus truitti s..     bacias de Sergipe/Alagoas, Potiguar e Ceará pode acarretar problemas cronoestratigráficos, já que o diacronismo verificado para seu limite superior é mais pronunciado..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 478\n",
      "idx in filtred file = 60\n",
      "Em contrapartida,     bacias de Campos e Espírito Santo, até o momento, não foi observado qualquer diacronismo flagrante para o topo    zona e, também, não se dispõe de outra espécie fóssil capaz de substituir, com características cronoestratigraficas melhores, Nannoconus truitti sl..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 480\n",
      "idx in filtred file = 61\n",
      "sítio sedimentar, raros exemplares de Nannoconus truitti têm sido observados     estratos basais    Formação Itajaí (folhelhos e margas) que jazem imediatamente acima    Formação Guarujá (carbonatos)..\n",
      "-------------\n",
      "Token 1 =   Formação Itajaí --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_163\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "-------------\n",
      "Token 1 =   Formação Itajaí --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_163\n",
      "Token 2 =   margas --- Class 2 =  ROCHA --- URI 2 =  #marlstone\n",
      "Relation Type =  constituted_by\n",
      "-------------\n",
      "Token 1 =   Formação Guarujá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_166\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "-------------\n",
      "Token 1 =   Formação Guarujá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_166\n",
      "Token 2 =   margas --- Class 2 =  ROCHA --- URI 2 =  #marlstone\n",
      "Relation Type =  constituted_by\n",
      "-------------\n",
      "-------------\n",
      "  index_e           LABEL START  END       TEXT         word_join start_word  \\\n",
      "0      13  B=UNIDADE_LITO   100  108   Formação   Formação Itajaí        100   \n",
      "0      16         B=ROCHA   117  126  folhelhos         folhelhos        117   \n",
      "0      18         B=ROCHA   129  135     margas            margas        129   \n",
      "0      24  B=UNIDADE_LITO   170  178   Formação  Formação Guarujá        170   \n",
      "\n",
      "  end_word    label_word            URI  \n",
      "0      115  UNIDADE_LITO  #formacao_163  \n",
      "0      126         ROCHA         #shale  \n",
      "0      135         ROCHA     #marlstone  \n",
      "0      186  UNIDADE_LITO  #formacao_166  \n",
      "-------------\n",
      "sentence->  480\n",
      "-------------\n",
      "sítio sedimentar, raros exemplares de Nannoconus truitti têm sido observados     estratos basais    Formação Itajaí (folhelhos e margas) que jazem imediatamente acima    Formação Guarujá (carbonatos)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '13', 'to_id': '16', 'type': 'relation', 'direction': 'right', 'labels': ['constituted_by']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '13', 'to_id': '18', 'type': 'relation', 'direction': 'right', 'labels': ['constituted_by']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '24', 'to_id': '16', 'type': 'relation', 'direction': 'right', 'labels': ['constituted_by']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '24', 'to_id': '18', 'type': 'relation', 'direction': 'right', 'labels': ['constituted_by']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 482\n",
      "idx in filtred file = 62\n",
      "Se o desaparecimento       taxon             vinculado a uma mudança climática (obs. 3), que se deu gradativamente de sul para norte, o mesmo não deveria ter os últimos registros     depósitos cenomanianos    Bacia de Santos, e albianos     bacias de Campos e Espírito Santo..\n",
      "-------------\n",
      "Token 1 =   cenomanianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   albianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  interval_met_by\n",
      "-------------\n",
      "Token 1 =   albianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   cenomanianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  interval_meets\n",
      "-------------\n",
      "-------------\n",
      "  index_e            LABEL START  END          TEXT     word_join start_word  \\\n",
      "0      32  B=UNIDADE_CRONO   193  205  cenomanianos  cenomanianos        193   \n",
      "0      38  B=UNIDADE_CRONO   228  236      albianos      albianos        228   \n",
      "\n",
      "  end_word     label_word          URI  \n",
      "0      205  UNIDADE_CRONO  #Cenomanian  \n",
      "0      236  UNIDADE_CRONO      #Albian  \n",
      "-------------\n",
      "sentence->  482\n",
      "-------------\n",
      "Se o desaparecimento       taxon             vinculado a uma mudança climática (obs. 3), que se deu gradativamente de sul para norte, o mesmo não deveria ter os últimos registros     depósitos cenomanianos    Bacia de Santos, e albianos     bacias de Campos e Espírito Santo..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '32', 'to_id': '38', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-----------\n",
      "relation\n",
      "{'from_id': '38', 'to_id': '32', 'type': 'relation', 'direction': 'right', 'labels': ['temporal_relation']}\n",
      "-------------\n",
      "-------------\n",
      "sentence = 483\n",
      "idx in filtred file = 63\n",
      "Assim, esta incoerência induz a formulação de duas hipóteses: b) ou os pontos de controle (poços)     Bacias de Campos e Espirito Santo - em que o desaparecimento de Nannoconus truitti s.l..\n",
      "-------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20412\\2681250223.py\u001b[0m in \u001b[0;36mget_relations_between_uris\u001b[1;34m(uri_1, uri_2)\u001b[0m\n\u001b[0;32m     46\u001b[0m                  \u001b[0mFILTER\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0;31m?\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\" + '\"' + uri_1 + '\"' + \"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                  }\n\u001b[1;32m---> 48\u001b[1;33m             \"\"\"))\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mrelations_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Petro_KGraph\\lib\\site-packages\\owlready2\\sparql\\main.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPreparedSelectQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPreparedQuery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPreparedQuery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m       \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m       \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\Petro_KGraph\\lib\\site-packages\\owlready2\\sparql\\main.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[0msql_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_rdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameter_datatypes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msql_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_rdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPreparedSelectQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPreparedQuery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numberSentences = df_filtred.iloc[-1]['sentence'] #numero de sentencas diferentes no arquivo ja filtrado\n",
    "\n",
    "lista_relacoes, lista_uris, lista_classes, list_sentences_dict = [], [], [], []\n",
    "\n",
    "df_relation, df_bert = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "countJsons=0\n",
    "for idx in range(1,len(df_group)):\n",
    "    filtred_sentence = df_group.get_group(idx)#aqui filtred_sentence é um dataframe da sentenca\n",
    "    originalSentenceNumber = filtred_sentence.iloc[0]['#sentence_original']\n",
    "    print(\"-------------\")\n",
    "    print('sentence =', originalSentenceNumber)\n",
    "    print('idx in filtred file =', idx)   \n",
    "    text = print_sentence_text(filtred_sentence)\n",
    "    \n",
    "    df_entity = pd.DataFrame()\n",
    "    from_id, to_id = [], []\n",
    "    relation_from, relation_to = [], []\n",
    "    lista_relacoes_sentence = []\n",
    "    is_to_save = False #se cada sentenca vai ser salva ao fim de seu processamento\n",
    "    df_bert.to_csv(save_csv_name, encoding='utf-8',index=False)\n",
    "    for idxTokens in range(0,len(filtred_sentence)):\n",
    "        token = filtred_sentence.iloc[idxTokens]['deps']     \n",
    "        if \"B=\" in token and filtred_sentence.iloc[idxTokens]['misc'].get('grafo'): #encontrou o comeco de uma entidade com URI\n",
    "            URI_1 = filtred_sentence.iloc[idxTokens]['misc'].get('grafo')    \n",
    "            for idxTokens2 in range(0,len(filtred_sentence)):\n",
    "                token2 = filtred_sentence.iloc[idxTokens2]['deps']   \n",
    "                if idxTokens!= idxTokens2 and \"B=\" in token2 and filtred_sentence.iloc[idxTokens2]['misc'].get('grafo'): #encontrou o comeco de uma  outra entidade com URI\n",
    "                    URI_2 = filtred_sentence.iloc[idxTokens2]['misc'].get('grafo')\n",
    "                    has_relation = False\n",
    "                    relation_URIs = get_relations_between_uris(URI_1, URI_2)            \n",
    "                    if relation_URIs != {}: #talvez exista relacao entre URIs, dicionario pode vir vazio -> []\n",
    "                        for x, y in relation_URIs.items():\n",
    "                            if y != []: #existe alguma relacao\n",
    "                                is_to_save = True\n",
    "                                has_relation = True\n",
    "                                relation_type = x\n",
    "                                Ent1 = token.replace(\"B=\",\"\")\n",
    "                                Ent2 = token2.replace(\"B=\",\"\")\n",
    "                                is_rel_interesse = verifica_pares_entidade_interesse(Ent1,Ent2)\n",
    "                                if is_rel_interesse == False:\n",
    "                                    relation_type = 'temporal_relation'\n",
    "                                lista_relacoes_sentence.append(relation_type)\n",
    "                                \n",
    "                                #para depois contabilizar os pares de entidade por relacao\n",
    "                                df_relation = create_relations_dataframe(df_relation,token,token2,URI_1,URI_2,x,originalSentenceNumber)\n",
    "                            \n",
    "                                #criar df_bert para BERT RE com codigo do Fabio\n",
    "                                df_bert = create_bert_dataframe(df_bert,idxTokens,idxTokens2,filtred_sentence,\n",
    "                                                                text,has_relation,relation_type,originalSentenceNumber)\n",
    "                                \n",
    "                                df_entity = create_df_JsonFiles(df_entity,x,token,token2,URI_1,URI_2,\n",
    "                                                                idxTokens,idxTokens2,from_id,to_id,filtred_sentence)\n",
    "                                \n",
    "                                from_id.append(idxTokens)\n",
    "                                to_id.append(idxTokens2)    \n",
    "                                \n",
    "                                #listas para contabilizar relacoes, uris e classes\n",
    "                                lista_relacoes.append(relation_type)\n",
    "                                lista_uris.append(URI_1)\n",
    "                                lista_uris.append(URI_2)         \n",
    "                                lista_classes.append(Ent1)\n",
    "                                lista_classes.append(Ent2)\n",
    "\n",
    "                    if not has_relation: #nao achou relacao\n",
    "                        relation_type = 'no_relation'\n",
    "                        df_bert = create_bert_dataframe(df_bert,idxTokens,idxTokens2,filtred_sentence,\n",
    "                                                        text,has_relation,relation_type,originalSentenceNumber)\n",
    "                        \n",
    "    if is_to_save:\n",
    "        countJsons+=1\n",
    "        #salvar arquivo json para labelstudio\n",
    "        saveJsonFiles(df_entity,text,from_id,to_id, \n",
    "                      lista_relacoes_sentence,filtred_sentence,originalSentenceNumber,save_folder_path)\n",
    "        #salvar json para bert (modelo nao foi usado)\n",
    "#         list_sentences_dict = getDictBert(df_entity,text,\n",
    "#                                           lista_relacoes_sentence,from_id,to_id,list_sentences_dict)\n",
    "        \n",
    "print(\"-------------\")\n",
    "print(\"Number of Jsons saved = \", countJsons )\n",
    "\n",
    "# pickle.dump(df_relation, open('df_relation.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "df_relation.to_csv('df_relation.csv', encoding='utf-8',index=False)\n",
    "df_bert.to_csv(save_csv_name, encoding='utf-8',index=False)\n",
    "\n",
    "relacoes, numb_rel = np.unique(lista_relacoes, return_counts = True)\n",
    "uris, numb_uris = np.unique(lista_uris, return_counts = True)\n",
    "classes, numb_classes = np.unique(lista_classes, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "relacoes, numb_rel = np.unique(lista_relacoes, return_counts = True)\n",
    "uris, numb_uris = np.unique(lista_uris, return_counts = True)\n",
    "classes, numb_classes = np.unique(lista_classes, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das relações encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['constituted_by', 'located_in', 'temporal_relation']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relacoes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 16, 18]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_rel.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das classes encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BACIA', 'POÇO', 'ROCHA', 'UNIDADE_CRONO', 'UNIDADE_LITO']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 8, 4, 36, 12]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_classes.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das URIs encontradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Albian',\n",
       " '#Aptian',\n",
       " '#BASE_CD_BACIA_096',\n",
       " '#BASE_CD_BACIA_100',\n",
       " '#BASE_CD_BACIA_116',\n",
       " '#BASE_CD_BACIA_270',\n",
       " '#BASE_CD_BACIA_281',\n",
       " '#Cenomanian',\n",
       " '#POCO_CD_POCO_007553',\n",
       " '#POCO_CD_POCO_010471',\n",
       " '#POCO_CD_POCO_012996',\n",
       " '#Turonian',\n",
       " '#formacao_163',\n",
       " '#formacao_166',\n",
       " '#formacao_319',\n",
       " '#grupo_000',\n",
       " '#marlstone',\n",
       " '#membro_010',\n",
       " '#shale']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uris.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 14, 2, 6, 6, 1, 1, 4, 2, 4, 2, 2, 2, 2, 6, 1, 2, 1, 2]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_uris.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação de pares de entidades por tipo de relação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtred = pickle.load(open('df_relation.pkl', 'rb'))\n",
    "df_relations = pd.read_csv('df_relation.csv')\n",
    "df_grp = df_relations.groupby('Relation')\n",
    "relations_groups = df_grp.groups\n",
    "relations = list(relations_groups)\n",
    "lista_pares = []\n",
    "for relation in relations:\n",
    "    df_rel = df_grp.get_group(relation)\n",
    "    list_rel = []\n",
    "    for idx_rel in range(0,len(df_rel)):\n",
    "        par = df_rel.iloc[idx_rel]['Ent1'] + ' + ' + df_rel.iloc[idx_rel]['Ent2']\n",
    "        list_rel.append(par)\n",
    "    lista_pares.append(list_rel)\n",
    "print('Number of types of relations ->', len(lista_pares))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliar idx_pair de 0 ao tamanho apresentado acima para verificar os pares de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "pares, numb_pares = np.unique())[idx], return_counts = True)\n",
    "print('Relation -> ',relations[idx])\n",
    "print('Entities pair -> ',pares.tolist())\n",
    "print('Number of ocorrences -> ',numb_pares.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_e</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Ent1</th>\n",
       "      <th>Ent2</th>\n",
       "      <th>has_relation</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[E1] Membro Mucuri [/E1], [E2] Eocretáceo [/E2...</td>\n",
       "      <td>UNIDADE_LITO</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[E1] Membro Mucuri [/E1], Eocretáceo    [E2] B...</td>\n",
       "      <td>UNIDADE_LITO</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>True</td>\n",
       "      <td>located_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[E2] Membro Mucuri [/E2], [E1] Eocretáceo [/E1...</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>UNIDADE_LITO</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Membro Mucuri, [E1] Eocretáceo [/E1]    [E2] B...</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[E2] Membro Mucuri [/E2], Eocretáceo    [E1] B...</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>UNIDADE_LITO</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>modelo proposto      autor, são discutidos con...</td>\n",
       "      <td>NÃOCONSOLID</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>modelo proposto      autor, são discutidos con...</td>\n",
       "      <td>NÃOCONSOLID</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>modelo proposto      autor, são discutidos con...</td>\n",
       "      <td>NÃOCONSOLID</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>modelo proposto      autor, são discutidos con...</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>modelo proposto      autor, são discutidos con...</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>NÃOCONSOLID</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_e                                           sentence           Ent1  \\\n",
       "0        6  [E1] Membro Mucuri [/E1], [E2] Eocretáceo [/E2...   UNIDADE_LITO   \n",
       "0        6  [E1] Membro Mucuri [/E1], Eocretáceo    [E2] B...   UNIDADE_LITO   \n",
       "0        6  [E2] Membro Mucuri [/E2], [E1] Eocretáceo [/E1...  UNIDADE_CRONO   \n",
       "0        6  Membro Mucuri, [E1] Eocretáceo [/E1]    [E2] B...  UNIDADE_CRONO   \n",
       "0        6  [E2] Membro Mucuri [/E2], Eocretáceo    [E1] B...          BACIA   \n",
       "..     ...                                                ...            ...   \n",
       "0      119  modelo proposto      autor, são discutidos con...    NÃOCONSOLID   \n",
       "0      119  modelo proposto      autor, são discutidos con...    NÃOCONSOLID   \n",
       "0      119  modelo proposto      autor, são discutidos con...    NÃOCONSOLID   \n",
       "0      119  modelo proposto      autor, são discutidos con...          BACIA   \n",
       "0      119  modelo proposto      autor, são discutidos con...          BACIA   \n",
       "\n",
       "             Ent2 has_relation     relation  \n",
       "0   UNIDADE_CRONO        False  no_relation  \n",
       "0           BACIA         True   located_in  \n",
       "0    UNIDADE_LITO        False  no_relation  \n",
       "0           BACIA        False  no_relation  \n",
       "0    UNIDADE_LITO        False  no_relation  \n",
       "..            ...          ...          ...  \n",
       "0           BACIA        False  no_relation  \n",
       "0   UNIDADE_CRONO        False  no_relation  \n",
       "0           BACIA        False  no_relation  \n",
       "0           BACIA        False  no_relation  \n",
       "0     NÃOCONSOLID        False  no_relation  \n",
       "\n",
       "[118 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
