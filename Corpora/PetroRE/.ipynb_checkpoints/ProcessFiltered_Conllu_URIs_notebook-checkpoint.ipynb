{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import operator as op\n",
    "import warnings \n",
    "from owlready2 import * #\n",
    "import random\n",
    "import unicodedata\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar ontologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto_name = \"OntoGeoLogicaInstanciasRelacoes\"\n",
    "onto = get_ontology(\"../../KnowledgeGraph/OntoGeoLogicaInstanciasRelacoes.owl\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para procurar na ontologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_between_uris(uri_1, uri_2): \n",
    "    #funcao que acessa a ontologia e procura relacao entre URIs\n",
    "    dict_relation_uris = {}\n",
    "    #Pega as relacoes que a URI1 tem\n",
    "    relation_query_results = list(default_world.sparql(\"\"\"\n",
    "            SELECT DISTINCT ?rel\n",
    "            WHERE{?uri ?rel ?obj\n",
    "                 FILTER(contains(str(?rel), \"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\"))\n",
    "                 FILTER (contains(str(?uri), \"\"\" + '\"' + uri_1 + '\"' + \"\"\"))\n",
    "                 }\n",
    "            \"\"\"))\n",
    "    \n",
    "    relations_str = []\n",
    "    for relation_uris in relation_query_results:\n",
    "        relations_str.append(str(relation_uris[0]).rsplit(\".\",1)[-1])\n",
    "        \n",
    "    # Para cada tipo de relação procura se existe match entre URI1 e URI2\n",
    "    for relation in relations_str:\n",
    "        relation_between_words = list(default_world.sparql(\"\"\"\n",
    "                PREFIX prefix: <http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#>\n",
    "                SELECT distinct ?y ?x2\n",
    "                WHERE{?y prefix:\"\"\" +  relation  +  \"\"\" ?x1\n",
    "\n",
    "                      FILTER (contains(str(?y), \"\"\" + '\"' + uri_1  + '\"' + \"\"\"))        \n",
    "\n",
    "                      ?x2 rdf:type ?j                                   \n",
    "                      FILTER (contains(str(?x2), \"\"\" + '\"' + uri_2  + '\"' + \"\"\"))\n",
    "\n",
    "                      FILTER ( ?x2 = ?x1 )\n",
    "                    }\n",
    "                \"\"\"))\n",
    "        dict_relation_uris[relation] = relation_between_words\n",
    "    return dict_relation_uris\n",
    "\n",
    "def go_through_relations(uri1,uri2):\n",
    "    relation_uris = get_relations_between_uris(uri1, uri2)            \n",
    "    if relation_uris != {}: #talvez exista relacao entre URIs, dicionario pode vir vazio -> []\n",
    "        for x, y in relation_uris.items():#procurar por relacao\n",
    "            if y != []: #existe alguma relacao\n",
    "#                 print(x)\n",
    "                return x\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para printar informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentence_text(sentence):\n",
    "    #printa e retorna o texto original da sentenca\n",
    "    size_sentence = int(sentence.iloc[-1][\"end\"])\n",
    "    text = \" \"*size_sentence\n",
    "    for index, row in sentence.iterrows():\n",
    "        text = text[:int(row[\"start\"])] + row[\"form\"] +text[int(row[\"end\"]):]\n",
    "    print(text)\n",
    "    print(\"-------------\")\n",
    "    return text\n",
    "\n",
    "def print_relation_entities(word1,word2,ent1,ent2,URI_1,URI_2,relation_type,text):\n",
    "    #printa as entidades e relacao entre elas\n",
    "    print('Token 1 = ', word1, '--- Class 1 = ', ent1, '--- URI 1 = ', URI_1)\n",
    "    print('Token 2 = ', word2, '--- Class 2 = ', ent2,'--- URI 2 = ',URI_2)\n",
    "    print('Relation Type = ', relation_type)\n",
    "    print(text)\n",
    "    print(\"-------------\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para gerar Jsons a serem lidos no labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultRelationJson(object):\n",
    "    def __init__(self, from_id, to_id, relations, direction = \"right\"):\n",
    "        self.dict = {\n",
    "            \"from_id\": str(from_id),\n",
    "            \"to_id\": str(to_id),\n",
    "            \"type\": \"relation\",\n",
    "            \"direction\": direction,\n",
    "            \"labels\": relations\n",
    "        }\n",
    "    def get_dict(self):\n",
    "        return self.dict\n",
    "class ResultNERJson(object):\n",
    "    def __init__(self, row):     \n",
    "        self.result_dict = {\n",
    "            \"value\": {\n",
    "            \"start\": row[\"start_word\"],\n",
    "            \"end\": row[\"end_word\"],\n",
    "            \"text\": row[\"word_join\"],\n",
    "            \"labels\": [\n",
    "              row[\"label_word\"]\n",
    "            ],\n",
    "            \"URI\": row[\"URI\"]\n",
    "            },\n",
    "            \n",
    "            \"id\": row[\"index_e\"],\n",
    "            \"from_name\": \"label\",\n",
    "            \"to_name\": \"text\",\n",
    "            \"type\": \"labels\",\n",
    "            \"origin\": \"prediction\"\n",
    "        }\n",
    "    def get_dict(self):\n",
    "        return self.result_dict  \n",
    "class CreateOutput(object):\n",
    "    def __init__(self, text, filtred_sentence, entity_name_new):\n",
    "        self.filtred_sentence = filtred_sentence\n",
    "        self.entity_name_new = entity_name_new\n",
    "        self.main_dict = {\n",
    "            \"id\": 1,\n",
    "            \"data\": {\n",
    "              \"text\": text #sentenca inteira\n",
    "            },\n",
    "            \"annotations\": []\n",
    "        }\n",
    "        self._add_annotations()      \n",
    "    def _add_annotations(self):\n",
    "        results = []\n",
    "        count = 0        \n",
    "        for index, row in self.entity_name_new.iterrows(): \n",
    "            results.append(ResultNERJson(row).get_dict())        \n",
    "        item = [{\n",
    "              \"id\": 1,\n",
    "              \"created_username\": \" null, 0\",\n",
    "              \"created_ago\": \"\",\n",
    "              \"result\": results\n",
    "            }]\n",
    "        self.main_dict[\"annotations\"] = item\n",
    "    def get_output(self):\n",
    "        return self.main_dict\n",
    "    def add_relationship(self, from_id, to_id, relations, direction):\n",
    "        results = self.main_dict.get(\"annotations\")[0].get(\"result\")\n",
    "        relation = ResultRelationJson(from_id, to_id, [relations], direction).get_dict()\n",
    "        results.append(relation)\n",
    "        self.main_dict[\"annotations\"][0][\"result\"] = results   \n",
    "        \n",
    "def combine_itens_from_lists_add_in_json(from_id_vec, to_id_vec, relation_from_vec, output):\n",
    "    for idxRelation in range(0,len(from_id_vec)):\n",
    "        direction = \"right\"\n",
    "        output.add_relationship(from_id=from_id_vec[idxRelation], to_id=to_id_vec[idxRelation], relations = relation_from_vec[idxRelation], direction=direction)\n",
    "    return output\n",
    "def saveJsonFiles(df,from_id,to_id, lista_relaoces_sentence,sentence,SentenceNum,path):\n",
    "    #cria e salva o arquivo Json para labelstudio\n",
    "    text = sentence.iloc[0]['text']\n",
    "    print('Saved Json ->', True)\n",
    "    output = CreateOutput(text,sentence, df)\n",
    "    combine_itens_from_lists_add_in_json(from_id, to_id, lista_relacoes_sentence, output)\n",
    "    print(\"-------------\")\n",
    "    with open(os.path.join(path,f\"{SentenceNum}.json\"), \"w\") as outfile: \n",
    "        json.dump(output.get_output(), outfile) \n",
    "        \n",
    "def get_df_forJsons(sentence,idxTokens):\n",
    "    #retorna um dataframe com as informações das entidades e uma string contendo o nome completo da entidade\n",
    "    df_save_words = pd.DataFrame(columns=['index_e', \"LABEL\", \"START\", \"END\",\\\n",
    "                                      \"TEXT\", \"word_join\", \"start_word\", \"end_word\", \"label_word\",\"URI\"])\n",
    "\n",
    "    index_e = sentence.iloc[idxTokens]['index_e']\n",
    "    label = sentence.iloc[idxTokens]['deps']\n",
    "    start = sentence.iloc[idxTokens]['word_join_start']\n",
    "    end = start + len(sentence.iloc[idxTokens]['form'])\n",
    "    text_ent = sentence.iloc[idxTokens]['form']\n",
    "    word_join = sentence.iloc[idxTokens]['word_join']\n",
    "    start_word = sentence.iloc[idxTokens]['word_join_start']\n",
    "    end_word = sentence.iloc[idxTokens]['word_join_end']\n",
    "    label_word = label.replace(\"B=\",\"\")\n",
    "    URI = sentence.iloc[idxTokens]['grafo']\n",
    "\n",
    "    df_save_words.loc[len(df_save_words.index)] = [index_e, label, start, end, text_ent, word_join,\n",
    "                                                   start_word,\n",
    "                                                   end_word,\n",
    "                                                   label_word,\n",
    "                                                   URI]\n",
    "\n",
    "    return df_save_words, word_join\n",
    "        \n",
    "def create_df_JsonFiles(df_entity,x,token,token2,URI_1,URI_2,idxTokens,idxTokens2,from_id,to_id,sentence):\n",
    "    #retorna o dataframe utilizado para criacao dos arquivos Json para labelstudio\n",
    "    entity_name_new_token1,wordjoin_1 = get_df_forJsons(sentence,idxTokens)\n",
    "    entity_name_new_token2,wordjoin_2 = get_df_forJsons(sentence,idxTokens2)\n",
    "    if idxTokens not in from_id and idxTokens not in to_id:\n",
    "        df_entity = pd.concat([df_entity, entity_name_new_token1])\n",
    "    if idxTokens2 not in from_id and idxTokens2 not in to_id:\n",
    "        df_entity = pd.concat([df_entity, entity_name_new_token2])\n",
    "\n",
    "#     print_relation_entities(wordjoin_1,wordjoin_2,token.replace('B=',''),token2.replace('B=',''),URI_1,URI_2,x)\n",
    "    return df_entity  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para criar dataframe para modelo BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_moddedText_BERT(text,start1,end1,start2,end2,Ent1_inic,Ent1_end,Ent2_inic,Ent2_end):\n",
    "    new_end_ent1 = end1 + len(Ent1_inic)\n",
    "    new_start_ent2 = start2 + len(Ent1_inic) + len(Ent1_end)\n",
    "    new_end_ent2 = end2 + len(Ent1_inic) + len(Ent1_end) + len(Ent2_inic)      \n",
    "    #adicionando [E1] e [/E1]\n",
    "    text_new = text[:start1] + Ent1_inic + text[start1:]\n",
    "    text_new = text_new[:new_end_ent1] + Ent1_end + text_new[new_end_ent1:]\n",
    "    #adicionando [E2] e [/E2]\n",
    "    text_new2 = text_new[:new_start_ent2] + Ent2_inic + text_new[new_start_ent2:]\n",
    "    text_new2 = text_new2[:new_end_ent2] + Ent2_end + text_new2[new_end_ent2:]\n",
    "    \n",
    "    return text_new2\n",
    "\n",
    "def createText_sentence_BERT(text,start_1,end_1,start_2,end_2):\n",
    "    #funcao que retorna um novo texto para sentenca com [E1] e [E2] adicionados junto de cada entidade\n",
    "    start_ent1, start_ent2 = start_1, start_2\n",
    "    end_ent1, end_ent2 = end_1, end_2\n",
    "    Ent1_inic, Ent1_end = '[E1] ', ' [/E1]'\n",
    "    Ent2_inic, Ent2_end = '[E2] ', ' [/E2]'\n",
    "    \n",
    "    if start_ent1 < start_ent2: #[E1] vem antes de [E2]\n",
    "        text_new = create_moddedText_BERT(text,start_ent1,end_ent1,start_ent2,end_ent2,\\\n",
    "                                  Ent1_inic,Ent1_end,Ent2_inic,Ent2_end)\n",
    "    else: #[E2] vem antes de [E1]      \n",
    "        text_new = create_moddedText_BERT(text,start_ent2,end_ent2,start_ent1,end_ent1,\\\n",
    "                                      Ent2_inic,Ent2_end,Ent1_inic,Ent1_end)  \n",
    "    return text_new\n",
    "\n",
    "def create_bert_dataframe(df_bert,idxTokens,idxTokens2,sentence,URI_1,URI_2,has_relation,relation_type,SentenceNumber):\n",
    "    #retorna o dataframe com as informacoes de cada sentenca para utilizar no modelo BERT\n",
    "    df_bert_temp = pd.DataFrame(columns=['#Sentence','sentence','Ent1','Ent2','URI_1','URI_2','has_relation','relation'])\n",
    "    text = sentence.iloc[0]['text']\n",
    "    wordjoin_1, wordjoin_2 = sentence.iloc[idxTokens]['word_join'], sentence.iloc[idxTokens2]['word_join']\n",
    "    ent1, ent2 = sentence.iloc[idxTokens]['deps'], sentence.iloc[idxTokens2]['deps']\n",
    "    ent1, ent2 = ent1.replace(\"B=\",\"\"), ent2.replace(\"B=\",\"\")\n",
    "    start_1, start_2 = sentence.iloc[idxTokens]['word_join_start'], sentence.iloc[idxTokens2]['word_join_start']\n",
    "    end_1, end_2 = sentence.iloc[idxTokens]['word_join_end'], sentence.iloc[idxTokens2]['word_join_end']\n",
    "    text_bert_ents = createText_sentence_BERT(text,start_1,end_1,start_2,end_2)\n",
    "    df_bert_temp.loc[0] = [SentenceNumber,\n",
    "                           text_bert_ents,\n",
    "                           ent1,\n",
    "                           ent2,\n",
    "                           URI_1,\n",
    "                           URI_2,\n",
    "                           has_relation,\n",
    "                           relation_type]\n",
    "    df_bert = pd.concat([df_bert, df_bert_temp])\n",
    "    if relation_type!='no_relation':\n",
    "        print_relation_entities(wordjoin_1,wordjoin_2,ent1,ent2,URI_1,URI_2,relation_type,text_bert_ents)\n",
    "    return df_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para processar as sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def create_relations_dataframe(df_relation,token,token2,URI_1,URI_2,x,originalSentenceNumber):\n",
    "    #retorna dataframe das entidades e suas relações em cada linha\n",
    "    #importante para contabilizar os tipos de relação\n",
    "    df_relation_new = pd.DataFrame(columns=['Relation','Ent1','Ent2','URI_1','URI_2','#Sentence'])\n",
    "    df_relation_new.loc[0] = [x,\n",
    "                            token.replace('B=',''),\n",
    "                            token2.replace('B=',''),\n",
    "                            URI_1,\n",
    "                            URI_2,\n",
    "                            originalSentenceNumber]\n",
    "    df_relation = pd.concat([df_relation, df_relation_new])\n",
    "    return df_relation\n",
    "\n",
    "def verifica_pares_entidade_interesse(ENT_1, ENT_2,relation_type):\n",
    "    #verifica se a relacao encontrada vai ser do tipo temporal_relation CRONO->CRONO\n",
    "    #funcao talvez precise ser atualizada no futuro conforme a ontologia for povoada\n",
    "    lista_from = ['POÇO','UNIDADE_LITO','UNIDADE_LITO','CAMPO','POÇO','POÇO','UNIDADE_LITO','UNIDADE_LITO']\n",
    "    lista_to = ['UNIDADE_LITO','NÂOCONSOLID','ROCHA','BACIA','BACIA','CAMPO','BACIA','UNIDADE_CRONO']        \n",
    "    for idx in range(0,len(lista_to)):\n",
    "        if lista_from[idx] == ENT_1 and lista_to[idx] == ENT_2:\n",
    "            return relation_type\n",
    "    return 'temporal_relation'\n",
    "\n",
    "def go_through_sentence(sentence_df,df_relation,df_bert,sent_numb):\n",
    "    #percorre a sentenca em busca de relacoes entre entidades anotadas com URIs\n",
    "    df_entity = pd.DataFrame()\n",
    "    from_id, to_id = [], []\n",
    "    relation_from, relation_to = [], []\n",
    "    lista_relacoes_sentence = []\n",
    "    is_to_save = False\n",
    "#     df_bert.to_csv(save_csv_name, encoding='utf-8',index=False)\n",
    "#     df_relation.to_csv('df_relation.csv', encoding='utf-8',index=False)\n",
    "    for idxTokens in range(len(sentence_df)):\n",
    "        token, URI_1 = sentence_df.iloc[idxTokens]['deps'], sentence_df.iloc[idxTokens]['grafo']\n",
    "        for idxTokens2 in range(len(sentence_df)):\n",
    "            if idxTokens != idxTokens2:\n",
    "                token2, URI_2 = sentence_df.iloc[idxTokens2]['deps'], sentence_df.iloc[idxTokens2]['grafo']\n",
    "                has_relation = False\n",
    "                relation_type = go_through_relations(URI_1,URI_2)\n",
    "                if relation_type: \n",
    "                    print(\"-------------\")\n",
    "                    print('sentence =', sent_numb)\n",
    "                    is_to_save = True\n",
    "                    has_relation = True\n",
    "                    Ent1, Ent2 = token.replace(\"B=\",\"\"), token2.replace(\"B=\",\"\")\n",
    "                    relation_type = verifica_pares_entidade_interesse(Ent1,Ent2,relation_type)\n",
    "                    lista_relacoes_sentence.append(relation_type)\n",
    "\n",
    "                    #criar df_bert para BERT RE com codigo do Fabio\n",
    "                    df_bert = create_bert_dataframe(df_bert,idxTokens,idxTokens2,sentence_df,\n",
    "                                                    URI_1,URI_2,\n",
    "                                                    has_relation,relation_type,originalSentenceNumber)\n",
    "\n",
    "                    #para contabilizar os pares de entidade por relacao\n",
    "                    df_relation = create_relations_dataframe(df_relation,token,token2,\n",
    "                                                             URI_1,URI_2,relation_type,originalSentenceNumber)\n",
    "                    #listas para contabilizar relacoes, uris e classes\n",
    "                    lista_relacoes.append(relation_type)\n",
    "                    lista_uris.append(URI_1)\n",
    "                    lista_uris.append(URI_2)         \n",
    "                    lista_classes.append(Ent1)\n",
    "                    lista_classes.append(Ent2)\n",
    "\n",
    "                    if is_to_createJsons: #se quiser criar Jsons para LabelStudio\n",
    "                        df_entity = create_df_JsonFiles(df_entity,relation_type,token,token2,URI_1,URI_2,\n",
    "                                                        idxTokens,idxTokens2,from_id,to_id,sentence_df)\n",
    "                        from_id.append(idxTokens)\n",
    "                        to_id.append(idxTokens2) \n",
    "\n",
    "                else: #nao achou relacao\n",
    "                    relation_type = 'no_relation'\n",
    "\n",
    "                    df_bert = create_bert_dataframe(df_bert,idxTokens,idxTokens2,sentence_df,\n",
    "                                                    URI_1,URI_2,has_relation,relation_type,originalSentenceNumber)\n",
    "                        \n",
    "    return lista_relacoes,lista_uris,lista_classes,\\\n",
    "            df_bert, df_relation, df_entity, \\\n",
    "            lista_relacoes_sentence, from_id, to_id, is_to_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ler arquivo csv (ou pkl) com as sentenças pós filtragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero total de sentenças pos-filtragem ->  446\n"
     ]
    }
   ],
   "source": [
    "#df_filtred_sentences = pickle.load(open('df_filtred_petroner_uri_2023_04_05.conllu.pkl', 'rb'))\n",
    "#df_filtred_sentences = pd.read_csv('df_filtred_petroner_uri_2023_04_05_conllu.csv')\n",
    "\n",
    "df_filtred_sentences = pickle.load(open('df_filtred_petroner_uri_valid.conllu.pkl', 'rb'))\n",
    "df_filtred_sentences = pd.read_csv('df_filtred_petroner_uri_valid_conllu.csv')\n",
    "\n",
    "df_group = df_filtred_sentences.groupby('sentence')\n",
    "print('Numero total de sentenças pos-filtragem -> ',len(df_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolher se deseja criar Jsons para labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_to_createJsons = True\n",
    "# is_to_createJsons = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_folder_path = \"./JSONs_04_05\" #local onde são salvos os Jsons para labelstudio\n",
    "save_folder_path = \"./JSONs_valid\"\n",
    "save_csv_name = 'df_bert_sentences_valid.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotina para processar as sentenças já filtradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 34\n",
      "Token 1 =   poço 7-BRG-12-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007553\n",
      "Token 2 =   Bacia de Sergipe/Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Observações:  1.a biozona foi originalmente definida em depósitos    [E2] Bacia de Sergipe/Alagoas [/E2] (testemunhos    [E1] poço 7-BRG-12-SE [/E1]), por Beurlen et al (1987)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 47\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Cronoestratigrafia: [E1] Albiano [/E1], podendo, entretanto, englobar parte    [E2] Aptiano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 47\n",
      "Token 1 =   Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Cronoestratigrafia: [E2] Albiano [/E2], podendo, entretanto, englobar parte    [E1] Aptiano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 63\n",
      "Token 1 =   poço 7-BRG-12-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007553\n",
      "Token 2 =   Bacia de Sergipe/Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "entanto, Trôelsen e Quadros (1971) já haviam fotografado - alguns de seus - exemplares ([E2] Bacia de Sergipe/Alagoas [/E2], [E1] poço 7-BRG-12-SE [/E1])..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 65\n",
      "Token 1 =   Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Em termos ¢ronoestratigraficos, entretanto, Freitas et al. (op. cit.), preferiram não firmar posição quanto    andar em que as tais associações estavam inseridas,              a afirmar que as espécies reconhecidas não eram suficientes para distinguir o [E1] Aptiano [/E1]    [E2] Albiano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 65\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Em termos ¢ronoestratigraficos, entretanto, Freitas et al. (op. cit.), preferiram não firmar posição quanto    andar em que as tais associações estavam inseridas,              a afirmar que as espécies reconhecidas não eram suficientes para distinguir o [E2] Aptiano [/E2]    [E1] Albiano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 78\n",
      "Token 1 =   andares Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Em face     problemas mencionados,             que a delimitação entre os [E1] andares Aptiano [/E1] e [E2] Albiano [/E2], com base em exemplares    gênero Nannoconus, seja uma tarefa difícil..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 78\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   andares Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Em face     problemas mencionados,             que a delimitação entre os [E2] andares Aptiano [/E2] e [E1] Albiano [/E1], com base em exemplares    gênero Nannoconus, seja uma tarefa difícil..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 96\n",
      "Token 1 =   intra-albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato [E1] intra-albiano [/E1], correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos [E2] aptianos [/E2] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 96\n",
      "Token 1 =   intra-albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato [E1] intra-albiano [/E1], correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos [E2] aptianos [/E2] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 96\n",
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   intra-albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato [E2] intra-albiano [/E2], correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos [E1] aptianos [/E1] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 370\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 96\n",
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato intra-albiano, correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos [E1] aptianos [/E1] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos [E2] aptianos [/E2] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 96\n",
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   intra-albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato [E2] intra-albiano [/E2], correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos aptianos (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos [E1] aptianos [/E1] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 96\n",
      "Token 1 =   aptianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   aptianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Esta constatação induz   formulação de algumas hipóteses para explicar o não-registro       última biozona     bacias mencionadas: a) a existência de amplo hiato intra-albiano, correspondente    tempo compreendido      biozona Nannoconus fragilis; b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; “e d) eventualmente, já em tempos [E2] aptianos [/E2] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul. b) as condicionantes ambientais    água    mar necessárias para a proliferação e sedimentação (após a morte    organismo) de Nannoconus fragilis não teriam sido atingidas; c) a recristalização sofrida       carbonatos durante a diagénese teria destruído ou dificultaria muito a liberação     nanofósseis    matriz    rocha, impedindo, assim, o reconhecimento    biozona em análises rotineiras; mo d) eventualmente, já em tempos [E1] aptianos [/E1] (?), a margem equatorial receberia influxos de águas oriundas    oceano situado a norte    primitivo Atlântico Sul..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 367\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 98\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   intra-albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "De acordo com os arcabouços bioestratigráficos elaborados    partir de outros grupos fósseis (palinomorfos, principalmente), o [E1] Albiano [/E1],    margem sudeste, é dividido em duas ou mais biozonas e as investigações não sugerem a existência de qualquer hiato [E2] intra-albiano [/E2] de grande expressão geográfica (Azevedo et al. 1987a; Viviers et al. 1986; Oliveira et al. 1993)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 98\n",
      "Token 1 =   intra-albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "De acordo com os arcabouços bioestratigráficos elaborados    partir de outros grupos fósseis (palinomorfos, principalmente), o [E2] Albiano [/E2],    margem sudeste, é dividido em duas ou mais biozonas e as investigações não sugerem a existência de qualquer hiato [E1] intra-albiano [/E1] de grande expressão geográfica (Azevedo et al. 1987a; Viviers et al. 1986; Oliveira et al. 1993)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 105\n",
      "Token 1 =   Formação Macaé --- Class 1 =  UNIDADE_LITO --- URI 1 =  #grupo_000\n",
      "Token 2 =   Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "É sabido; por exemplo, que a porção superior    [E1] Formação Macaé [/E1] (Albiano/Turoniano    Bacia de ([E2] Campos [/E2]) encerra níveis ricos em nanofósseis, observáveis somente com o auxílio    microscópio eletrônico de varredura (MEV, Spadini et al. 1988)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 140\n",
      "Token 1 =   poço 1-CES-75 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_012996\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "[E2] Bacia    Ceará [/E2], Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano ([E1] poço 1-CES-75 [/E1]), o que também pode ser verificado    perfuração 1-US-1-SE    Bacia de Sergipe/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 140\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Bacia de Sergipe --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração [E1] 1-US-1-SE [/E1]    [E2] Bacia de Sergipe [/E2]/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 140\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração [E1] 1-US-1-SE [/E1]    Bacia de Sergipe/[E2] Alagoas [/E2] (Cunha, informação verbal)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 149\n",
      "Token 1 =   poço 1-CES-75 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_012996\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "[E2] Bacia    Ceará [/E2], Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano ([E1] poço 1-CES-75 [/E1]), o que também pode ser verificado    perfuração 1-US-1-SE    Bacia de Sergipe/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 149\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Bacia de Sergipe --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração [E1] 1-US-1-SE [/E1]    [E2] Bacia de Sergipe [/E2]/Alagoas (Cunha, informação verbal)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 149\n",
      "Token 1 =   1-US-1-SE --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_010471\n",
      "Token 2 =   Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Bacia    Ceará, Cunha (1990a) sugere que a espécie Nannoconus truitti truitti teria sido extinta    Turoniano (poço 1-CES-75), o que também pode ser verificado    perfuração [E1] 1-US-1-SE [/E1]    Bacia de Sergipe/[E2] Alagoas [/E2] (Cunha, informação verbal)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 154\n",
      "Token 1 =   cenomanianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   turonianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Turonian\n",
      "Relation Type =  temporal_relation\n",
      "Iniciada    parte sul    costa brasileira, próximo    término do-Albiano, esta mudança teria migrado, gradativamente, para norte, atingindo as bacias de Sergipe/Alagoas, Potiguar e    Ceará somente em tempos [E1] cenomanianos [/E1]/[E2] turonianos [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 154\n",
      "Token 1 =   turonianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Turonian\n",
      "Token 2 =   cenomanianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  temporal_relation\n",
      "Iniciada    parte sul    costa brasileira, próximo    término do-Albiano, esta mudança teria migrado, gradativamente, para norte, atingindo as bacias de Sergipe/Alagoas, Potiguar e    Ceará somente em tempos [E2] cenomanianos [/E2]/[E1] turonianos [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 163\n",
      "Token 1 =   Formação Itajaí --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_163\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "sítio sedimentar, raros exemplares de Nannoconus truitti têm sido observados     estratos basais    [E1] Formação Itajaí [/E1] ([E2] folhelhos [/E2] e margas) que jazem imediatamente acima    Formação Guarujá (carbonatos)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 163\n",
      "Token 1 =   Formação Itajaí --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_163\n",
      "Token 2 =   margas --- Class 2 =  ROCHA --- URI 2 =  #marlstone\n",
      "Relation Type =  constituted_by\n",
      "sítio sedimentar, raros exemplares de Nannoconus truitti têm sido observados     estratos basais    [E1] Formação Itajaí [/E1] (folhelhos e [E2] margas [/E2]) que jazem imediatamente acima    Formação Guarujá (carbonatos)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 163\n",
      "Token 1 =   Formação Guarujá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_166\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "sítio sedimentar, raros exemplares de Nannoconus truitti têm sido observados     estratos basais    Formação Itajaí ([E2] folhelhos [/E2] e margas) que jazem imediatamente acima    [E1] Formação Guarujá [/E1] (carbonatos)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 163\n",
      "Token 1 =   Formação Guarujá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_166\n",
      "Token 2 =   margas --- Class 2 =  ROCHA --- URI 2 =  #marlstone\n",
      "Relation Type =  constituted_by\n",
      "sítio sedimentar, raros exemplares de Nannoconus truitti têm sido observados     estratos basais    Formação Itajaí (folhelhos e [E2] margas [/E2]) que jazem imediatamente acima    [E1] Formação Guarujá [/E1] (carbonatos)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 165\n",
      "Token 1 =   cenomanianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   albianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Se o desaparecimento       taxon             vinculado a uma mudança climática (obs. 3), que se deu gradativamente de sul para norte, o mesmo não deveria ter os últimos registros     depósitos [E1] cenomanianos [/E1]    Bacia de Santos, e [E2] albianos [/E2]     bacias de Campos e Espírito Santo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 165\n",
      "Token 1 =   albianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   cenomanianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  temporal_relation\n",
      "Se o desaparecimento       taxon             vinculado a uma mudança climática (obs. 3), que se deu gradativamente de sul para norte, o mesmo não deveria ter os últimos registros     depósitos [E2] cenomanianos [/E2]    Bacia de Santos, e [E1] albianos [/E1]     bacias de Campos e Espírito Santo..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 167\n",
      "Token 1 =   andares Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Cenomaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  temporal_relation\n",
      "foi aferido com relação     outros grupos fósseis — não guardam o registro sedimentar continuo     [E1] andares Albiano [/E1] e [E2] Cenomaniano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 167\n",
      "Token 1 =   Cenomaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   andares Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "foi aferido com relação     outros grupos fósseis — não guardam o registro sedimentar continuo     [E2] andares Albiano [/E2] e [E1] Cenomaniano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 172\n",
      "Token 1 =   Albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   Cenomaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  temporal_relation\n",
      "Ainda não há argumentos consistentes para firmar uma posição quanto    limite superior    biozona ([E1] Albiano [/E1] ou [E2] Cenomaniano [/E2] - parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 172\n",
      "Token 1 =   Cenomaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   Albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Ainda não há argumentos consistentes para firmar uma posição quanto    limite superior    biozona ([E2] Albiano [/E2] ou [E1] Cenomaniano [/E1] - parte inferior)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 240\n",
      "Token 1 =   poço 1-CES-75 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_012996\n",
      "Token 2 =   Bacia Ceará --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "Algum tempo depois, Cunha (1990a) a reconheceu com pequena espessura    [E1] poço 1-CES-75 [/E1]    [E2] Bacia    Ceará [/E2] (Sub-bacia de Mundaú)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 240\n",
      "Token 1 =   poço 1-CES-75 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_012996\n",
      "Token 2 =   Sub-bacia de Mundaú --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_096\n",
      "Relation Type =  located_in\n",
      "Algum tempo depois, Cunha (1990a) a reconheceu com pequena espessura    [E1] poço 1-CES-75 [/E1]    Bacia    Ceará ([E2] Sub-bacia de Mundaú [/E2])..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 319\n",
      "Token 1 =   coniaciano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Coniacian\n",
      "Token 2 =   santoniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Santonian\n",
      "Relation Type =  temporal_relation\n",
      "Por ter modificado seu limite inferior, passando a               a partir    última ocorrência de Stoverius achylosus, Wanderley (1987, 1988) atribuiu para a biozona o intervalo [E1] coniaciano [/E1]/[E2] santoniano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 319\n",
      "Token 1 =   santoniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Santonian\n",
      "Token 2 =   coniaciano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Coniacian\n",
      "Relation Type =  temporal_relation\n",
      "Por ter modificado seu limite inferior, passando a               a partir    última ocorrência de Stoverius achylosus, Wanderley (1987, 1988) atribuiu para a biozona o intervalo [E2] coniaciano [/E2]/[E1] santoniano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 321\n",
      "Token 1 =   santoniana --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Santonian\n",
      "Token 2 =   campaniana --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Finalmente, Oliveira et al. (1993), adotando as observações de Perch-Nielsen (1985) e Cunha et al. (op. cit), concluíram que a zona abranae a secão [E1] santoniana [/E1]/[E2] campaniana [/E2] (parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 321\n",
      "Token 1 =   campaniana --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   santoniana --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Santonian\n",
      "Relation Type =  temporal_relation\n",
      "Finalmente, Oliveira et al. (1993), adotando as observações de Perch-Nielsen (1985) e Cunha et al. (op. cit), concluíram que a zona abranae a secão [E2] santoniana [/E2]/[E1] campaniana [/E1] (parte inferior)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 323\n",
      "Token 1 =   Santoniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Santonian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Este é um-fato importante, pois, até então, as correlações estabelecidas entre nanofósseis e outros grupos fósseis (ver obs. 3) sugeriam que a última ocorrência de Lithastrinus grillii          dado    término    [E1] Santoniano [/E1], embora já se tivesse o conhecimento de que, em outras partes    mundo, esta espécie teria sobrevivido até o início    deposição    [E2] Campaniano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 323\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Santoniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Santonian\n",
      "Relation Type =  temporal_relation\n",
      "Este é um-fato importante, pois, até então, as correlações estabelecidas entre nanofósseis e outros grupos fósseis (ver obs. 3) sugeriam que a última ocorrência de Lithastrinus grillii          dado    término    [E2] Santoniano [/E2], embora já se tivesse o conhecimento de que, em outras partes    mundo, esta espécie teria sobrevivido até o início    deposição    [E1] Campaniano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 333\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   santonianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Santonian\n",
      "Relation Type =  temporal_relation\n",
      "margem continental brasileira, por exemplo, há trabalhos que postulam a ocorrência de eventos erosivos destruindo os estratos basais    [E1] Campaniano [/E1], e a espécie Lithastrinus grillii seria,    maioria     seções, registrada apenas     depósitos [E2] santonianos [/E2] (Cunha et al. 1993; Oliveira et al. 1993)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 333\n",
      "Token 1 =   santonianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Santonian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "margem continental brasileira, por exemplo, há trabalhos que postulam a ocorrência de eventos erosivos destruindo os estratos basais    [E2] Campaniano [/E2], e a espécie Lithastrinus grillii seria,    maioria     seções, registrada apenas     depósitos [E1] santonianos [/E1] (Cunha et al. 1993; Oliveira et al. 1993)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 360\n",
      "Token 1 =   Santoniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Santonian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Até mesmo a polêmica relativa    momento    extinção de Marthasterites furcatus (término    [E1] Santoniano [/E1] ou inicio    [E2] Campaniano [/E2]) é bem semelhante        de Lithastrinus grillii..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 360\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Santoniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Santonian\n",
      "Relation Type =  temporal_relation\n",
      "Até mesmo a polêmica relativa    momento    extinção de Marthasterites furcatus (término    [E2] Santoniano [/E2] ou inicio    [E1] Campaniano [/E1]) é bem semelhante        de Lithastrinus grillii..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 382\n",
      "Token 1 =   campanianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   maastrichtianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Maastrichtian\n",
      "Relation Type =  temporal_relation\n",
      "Para a Bacia de Santos, Viviers (1986) argumenta que grande parte     sedimentos [E1] campanianos [/E1]/[E2] maastrichtianos [/E2] são representados por espessas camadas de clásticos grosseiros, o que inviabilizaria a individualização    biozona..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 382\n",
      "Token 1 =   maastrichtianos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Maastrichtian\n",
      "Token 2 =   campanianos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Para a Bacia de Santos, Viviers (1986) argumenta que grande parte     sedimentos [E2] campanianos [/E2]/[E1] maastrichtianos [/E1] são representados por espessas camadas de clásticos grosseiros, o que inviabilizaria a individualização    biozona..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 412\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 390\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   intra-campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em determinados trabalhos, o limite superior    biozona é associado    término    [E1] Campaniano [/E1] (Freitas, 1984; Antunes, 1984 e 1987, por exemplo); em outros é considerado um biorizonte [E2] intra-campaniano [/E2], muito próximo    topo       andar (Cunha e Antunes, 1993)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 390\n",
      "Token 1 =   intra-campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em determinados trabalhos, o limite superior    biozona é associado    término    [E2] Campaniano [/E2] (Freitas, 1984; Antunes, 1984 e 1987, por exemplo); em outros é considerado um biorizonte [E1] intra-campaniano [/E1], muito próximo    topo       andar (Cunha e Antunes, 1993)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 399\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   intra-campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em determinados trabalhos, o limite superior    biozona é “associado    término    [E1] Campaniano [/E1] (Freitas, 1984; Antunes, 1984 e 1987, por exemplo); em outros é considerado um biorizonte [E2] intra-campaniano [/E2], muito próximo    topo       andar (Cunha e Antunes, 1993)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 399\n",
      "Token 1 =   intra-campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em determinados trabalhos, o limite superior    biozona é “associado    término    [E2] Campaniano [/E2] (Freitas, 1984; Antunes, 1984 e 1987, por exemplo); em outros é considerado um biorizonte [E1] intra-campaniano [/E1], muito próximo    topo       andar (Cunha e Antunes, 1993)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 412\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E1] Campaniano [/E1] (parte superior) ou [E2] Campaniano [/E2] (parte superior)/Maactrichtiano (narte inferior)\n",
      "-------------\n",
      "-------------\n",
      "sentence = 412\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Maactrichtiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Maastrichtian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E1] Campaniano [/E1] (parte superior) ou Campaniano (parte superior)/[E2] Maactrichtiano [/E2] (narte inferior)\n",
      "-------------\n",
      "-------------\n",
      "sentence = 412\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E2] Campaniano [/E2] (parte superior) ou [E1] Campaniano [/E1] (parte superior)/Maactrichtiano (narte inferior)\n",
      "-------------\n",
      "-------------\n",
      "sentence = 412\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Maactrichtiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Maastrichtian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    Campaniano (parte superior) ou [E1] Campaniano [/E1] (parte superior)/[E2] Maactrichtiano [/E2] (narte inferior)\n",
      "-------------\n",
      "-------------\n",
      "sentence = 412\n",
      "Token 1 =   Maactrichtiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Maastrichtian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E2] Campaniano [/E2] (parte superior) ou Campaniano (parte superior)/[E1] Maactrichtiano [/E1] (narte inferior)\n",
      "-------------\n",
      "-------------\n",
      "sentence = 412\n",
      "Token 1 =   Maactrichtiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Maastrichtian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    Campaniano (parte superior) ou [E2] Campaniano [/E2] (parte superior)/[E1] Maactrichtiano [/E1] (narte inferior)\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 414\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E1] Campaniano [/E1] (parte superior) ou [E2] Campaniano [/E2] (parte superior)/Maastrichtiano (parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 414\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Maastrichtiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Maastrichtian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E1] Campaniano [/E1] (parte superior) ou Campaniano (parte superior)/[E2] Maastrichtiano [/E2] (parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 414\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E2] Campaniano [/E2] (parte superior) ou [E1] Campaniano [/E1] (parte superior)/Maastrichtiano (parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 414\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Maastrichtiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Maastrichtian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    Campaniano (parte superior) ou [E1] Campaniano [/E1] (parte superior)/[E2] Maastrichtiano [/E2] (parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 414\n",
      "Token 1 =   Maastrichtiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Maastrichtian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    [E2] Campaniano [/E2] (parte superior) ou Campaniano (parte superior)/[E1] Maastrichtiano [/E1] (parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 414\n",
      "Token 1 =   Maastrichtiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Maastrichtian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "Em outras é associada    Campaniano (parte superior) ou [E2] Campaniano [/E2] (parte superior)/[E1] Maastrichtiano [/E1] (parte inferior)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 451\n",
      "Token 1 =   Campaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Campanian\n",
      "Token 2 =   Maastrichtiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Maastrichtian\n",
      "Relation Type =  temporal_relation\n",
      "[E1] Campaniano [/E1]/[E2] Maastrichtiano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 451\n",
      "Token 1 =   Maastrichtiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Maastrichtian\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  temporal_relation\n",
      "[E2] Campaniano [/E2]/[E1] Maastrichtiano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 511\n",
      "Token 1 =   albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   cenomaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  temporal_relation\n",
      "a Zona Braarudosphaera africana passaria a ser denominada Braarudosphaera ex. gr. B. africana: 3. a Zona Nannoconus truitti (N-250) só seria empregada     bacias    margem sudeste e estaria associada, com certas feservas,    intervalo [E1] albiano [/E1]/[E2] cenomaniano [/E2] (parte inferior)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 511\n",
      "Token 1 =   cenomaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "a Zona Braarudosphaera africana passaria a ser denominada Braarudosphaera ex. gr. B. africana: 3. a Zona Nannoconus truitti (N-250) só seria empregada     bacias    margem sudeste e estaria associada, com certas feservas,    intervalo [E2] albiano [/E2]/[E1] cenomaniano [/E1] (parte inferior)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 553\n",
      "Token 1 =   albiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Albian\n",
      "Token 2 =   cenomaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Cenomanian\n",
      "Relation Type =  temporal_relation\n",
      "Essas três unidades                  início    formação    oceano Atlântico Sul e caracterizam, de modo geral, o intervalo [E1] albiano [/E1]/[E2] cenomaniano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 553\n",
      "Token 1 =   cenomaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Cenomanian\n",
      "Token 2 =   albiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Albian\n",
      "Relation Type =  temporal_relation\n",
      "Essas três unidades                  início    formação    oceano Atlântico Sul e caracterizam, de modo geral, o intervalo [E2] albiano [/E2]/[E1] cenomaniano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 576\n",
      "Token 1 =   Fazenda Cedro --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0444\n",
      "Token 2 =   Bacia Espirito Santo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_270\n",
      "Relation Type =  located_in\n",
      "ANTUNES, R. L. Geohistória    paleocanion de [E1] Fazenda Cedro [/E1], [E2] Bacia    Espirito Santo [/E2] - Brasil, segundo dados biocronoestratigráficos..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 698\n",
      "Token 1 =   formações Monte Alegre --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_232\n",
      "Token 2 =   bacias Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "RESUMO -     [E2] bacias    Amazonas [/E2] e    Solimões, a sequência carbonifera é representada       [E1] formações Monte Alegre [/E1], Itaituba e,      menos,      parte basal    Formação Nova Olinda..\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 416\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 698\n",
      "Token 1 =   formações Monte Alegre --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_232\n",
      "Token 2 =   carbonifera --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  has_age\n",
      "RESUMO -     bacias    Amazonas e    Solimões, a sequência [E2] carbonifera [/E2] é representada       [E1] formações Monte Alegre [/E1], Itaituba e,      menos,      parte basal    Formação Nova Olinda..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 698\n",
      "Token 1 =   Itaituba --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_187\n",
      "Token 2 =   bacias Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "RESUMO -     [E2] bacias    Amazonas [/E2] e    Solimões, a sequência carbonifera é representada       formações Monte Alegre, [E1] Itaituba [/E1] e,      menos,      parte basal    Formação Nova Olinda..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 698\n",
      "Token 1 =   Itaituba --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_187\n",
      "Token 2 =   carbonifera --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  has_age\n",
      "RESUMO -     bacias    Amazonas e    Solimões, a sequência [E2] carbonifera [/E2] é representada       formações Monte Alegre, [E1] Itaituba [/E1] e,      menos,      parte basal    Formação Nova Olinda..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 698\n",
      "Token 1 =   Formação Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   bacias Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "RESUMO -     [E2] bacias    Amazonas [/E2] e    Solimões, a sequência carbonifera é representada       formações Monte Alegre, Itaituba e,      menos,      parte basal    [E1] Formação Nova Olinda [/E1]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 698\n",
      "Token 1 =   Formação Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   carbonifera --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  has_age\n",
      "RESUMO -     bacias    Amazonas e    Solimões, a sequência [E2] carbonifera [/E2] é representada       formações Monte Alegre, Itaituba e,      menos,      parte basal    [E1] Formação Nova Olinda [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 699\n",
      "Token 1 =   poços 2-CA-1-AM --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_022660\n",
      "Token 2 =   Formação Itaituba --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_187\n",
      "Relation Type =  crosses\n",
      "Dentro    intervalo abrangido por essas formações, foi possivel reconhecer o limite Morrowano/Atokano     [E1] poços 2-CA-1-AM [/E1] e 1-UI-1-AM, situado    parte média    [E2] Formação Itaituba [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 737\n",
      "Token 1 =   Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "oportuno comentar a origem     unidades [E1] Morrowano [/E1] e [E2] Atokano [/E2], para melhor             e compreender a razão de tantas controvérsias, principalmente    estudo de foraminiferos e conodontes..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 737\n",
      "Token 1 =   Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "oportuno comentar a origem     unidades [E2] Morrowano [/E2] e [E1] Atokano [/E1], para melhor             e compreender a razão de tantas controvérsias, principalmente    estudo de foraminiferos e conodontes..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 739\n",
      "Token 1 =   Carbonifero --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   carboniferas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  temporal_relation\n",
      "Fig. 3 - Quadro de tempo geológico para o [E1] Carbonifero [/E1], revisado, atualizado e ampliado por Haq e Eysinga (1987), modificado com a colocação     formações [E2] carboniferas [/E2]    Bacia    Amazonas..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 739\n",
      "Token 1 =   carboniferas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   Carbonifero --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  temporal_relation\n",
      "Fig. 3 - Quadro de tempo geológico para o [E2] Carbonifero [/E2], revisado, atualizado e ampliado por Haq e Eysinga (1987), modificado com a colocação     formações [E1] carboniferas [/E1]    Bacia    Amazonas..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 382\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 745\n",
      "Token 1 =   Série Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "Cabe ressaltar que a Série Lampasan era definida em [E1] Série Atokan [/E1] ([E2] Atokan [/E2] Series), caracterizada      como equivalente   Zona de Fusulinella e incluía camadas presença de Pseudostafella, Ozawainella, Profusulinella, consideradas desmoinesianas,    passo que a Série Fusiella e Fusulinella..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 745\n",
      "Token 1 =   Série Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   desmoinesianas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      "Cabe ressaltar que a Série Lampasan era definida em [E1] Série Atokan [/E1] (Atokan Series), caracterizada      como equivalente   Zona de Fusulinella e incluía camadas presença de Pseudostafella, Ozawainella, Profusulinella, consideradas [E2] desmoinesianas [/E2],    passo que a Série Fusiella e Fusulinella..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 745\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Série Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "Cabe ressaltar que a Série Lampasan era definida em [E2] Série Atokan [/E2] ([E1] Atokan [/E1] Series), caracterizada      como equivalente   Zona de Fusulinella e incluía camadas presença de Pseudostafella, Ozawainella, Profusulinella, consideradas desmoinesianas,    passo que a Série Fusiella e Fusulinella..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 745\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   desmoinesianas --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      "Cabe ressaltar que a Série Lampasan era definida em Série Atokan ([E1] Atokan [/E1] Series), caracterizada      como equivalente   Zona de Fusulinella e incluía camadas presença de Pseudostafella, Ozawainella, Profusulinella, consideradas [E2] desmoinesianas [/E2],    passo que a Série Fusiella e Fusulinella..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 745\n",
      "Token 1 =   desmoinesianas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Série Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "Cabe ressaltar que a Série Lampasan era definida em [E2] Série Atokan [/E2] (Atokan Series), caracterizada      como equivalente   Zona de Fusulinella e incluía camadas presença de Pseudostafella, Ozawainella, Profusulinella, consideradas [E1] desmoinesianas [/E1],    passo que a Série Fusiella e Fusulinella..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 745\n",
      "Token 1 =   desmoinesianas --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "Cabe ressaltar que a Série Lampasan era definida em Série Atokan ([E2] Atokan [/E2] Series), caracterizada      como equivalente   Zona de Fusulinella e incluía camadas presença de Pseudostafella, Ozawainella, Profusulinella, consideradas [E1] desmoinesianas [/E1],    passo que a Série Fusiella e Fusulinella..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 749\n",
      "Token 1 =   Desmoinesian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Missourian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Missourian_Age\n",
      "Relation Type =  temporal_relation\n",
      "a conodontes Atokanos    base    Mais tarde, aquele autor mudou para Morrowan, horizonte Akavassky    seção-tipo Bashkiriano     [E1] Desmoinesian [/E1], [E2] Missourian [/E2] e Virgilian (Moore, 1937)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 749\n",
      "Token 1 =   Missourian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Missourian_Age\n",
      "Token 2 =   Desmoinesian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      "a conodontes Atokanos    base    Mais tarde, aquele autor mudou para Morrowan, horizonte Akavassky    seção-tipo Bashkiriano     [E2] Desmoinesian [/E2], [E1] Missourian [/E1] e Virgilian (Moore, 1937)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 749\n",
      "Token 1 =   Missourian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Missourian_Age\n",
      "Token 2 =   Virgilian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Virgilian_Age\n",
      "Relation Type =  temporal_relation\n",
      "a conodontes Atokanos    base    Mais tarde, aquele autor mudou para Morrowan, horizonte Akavassky    seção-tipo Bashkiriano     Desmoinesian, [E1] Missourian [/E1] e [E2] Virgilian [/E2] (Moore, 1937)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 749\n",
      "Token 1 =   Virgilian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Virgilian_Age\n",
      "Token 2 =   Missourian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Missourian_Age\n",
      "Relation Type =  temporal_relation\n",
      "a conodontes Atokanos    base    Mais tarde, aquele autor mudou para Morrowan, horizonte Akavassky    seção-tipo Bashkiriano     Desmoinesian, [E2] Missourian [/E2] e [E1] Virgilian [/E1] (Moore, 1937)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 578\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 753\n",
      "Token 1 =   Morrowan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Morrowano/Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "Assim, o aparecimento de Profusulinella não (1940) propôs o uso formal     cinco séries: [E1] Morrowan [/E1], coincide com o limite [E2] Morrowano/Atokano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 753\n",
      "Token 1 =   Morrowano/Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Morrowan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "Assim, o aparecimento de Profusulinella não (1940) propôs o uso formal     cinco séries: [E2] Morrowan [/E2], coincide com o limite [E1] Morrowano/Atokano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 754\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Desmoinesian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      "Por este [E1] Atokan [/E1], [E2] Desmoinesian [/E2], Missourian e Virgilian..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 754\n",
      "Token 1 =   Desmoinesian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "Por este [E2] Atokan [/E2], [E1] Desmoinesian [/E1], Missourian e Virgilian..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 754\n",
      "Token 1 =   Desmoinesian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Missourian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Missourian_Age\n",
      "Relation Type =  temporal_relation\n",
      "Por este Atokan, [E1] Desmoinesian [/E1], [E2] Missourian [/E2] e Virgilian..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 754\n",
      "Token 1 =   Missourian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Missourian_Age\n",
      "Token 2 =   Desmoinesian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      "Por este Atokan, [E2] Desmoinesian [/E2], [E1] Missourian [/E1] e Virgilian..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 754\n",
      "Token 1 =   Missourian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Missourian_Age\n",
      "Token 2 =   Virgilian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Virgilian_Age\n",
      "Relation Type =  temporal_relation\n",
      "Por este Atokan, Desmoinesian, [E1] Missourian [/E1] e [E2] Virgilian [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 754\n",
      "Token 1 =   Virgilian --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Virgilian_Age\n",
      "Token 2 =   Missourian --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Missourian_Age\n",
      "Relation Type =  temporal_relation\n",
      "Por este Atokan, Desmoinesian, [E2] Missourian [/E2] e [E1] Virgilian [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 755\n",
      "Token 1 =   Derryan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "motivo, camadas contendo este gênero devem ser Outros termos como “Bendian”, “Lampasan” e consideradas em posicionamento superior, definido      “[E1] Derryan [/E1]” foram utilizados para o intervalo hoje designado presença de Pseudostafella-Eoschubertella dentro    por “[E2] Atokan [/E2]” (Sutherland e Manger, 1984)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 755\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Derryan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "motivo, camadas contendo este gênero devem ser Outros termos como “Bendian”, “Lampasan” e consideradas em posicionamento superior, definido      “[E2] Derryan [/E2]” foram utilizados para o intervalo hoje designado presença de Pseudostafella-Eoschubertella dentro    por “[E1] Atokan [/E1]” (Sutherland e Manger, 1984)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   2-CA-1-AM --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_022660\n",
      "Token 2 =   Bacia Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "O melhor resultado foi obtido    pogo [E1] 2-CA-1-AM [/E1],    Texas Central, propuseram o nome Atokan    [E2] Bacia    Amazonas [/E2], onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e Atokano (fig. 4), Desmoinesiano, pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   andares Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E1] Atokan [/E1]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os [E2] andares Morrowano [/E2] e Atokano (fig. 4), Desmoinesiano, pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E1] Atokan [/E1]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e [E2] Atokano [/E2] (fig. 4), Desmoinesiano, pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Desmoinesiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E1] Atokan [/E1]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e Atokano (fig. 4), [E2] Desmoinesiano [/E2], pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokan --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   pós- Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E1] Atokan [/E1]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e Atokano (fig. 4), Desmoinesiano, [E2] pós-Morrowano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   andares Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E2] Atokan [/E2]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os [E1] andares Morrowano [/E1] e Atokano (fig. 4), Desmoinesiano, pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   andares Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os [E1] andares Morrowano [/E1] e [E2] Atokano [/E2] (fig. 4), Desmoinesiano, pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   andares Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   pós- Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os [E1] andares Morrowano [/E1] e Atokano (fig. 4), Desmoinesiano, [E2] pós-Morrowano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E2] Atokan [/E2]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e [E1] Atokano [/E1] (fig. 4), Desmoinesiano, pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   andares Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os [E2] andares Morrowano [/E2] e [E1] Atokano [/E1] (fig. 4), Desmoinesiano, pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Desmoinesiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e [E1] Atokano [/E1] (fig. 4), [E2] Desmoinesiano [/E2], pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   pós- Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e [E1] Atokano [/E1] (fig. 4), Desmoinesiano, [E2] pós-Morrowano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Desmoinesiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E2] Atokan [/E2]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e Atokano (fig. 4), [E1] Desmoinesiano [/E1], pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   Desmoinesiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e [E2] Atokano [/E2] (fig. 4), [E1] Desmoinesiano [/E1], pós-Morrowano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   pós- Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Atokan --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome [E2] Atokan [/E2]    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e Atokano (fig. 4), Desmoinesiano, [E1] pós-Morrowano [/E1]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   pós- Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   andares Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os [E2] andares Morrowano [/E2] e Atokano (fig. 4), Desmoinesiano, [E1] pós-Morrowano [/E1]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 758\n",
      "Token 1 =   pós- Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "O melhor resultado foi obtido    pogo 2-CA-1-AM,    Texas Central, propuseram o nome Atokan    Bacia    Amazonas, onde foi possível estabelecer o especificamente para o que seria o intervalo pré-limite entre os andares Morrowano e [E2] Atokano [/E2] (fig. 4), Desmoinesiano, [E1] pós-Morrowano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 777\n",
      "Token 1 =   formações Itaituba --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_187\n",
      "Token 2 =   Carbonifero --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  has_age\n",
      "A aridez crescente em direção    final    [E2] Carbonifero [/E2] é comprovada      escassez cada vez maior de organismos   medida que se aproximam as partes mais altas     [E1] formações Itaituba [/E1] e Nova Olinda..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 777\n",
      "Token 1 =   Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   Carbonifero --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  has_age\n",
      "A aridez crescente em direção    final    [E2] Carbonifero [/E2] é comprovada      escassez cada vez maior de organismos   medida que se aproximam as partes mais altas     formações Itaituba e [E1] Nova Olinda [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 778\n",
      "Token 1 =   Morrowano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Morrowan_Age\n",
      "Token 2 =   Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      "entanto, outro fato parece ter influência: os ciclos durante o [E1] Morrowano [/E1] e [E2] Atokano [/E2] eram mais prolongados e havia tempo para maior permanência    ambiente marinho normal e, consequentemente, melhor desenvolvimento    fauna marinha..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 778\n",
      "Token 1 =   Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Morrowano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Morrowan_Age\n",
      "Relation Type =  temporal_relation\n",
      "entanto, outro fato parece ter influência: os ciclos durante o [E2] Morrowano [/E2] e [E1] Atokano [/E1] eram mais prolongados e havia tempo para maior permanência    ambiente marinho normal e, consequentemente, melhor desenvolvimento    fauna marinha..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 782\n",
      "Token 1 =   Atokano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Atokan_Age\n",
      "Token 2 =   Desmoinesiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Desmoinesian_Age\n",
      "Relation Type =  temporal_relation\n",
      ", hoje, que o [E1] Atokano [/E1] fazia parte anteriormente    [E2] Desmoinesiano [/E2], é possível que as datações de Petri (1956), por intermédio    que 7 - CONCLUSÕES\n",
      "-------------\n",
      "-------------\n",
      "sentence = 782\n",
      "Token 1 =   Desmoinesiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Desmoinesian_Age\n",
      "Token 2 =   Atokano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Atokan_Age\n",
      "Relation Type =  temporal_relation\n",
      ", hoje, que o [E2] Atokano [/E2] fazia parte anteriormente    [E1] Desmoinesiano [/E1], é possível que as datações de Petri (1956), por intermédio    que 7 - CONCLUSÕES\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 823\n",
      "Token 1 =   Formação Monte Alegre --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_232\n",
      "Token 2 =   Bacia Alto Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "LANZARINI, W. L. Facies sedimentares e ambiente deposicional    [E1] Formação Monte Alegre [/E1]    área de Juruá, [E2] Bacia    Alto Amazonas [/E2] - diagênese e permoporosidade     arenitos reservatórios..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 823\n",
      "Token 1 =   Formação Monte Alegre --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_232\n",
      "Token 2 =   arenitos --- Class 2 =  ROCHA --- URI 2 =  #sandstone\n",
      "Relation Type =  constituted_by\n",
      "LANZARINI, W. L. Facies sedimentares e ambiente deposicional    [E1] Formação Monte Alegre [/E1]    área de Juruá, Bacia    Alto Amazonas - diagênese e permoporosidade     [E2] arenitos [/E2] reservatórios..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 843\n",
      "Token 1 =   Formação itaituba --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_187\n",
      "Token 2 =   Bacia Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "SAVINI, R., ALTINER, D. A fauna de fusulinideos    poço 1 -    -1-AM ([E2] Bacia    Amazonas [/E2]): implicações para, um novo posicionamento cronoestratigráfico    [E1] Formação itaituba [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 910\n",
      "Token 1 =   Cretáceo Inferior --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #LowerCretaceous\n",
      "Token 2 =   Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "Evaporitos    [E1] Cretáceo Inferior [/E1] ([E2] Aptiano [/E2]) ocorrem de maneira expressiva    seqiiéncia sedimentar    Margem Continental Leste    Brasil, desde a Bacia de Alagoas até a Bacia de Santos, em espessuras que podem ultrapassar 1 km..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 910\n",
      "Token 1 =   Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Cretáceo Inferior --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #LowerCretaceous\n",
      "Relation Type =  temporal_relation\n",
      "Evaporitos    [E2] Cretáceo Inferior [/E2] ([E1] Aptiano [/E1]) ocorrem de maneira expressiva    seqiiéncia sedimentar    Margem Continental Leste    Brasil, desde a Bacia de Alagoas até a Bacia de Santos, em espessuras que podem ultrapassar 1 km..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 920\n",
      "Token 1 =   GTP-8 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_008339\n",
      "Token 2 =   Bacia de Sergipe --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "Os chevrons de halita analisados em amostras obtidas     testemunhos    perfuração [E1] GTP-8 [/E1], a porção terrestre    [E2] Bacia de Sergipe [/E2], indicam uma salmoura de composição enriquecida em cálcio e empobrecida em sulfato (tabela I), não compatível com os valores encontrados para esses elementos     oceanos modernos (Hardie, 1996)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 975\n",
      "Token 1 =   Formação Irati --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_254\n",
      "Token 2 =   folhelhos --- Class 2 =  ROCHA --- URI 2 =  #shale\n",
      "Relation Type =  constituted_by\n",
      "presumir, para o caso     [E2] folhelhos [/E2] carbonosos finamente laminados e com laminação espessa,    [E1] Formação Irati [/E1], que há maior probabilidade   associação com fluxos vinculados a eventos de tempestades..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1058\n",
      "Token 1 =   neopaleozóica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Paleozoic\n",
      "Token 2 =   Carbonífero Médio --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  temporal_relation\n",
      "A delimitação    seção [E1] neopaleozóica [/E1], que compreende as megasseqüências    [E2] Carbonífero Médio [/E2] e Permiano, compostas litologicamente de siliciclásticos, carbonatos e evaporitos, se faz necessária, posto que está entre os focos exploratórios    Companhia, principalmente após a descoberta de reservatórios portadores de hidrocarbonetos de excelente qualidade    área    Rio Uatumã..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1058\n",
      "Token 1 =   neopaleozóica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Paleozoic\n",
      "Token 2 =   Permiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Permian\n",
      "Relation Type =  temporal_relation\n",
      "A delimitação    seção [E1] neopaleozóica [/E1], que compreende as megasseqüências    Carbonífero Médio e [E2] Permiano [/E2], compostas litologicamente de siliciclásticos, carbonatos e evaporitos, se faz necessária, posto que está entre os focos exploratórios    Companhia, principalmente após a descoberta de reservatórios portadores de hidrocarbonetos de excelente qualidade    área    Rio Uatumã..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1058\n",
      "Token 1 =   Carbonífero Médio --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   neopaleozóica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Paleozoic\n",
      "Relation Type =  temporal_relation\n",
      "A delimitação    seção [E2] neopaleozóica [/E2], que compreende as megasseqüências    [E1] Carbonífero Médio [/E1] e Permiano, compostas litologicamente de siliciclásticos, carbonatos e evaporitos, se faz necessária, posto que está entre os focos exploratórios    Companhia, principalmente após a descoberta de reservatórios portadores de hidrocarbonetos de excelente qualidade    área    Rio Uatumã..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1058\n",
      "Token 1 =   Carbonífero Médio --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   Permiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Permian\n",
      "Relation Type =  temporal_relation\n",
      "A delimitação    seção neopaleozóica, que compreende as megasseqüências    [E1] Carbonífero Médio [/E1] e [E2] Permiano [/E2], compostas litologicamente de siliciclásticos, carbonatos e evaporitos, se faz necessária, posto que está entre os focos exploratórios    Companhia, principalmente após a descoberta de reservatórios portadores de hidrocarbonetos de excelente qualidade    área    Rio Uatumã..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1058\n",
      "Token 1 =   Permiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Permian\n",
      "Token 2 =   neopaleozóica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Paleozoic\n",
      "Relation Type =  temporal_relation\n",
      "A delimitação    seção [E2] neopaleozóica [/E2], que compreende as megasseqüências    Carbonífero Médio e [E1] Permiano [/E1], compostas litologicamente de siliciclásticos, carbonatos e evaporitos, se faz necessária, posto que está entre os focos exploratórios    Companhia, principalmente após a descoberta de reservatórios portadores de hidrocarbonetos de excelente qualidade    área    Rio Uatumã..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1058\n",
      "Token 1 =   Permiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Permian\n",
      "Token 2 =   Carbonífero Médio --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  temporal_relation\n",
      "A delimitação    seção neopaleozóica, que compreende as megasseqüências    [E2] Carbonífero Médio [/E2] e [E1] Permiano [/E1], compostas litologicamente de siliciclásticos, carbonatos e evaporitos, se faz necessária, posto que está entre os focos exploratórios    Companhia, principalmente após a descoberta de reservatórios portadores de hidrocarbonetos de excelente qualidade    área    Rio Uatumã..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1059\n",
      "Token 1 =   formações Monte Alegre --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_232\n",
      "Token 2 =   Grupo Tapajós --- Class 2 =  UNIDADE_LITO --- URI 2 =  #grupo_049\n",
      "Relation Type =  temporal_relation\n",
      "O [E2] Grupo Tapajós [/E2], conforme proposto por Caputo (1984), é constituído, em ordem ascen-dente,       [E1] formações Monte Alegre [/E1], Itaituba, Nova Olinda e Andirá..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1059\n",
      "Token 1 =   Itaituba --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_187\n",
      "Token 2 =   Grupo Tapajós --- Class 2 =  UNIDADE_LITO --- URI 2 =  #grupo_049\n",
      "Relation Type =  temporal_relation\n",
      "O [E2] Grupo Tapajós [/E2], conforme proposto por Caputo (1984), é constituído, em ordem ascen-dente,       formações Monte Alegre, [E1] Itaituba [/E1], Nova Olinda e Andirá..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1059\n",
      "Token 1 =   Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   Grupo Tapajós --- Class 2 =  UNIDADE_LITO --- URI 2 =  #grupo_049\n",
      "Relation Type =  temporal_relation\n",
      "O [E2] Grupo Tapajós [/E2], conforme proposto por Caputo (1984), é constituído, em ordem ascen-dente,       formações Monte Alegre, Itaituba, [E1] Nova Olinda [/E1] e Andirá..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1059\n",
      "Token 1 =   Andirá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_159\n",
      "Token 2 =   Grupo Tapajós --- Class 2 =  UNIDADE_LITO --- URI 2 =  #grupo_049\n",
      "Relation Type =  temporal_relation\n",
      "O [E2] Grupo Tapajós [/E2], conforme proposto por Caputo (1984), é constituído, em ordem ascen-dente,       formações Monte Alegre, Itaituba, Nova Olinda e [E1] Andirá [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1060\n",
      "Token 1 =   Carbonífero Médio --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   Pensilvaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pennsylvanian\n",
      "Relation Type =  temporal_relation\n",
      "Esta unidade litoestratigráfica, cuja espessura total atinge aproximadamente os 2 800 m, envolve o período de tempo que vai    [E1] Carbonífero Médio [/E1] ([E2] Pensilvaniano [/E2])    Permiano (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1060\n",
      "Token 1 =   Carbonífero Médio --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Carboniferous\n",
      "Token 2 =   Permiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Permian\n",
      "Relation Type =  temporal_relation\n",
      "Esta unidade litoestratigráfica, cuja espessura total atinge aproximadamente os 2 800 m, envolve o período de tempo que vai    [E1] Carbonífero Médio [/E1] (Pensilvaniano)    [E2] Permiano [/E2] (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1060\n",
      "Token 1 =   Pensilvaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pennsylvanian\n",
      "Token 2 =   Carbonífero Médio --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  temporal_relation\n",
      "Esta unidade litoestratigráfica, cuja espessura total atinge aproximadamente os 2 800 m, envolve o período de tempo que vai    [E2] Carbonífero Médio [/E2] ([E1] Pensilvaniano [/E1])    Permiano (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1060\n",
      "Token 1 =   Pensilvaniano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pennsylvanian\n",
      "Token 2 =   Permiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Permian\n",
      "Relation Type =  temporal_relation\n",
      "Esta unidade litoestratigráfica, cuja espessura total atinge aproximadamente os 2 800 m, envolve o período de tempo que vai    Carbonífero Médio ([E1] Pensilvaniano [/E1])    [E2] Permiano [/E2] (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1060\n",
      "Token 1 =   Permiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Permian\n",
      "Token 2 =   Carbonífero Médio --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Carboniferous\n",
      "Relation Type =  temporal_relation\n",
      "Esta unidade litoestratigráfica, cuja espessura total atinge aproximadamente os 2 800 m, envolve o período de tempo que vai    [E2] Carbonífero Médio [/E2] (Pensilvaniano)    [E1] Permiano [/E1] (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1060\n",
      "Token 1 =   Permiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Permian\n",
      "Token 2 =   Pensilvaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pennsylvanian\n",
      "Relation Type =  temporal_relation\n",
      "Esta unidade litoestratigráfica, cuja espessura total atinge aproximadamente os 2 800 m, envolve o período de tempo que vai    Carbonífero Médio ([E2] Pensilvaniano [/E2])    [E1] Permiano [/E1] (fig. 1)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1085\n",
      "Token 1 =   formações Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   conglomerados --- Class 2 =  ROCHA --- URI 2 =  #conglomerate\n",
      "Relation Type =  constituted_by\n",
      "Tais [E2] conglomerados [/E2], contidos entre as profun- considerações finais Estudos de detalhe     campos    bioestratigrafia, estratigrafia de seqüências e sismoestratigrafia, independentemente realizados, e ora integrados, permitiram estabelecer algumas conclusões de ordem estratigráfica a respeito    limite entre as [E1] formações Nova Olinda [/E1] e Andirá,    Grupo Tapajós, Bacia    Amazonas..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1085\n",
      "Token 1 =   formações Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   Grupo Tapajós --- Class 2 =  UNIDADE_LITO --- URI 2 =  #grupo_049\n",
      "Relation Type =  temporal_relation\n",
      "Tais conglomerados, contidos entre as profun- considerações finais Estudos de detalhe     campos    bioestratigrafia, estratigrafia de seqüências e sismoestratigrafia, independentemente realizados, e ora integrados, permitiram estabelecer algumas conclusões de ordem estratigráfica a respeito    limite entre as [E1] formações Nova Olinda [/E1] e Andirá,    [E2] Grupo Tapajós [/E2], Bacia    Amazonas..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1085\n",
      "Token 1 =   formações Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   Bacia Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "Tais conglomerados, contidos entre as profun- considerações finais Estudos de detalhe     campos    bioestratigrafia, estratigrafia de seqüências e sismoestratigrafia, independentemente realizados, e ora integrados, permitiram estabelecer algumas conclusões de ordem estratigráfica a respeito    limite entre as [E1] formações Nova Olinda [/E1] e Andirá,    Grupo Tapajós, [E2] Bacia    Amazonas [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1085\n",
      "Token 1 =   Andirá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_159\n",
      "Token 2 =   conglomerados --- Class 2 =  ROCHA --- URI 2 =  #conglomerate\n",
      "Relation Type =  constituted_by\n",
      "Tais [E2] conglomerados [/E2], contidos entre as profun- considerações finais Estudos de detalhe     campos    bioestratigrafia, estratigrafia de seqüências e sismoestratigrafia, independentemente realizados, e ora integrados, permitiram estabelecer algumas conclusões de ordem estratigráfica a respeito    limite entre as formações Nova Olinda e [E1] Andirá [/E1],    Grupo Tapajós, Bacia    Amazonas..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1085\n",
      "Token 1 =   Andirá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_159\n",
      "Token 2 =   Grupo Tapajós --- Class 2 =  UNIDADE_LITO --- URI 2 =  #grupo_049\n",
      "Relation Type =  temporal_relation\n",
      "Tais conglomerados, contidos entre as profun- considerações finais Estudos de detalhe     campos    bioestratigrafia, estratigrafia de seqüências e sismoestratigrafia, independentemente realizados, e ora integrados, permitiram estabelecer algumas conclusões de ordem estratigráfica a respeito    limite entre as formações Nova Olinda e [E1] Andirá [/E1],    [E2] Grupo Tapajós [/E2], Bacia    Amazonas..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1085\n",
      "Token 1 =   Andirá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_159\n",
      "Token 2 =   Bacia Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "Tais conglomerados, contidos entre as profun- considerações finais Estudos de detalhe     campos    bioestratigrafia, estratigrafia de seqüências e sismoestratigrafia, independentemente realizados, e ora integrados, permitiram estabelecer algumas conclusões de ordem estratigráfica a respeito    limite entre as formações Nova Olinda e [E1] Andirá [/E1],    Grupo Tapajós, [E2] Bacia    Amazonas [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1085\n",
      "Token 1 =   Grupo Tapajós --- Class 1 =  UNIDADE_LITO --- URI 1 =  #grupo_049\n",
      "Token 2 =   Bacia Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "Tais conglomerados, contidos entre as profun- considerações finais Estudos de detalhe     campos    bioestratigrafia, estratigrafia de seqüências e sismoestratigrafia, independentemente realizados, e ora integrados, permitiram estabelecer algumas conclusões de ordem estratigráfica a respeito    limite entre as formações Nova Olinda e Andirá,    [E1] Grupo Tapajós [/E1], [E2] Bacia    Amazonas [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1086\n",
      "Token 1 =   poço 9-FZ-2-AM --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_023241\n",
      "Token 2 =   Formação Nova Olinda --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_028\n",
      "Relation Type =  crosses\n",
      "A [E2] Formação Nova Olinda [/E2] engloba uma expressiva discordância em sua porção superior,       modo,             aqui a questão    contato entre as formações Nova Olinda e Andirá, a partir    estudo    intervalo 1 217,00 m a 1 350,00 m    [E1] poço 9-FZ-2-AM [/E1]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1086\n",
      "Token 1 =   poço 9-FZ-2-AM --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_023241\n",
      "Token 2 =   formações Nova Olinda --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_028\n",
      "Relation Type =  crosses\n",
      "A Formação Nova Olinda engloba uma expressiva discordância em sua porção superior,       modo,             aqui a questão    contato entre as [E2] formações Nova Olinda [/E2] e Andirá, a partir    estudo    intervalo 1 217,00 m a 1 350,00 m    [E1] poço 9-FZ-2-AM [/E1]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1086\n",
      "Token 1 =   poço 9-FZ-2-AM --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_023241\n",
      "Token 2 =   Andirá --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_159\n",
      "Relation Type =  crosses\n",
      "A Formação Nova Olinda engloba uma expressiva discordância em sua porção superior,       modo,             aqui a questão    contato entre as formações Nova Olinda e [E2] Andirá [/E2], a partir    estudo    intervalo 1 217,00 m a 1 350,00 m    [E1] poço 9-FZ-2-AM [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1087\n",
      "Token 1 =   Formação Nova Olinda --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_028\n",
      "Token 2 =   conglomerado --- Class 2 =  ROCHA --- URI 2 =  #conglomerate\n",
      "Relation Type =  constituted_by\n",
      ", também, que o limite superior    [E1] Formação Nova Olinda [/E1] seja posicionado    base    pacote de [E2] conglomerado [/E2] intraformacional de coloração avermelhada-escura a 1 271,50 m; sendo a seção siliciclástica sotoposta   base    Formação Andirá..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1087\n",
      "Token 1 =   Formação Andirá --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_159\n",
      "Token 2 =   conglomerado --- Class 2 =  ROCHA --- URI 2 =  #conglomerate\n",
      "Relation Type =  constituted_by\n",
      ", também, que o limite superior    Formação Nova Olinda seja posicionado    base    pacote de [E2] conglomerado [/E2] intraformacional de coloração avermelhada-escura a 1 271,50 m; sendo a seção siliciclástica sotoposta   base    [E1] Formação Andirá [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic type of, involving storid 388\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "sentence = 1146\n",
      "Token 1 =   Grupo Tapajós --- Class 1 =  UNIDADE_LITO --- URI 1 =  #grupo_049\n",
      "Token 2 =   Pensilvaniano Inferior --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Bashkirian\n",
      "Relation Type =  has_age\n",
      "Marinhos    [E1] Grupo Tapajós [/E1], [E2] Pensilvaniano Inferior [/E2] a Médio    Bacia    Amazonas com aplicação de isótopos de Sr e Nd       intervalo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1146\n",
      "Token 1 =   Grupo Tapajós --- Class 1 =  UNIDADE_LITO --- URI 1 =  #grupo_049\n",
      "Token 2 =   Bacia Amazonas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_030\n",
      "Relation Type =  located_in\n",
      "Marinhos    [E1] Grupo Tapajós [/E1], Pensilvaniano Inferior a Médio    [E2] Bacia    Amazonas [/E2] com aplicação de isótopos de Sr e Nd       intervalo..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1165\n",
      "Token 1 =   Formação Jandaíra --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_158\n",
      "Token 2 =   Bacia Potiguar --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_100\n",
      "Relation Type =  located_in\n",
      "em Engenharia Geológica      Universidade Federal de Ouro Preto, em 1984, com Mestrado em Análises de Bacias Sedimentares      Universidade Federal de Ouro Preto, em 1988, com o tema: Marco radioativo    [E1] Formação Jandaíra [/E1], [E2] Bacia    Potiguar [/E2], resultado que gerou a descoberta    fosfato Campaniano..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1165\n",
      "Token 1 =   Formação Jandaíra --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_158\n",
      "Token 2 =   Campaniano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Campanian\n",
      "Relation Type =  has_age\n",
      "em Engenharia Geológica      Universidade Federal de Ouro Preto, em 1984, com Mestrado em Análises de Bacias Sedimentares      Universidade Federal de Ouro Preto, em 1988, com o tema: Marco radioativo    [E1] Formação Jandaíra [/E1], Bacia    Potiguar, resultado que gerou a descoberta    fosfato [E2] Campaniano [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1306\n",
      "Token 1 =   holocênicos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   pleistocênicos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "encontro     postulados de Longman, estudos de carbonatos [E1] holocênicos [/E1] e [E2] pleistocênicos [/E2] evidenciam a rapidez     modificações diagenéticas, tanto    dissolução como    cimentação..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1306\n",
      "Token 1 =   pleistocênicos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   holocênicos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "encontro     postulados de Longman, estudos de carbonatos [E2] holocênicos [/E2] e [E1] pleistocênicos [/E1] evidenciam a rapidez     modificações diagenéticas, tanto    dissolução como    cimentação..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1320\n",
      "Token 1 =   holocênicos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   pleistocênicos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "Halley e Evans (1983, em Scholle e Halley, 1985), estudando carbonatos [E1] holocênicos [/E1] e [E2] pleistocênicos [/E2]    Província Flórida/Bahamas, demonstraram que as porosidades médias        rochas permanecem essencialmente             mantendo seus altos valores, mesmo quando submetidas    profundas alterações diagenéticas, incluíndo aí a transformação quase total    aragonita em calcita..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1320\n",
      "Token 1 =   pleistocênicos --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   holocênicos --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "Halley e Evans (1983, em Scholle e Halley, 1985), estudando carbonatos [E2] holocênicos [/E2] e [E1] pleistocênicos [/E1]    Província Flórida/Bahamas, demonstraram que as porosidades médias        rochas permanecem essencialmente             mantendo seus altos valores, mesmo quando submetidas    profundas alterações diagenéticas, incluíndo aí a transformação quase total    aragonita em calcita..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1341\n",
      "Token 1 =   Campo de Pampo --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0750\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "[E1] Campo de Pampo [/E1], [E2] Bacia de Campos [/E2], onde a profundidade de soterramento     reservatórios calcários albianos é de cerca de 1 800 m,            que packstones peloidais    base de ciclos de rasamento ascendente (shoaling-up cycles) apresentam porosidades    ordem de 30%, enquanto os grainstones oolíticos    topo     ciclos mostram porosidades menores (fig. 5)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1449\n",
      "Token 1 =   holocênica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   pleistocênica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "Tal superfície representa um limite de seqüências, separando a seqüência [E1] holocênica [/E1]    [E2] pleistocênica [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1449\n",
      "Token 1 =   pleistocênica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   holocênica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "Tal superfície representa um limite de seqüências, separando a seqüência [E2] holocênica [/E2]    [E1] pleistocênica [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1456\n",
      "Token 1 =   Manati --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0888\n",
      "Token 2 =   Bacia de Camamu --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_266\n",
      "Relation Type =  located_in\n",
      "Com a descoberta    campo de gás de [E1] Manati [/E1],    [E2] Bacia de Camamu [/E2], a exploração de hidrocarbonetos    plataforma continental central    Estado    Bahia recebeu um grande impulso, demandando mais conhecimentos geológicos..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1457\n",
      "Token 1 =   Campo de Manati --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0888\n",
      "Token 2 =   bacias de Camamu --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_266\n",
      "Relation Type =  located_in\n",
      "Em função    perspectiva de novas descobertas     [E2] bacias de Camamu [/E2] e de Almada, o presente trabalho foi realizado    sul    [E1] Campo de Manati [/E1], tendo sua área de estudo a cerca de 300 km de Salvador, entre a Ponta    Mutá e a cidade de Olivença (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1457\n",
      "Token 1 =   Campo de Manati --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0888\n",
      "Token 2 =   Almada --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_266\n",
      "Relation Type =  located_in\n",
      "Em função    perspectiva de novas descobertas     bacias de Camamu e de [E2] Almada [/E2], o presente trabalho foi realizado    sul    [E1] Campo de Manati [/E1], tendo sua área de estudo a cerca de 300 km de Salvador, entre a Ponta    Mutá e a cidade de Olivença (fig. 1)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1503\n",
      "Token 1 =   Pleistoceno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   Holoceno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "A maioria     amostras foi caracterizada como sendo de sedimentos retrabalhados, contendo fósseis tanto    [E1] Pleistoceno [/E1] quanto    [E2] Holoceno [/E2], sendo datadas    Quaternário indiviso..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1503\n",
      "Token 1 =   Pleistoceno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   Quaternário --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Quaternary\n",
      "Relation Type =  temporal_relation\n",
      "A maioria     amostras foi caracterizada como sendo de sedimentos retrabalhados, contendo fósseis tanto    [E1] Pleistoceno [/E1] quanto    Holoceno, sendo datadas    [E2] Quaternário [/E2] indiviso..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1503\n",
      "Token 1 =   Holoceno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   Pleistoceno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "A maioria     amostras foi caracterizada como sendo de sedimentos retrabalhados, contendo fósseis tanto    [E2] Pleistoceno [/E2] quanto    [E1] Holoceno [/E1], sendo datadas    Quaternário indiviso..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1503\n",
      "Token 1 =   Holoceno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   Quaternário --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Quaternary\n",
      "Relation Type =  temporal_relation\n",
      "A maioria     amostras foi caracterizada como sendo de sedimentos retrabalhados, contendo fósseis tanto    Pleistoceno quanto    [E1] Holoceno [/E1], sendo datadas    [E2] Quaternário [/E2] indiviso..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1503\n",
      "Token 1 =   Quaternário --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Quaternary\n",
      "Token 2 =   Pleistoceno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "A maioria     amostras foi caracterizada como sendo de sedimentos retrabalhados, contendo fósseis tanto    [E2] Pleistoceno [/E2] quanto    Holoceno, sendo datadas    [E1] Quaternário [/E1] indiviso..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1503\n",
      "Token 1 =   Quaternário --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Quaternary\n",
      "Token 2 =   Holoceno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "A maioria     amostras foi caracterizada como sendo de sedimentos retrabalhados, contendo fósseis tanto    Pleistoceno quanto    [E2] Holoceno [/E2], sendo datadas    [E1] Quaternário [/E1] indiviso..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1555\n",
      "Token 1 =   Holoceno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   Pleistoceno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "Limite de seqüência entre o [E1] Holoceno [/E1] e o [E2] Pleistoceno [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1555\n",
      "Token 1 =   Pleistoceno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   Holoceno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "Limite de seqüência entre o [E2] Holoceno [/E2] e o [E1] Pleistoceno [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1597\n",
      "Token 1 =   pleistocênica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   holocênica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "Esta superfície é o limite entre as seqüências [E1] pleistocênica [/E1] e [E2] holocênica [/E2], podendo ser claramente identificada     perfis de sísmica rasa..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1597\n",
      "Token 1 =   holocênica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   pleistocênica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "Esta superfície é o limite entre as seqüências [E2] pleistocênica [/E2] e [E1] holocênica [/E1], podendo ser claramente identificada     perfis de sísmica rasa..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1629\n",
      "Token 1 =   holocênica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Holocene\n",
      "Token 2 =   pleistocênica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Pleistocene\n",
      "Relation Type =  temporal_relation\n",
      "O limite entre as seqüências [E1] holocênica [/E1] e [E2] pleistocênica [/E2] é representado por uma superfície endurecida observada     perfis de sísmica rasa, a qual limita a penetração de testemunhagem..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1629\n",
      "Token 1 =   pleistocênica --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Pleistocene\n",
      "Token 2 =   holocênica --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Holocene\n",
      "Relation Type =  temporal_relation\n",
      "O limite entre as seqüências [E2] holocênica [/E2] e [E1] pleistocênica [/E1] é representado por uma superfície endurecida observada     perfis de sísmica rasa, a qual limita a penetração de testemunhagem..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1784\n",
      "Token 1 =   Campo de Sesmaria --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0932\n",
      "Token 2 =   Bacia Recôncavo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_240\n",
      "Relation Type =  located_in\n",
      "O [E1] Campo de Sesmaria [/E1], localizado    compartimento nordeste    [E2] Bacia    Recôncavo [/E2], foi descoberto em 1966 e é produtor de óleo, principalmente    Formação Sergi..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1784\n",
      "Token 1 =   Formação Sergi --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_239\n",
      "Token 2 =   Bacia Recôncavo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_240\n",
      "Relation Type =  located_in\n",
      "O Campo de Sesmaria, localizado    compartimento nordeste    [E2] Bacia    Recôncavo [/E2], foi descoberto em 1966 e é produtor de óleo, principalmente    [E1] Formação Sergi [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1801\n",
      "Token 1 =   Formação Sergi --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_239\n",
      "Token 2 =   Bacia Recôncavo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_240\n",
      "Relation Type =  located_in\n",
      "A análise de 138 lâminas delgadas mostrou que os mais altos teores de cimento    [E1] Formação Sergi [/E1],     campos    [E2] Bacia    Recôncavo [/E2], são encontrados    Campo de Sesmaria..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1801\n",
      "Token 1 =   Campo de Sesmaria --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0932\n",
      "Token 2 =   Bacia Recôncavo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_240\n",
      "Relation Type =  located_in\n",
      "A análise de 138 lâminas delgadas mostrou que os mais altos teores de cimento    Formação Sergi,     campos    [E2] Bacia    Recôncavo [/E2], são encontrados    [E1] Campo de Sesmaria [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1852\n",
      "Token 1 =   poços PIR-49 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007040\n",
      "Token 2 =   Campo de Pilar --- Class 2 =  CAMPO --- URI 2 =  #CAMP_CD_CAMPO_0773\n",
      "Relation Type =  located_in\n",
      "A partir       estudo    área sudeste    [E2] Campo de Pilar [/E2], definida       [E1] poços PIR-49 [/E1], 78, 89 e 85, foi possível constatar,    Formação Coqueito Seco, a ocorrência de feições de canal, de frente deltaica, de estratificações cruzadas e lobos de suspensão..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1852\n",
      "Token 1 =   poços PIR-49 --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007040\n",
      "Token 2 =   Formação Coqueito Seco --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_009\n",
      "Relation Type =  crosses\n",
      "A partir       estudo    área sudeste    Campo de Pilar, definida       [E1] poços PIR-49 [/E1], 78, 89 e 85, foi possível constatar,    [E2] Formação Coqueito Seco [/E2], a ocorrência de feições de canal, de frente deltaica, de estratificações cruzadas e lobos de suspensão..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1967\n",
      "Token 1 =   poços 3-PIR-49-AL --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007040\n",
      "Token 2 =   Campo de Pilar --- Class 2 =  CAMPO --- URI 2 =  #CAMP_CD_CAMPO_0773\n",
      "Relation Type =  located_in\n",
      "Visando   aplicação     conhecimentos adquiridos, foi selecionada, para interpretação estrutural e estratigráfica, uma área    extremo sudeste    [E2] Campo de Pilar [/E2] — AL, que compreende os [E1] poços 3-PIR-49-AL [/E1], 3-PIR-78-AL, 3-PIR-85-AL e 3-PIR-89-AL (fig, 12)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1967\n",
      "Token 1 =   3-PIR-78-AL --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007020\n",
      "Token 2 =   Campo de Pilar --- Class 2 =  CAMPO --- URI 2 =  #CAMP_CD_CAMPO_0773\n",
      "Relation Type =  located_in\n",
      "Visando   aplicação     conhecimentos adquiridos, foi selecionada, para interpretação estrutural e estratigráfica, uma área    extremo sudeste    [E2] Campo de Pilar [/E2] — AL, que compreende os poços 3-PIR-49-AL, [E1] 3-PIR-78-AL [/E1], 3-PIR-85-AL e 3-PIR-89-AL (fig, 12)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1967\n",
      "Token 1 =   3-PIR-85-AL --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007076\n",
      "Token 2 =   Campo de Pilar --- Class 2 =  CAMPO --- URI 2 =  #CAMP_CD_CAMPO_0773\n",
      "Relation Type =  located_in\n",
      "Visando   aplicação     conhecimentos adquiridos, foi selecionada, para interpretação estrutural e estratigráfica, uma área    extremo sudeste    [E2] Campo de Pilar [/E2] — AL, que compreende os poços 3-PIR-49-AL, 3-PIR-78-AL, [E1] 3-PIR-85-AL [/E1] e 3-PIR-89-AL (fig, 12)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1967\n",
      "Token 1 =   3-PIR-89-AL --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007052\n",
      "Token 2 =   Campo de Pilar --- Class 2 =  CAMPO --- URI 2 =  #CAMP_CD_CAMPO_0773\n",
      "Relation Type =  located_in\n",
      "Visando   aplicação     conhecimentos adquiridos, foi selecionada, para interpretação estrutural e estratigráfica, uma área    extremo sudeste    [E2] Campo de Pilar [/E2] — AL, que compreende os poços 3-PIR-49-AL, 3-PIR-78-AL, 3-PIR-85-AL e [E1] 3-PIR-89-AL [/E1] (fig, 12)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1981\n",
      "Token 1 =   Poço 3-PIR-49-AL --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007040\n",
      "Token 2 =   Formação Coqueiro --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_009\n",
      "Relation Type =  crosses\n",
      "Fig. 17 - [E1] Poço 3-PIR-49-AL [/E1]; [E2] Formação Coqueiro [/E2]\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1983\n",
      "Token 1 =   Poço 3-PIR-85-AL --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007076\n",
      "Token 2 =   Formação Coqueiro --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_009\n",
      "Relation Type =  crosses\n",
      "Fig. 19 - [E1] Poço 3-PIR-85-AL [/E1]; [E2] Formação Coqueiro [/E2]\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 1985\n",
      "Token 1 =   Poço 3-PIR-78-AL --- Class 1 =  POÇO --- URI 1 =  #POCO_CD_POCO_007020\n",
      "Token 2 =   Formação Coqueiro --- Class 2 =  UNIDADE_LITO --- URI 2 =  #formacao_009\n",
      "Relation Type =  crosses\n",
      "Fig. 22 - [E1] Poço 3-PIR-78-AL [/E1]; [E2] Formação Coqueiro [/E2]\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2191\n",
      "Token 1 =   Campo de Moréia --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0718\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "[E1] Campo de Moréia [/E1], parte     reservatórios    Campo de Caratinga, e vários arenitos delgados de idades diversas que aparecem preenchendo canyons    [E2] Bacia de Campos [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2191\n",
      "Token 1 =   Campo de Caratinga --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0247\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "Campo de Moréia, parte     reservatórios    [E1] Campo de Caratinga [/E1], e vários arenitos delgados de idades diversas que aparecem preenchendo canyons    [E2] Bacia de Campos [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2192\n",
      "Token 1 =   Formação Calumbi --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_027\n",
      "Token 2 =   Bacia de Sergipe/Alagoas --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_116\n",
      "Relation Type =  located_in\n",
      "A maior parte     reservatórios    [E1] Formação Calumbi [/E1],    [E2] Bacia de Sergipe/Alagoas [/E2], também depositados em canyons ou pequenas depressões intra-talude, também se enquadram       categoria..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2197\n",
      "Token 1 =   Campo de Lagoa Parda --- Class 1 =  CAMPO --- URI 1 =  #CAMP_CD_CAMPO_0603\n",
      "Token 2 =   Bacia Espírito Santo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_270\n",
      "Relation Type =  located_in\n",
      "Figura Seção estratigráfica    [E1] Campo de Lagoa Parda [/E1] ([E2] Bacia    Espírito Santo [/E2]), apresentando a arquitetura típica    complexo de canais discretos que constitui os reservatórios eocênicos..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2237\n",
      "Token 1 =   Formação Urucutuca --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_262\n",
      "Token 2 =   Bacia de Almada --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_266\n",
      "Relation Type =  located_in\n",
      "BRUHN, C. H. L.; MORAES, M. A. S., Turbiditos    [E1] Formação Urucutuca [/E1]    [E2] Bacia de Almada [/E2], Bahia : um laboratório de campo para o estudo de reservatórios canalizados..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2268\n",
      "Token 1 =   Fm. Carapebus --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_110\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "MACHADO, L. C. R.; KOWSMANN, R. O.; ALMEIDA JUNIOR, W.; MURAKAMI, C. Y.; SCHREINER, S.; MILLER, D. J.; PIAUILINO, P. O. V. Geometria    porção proximal    sistema deposicional turbidítico moderno    [E1] Fm. Carapebus [/E1], [E2] Bacia de Campos [/E2] : modelo para heterogeneidades de reservatório..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2309\n",
      "Token 1 =   Paleogeno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Paleogene\n",
      "Token 2 =   Paleoceno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Paleocene\n",
      "Relation Type =  temporal_relation\n",
      "Os tipos litológicos predominantes são rochas vulcânicas (basaltos), mas também ocorrem rochas intrusivas e vulcanoclásticas (autoclásticas e piroclásticas) e até ultrabásicas, cujas idades radiométricas Ar-Ar coincidem com o [E1] Paleogeno [/E1] ([E2] Paleoceno [/E2]    Mesoeoceno)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2309\n",
      "Token 1 =   Paleoceno --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Paleocene\n",
      "Token 2 =   Paleogeno --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Paleogene\n",
      "Relation Type =  temporal_relation\n",
      "Os tipos litológicos predominantes são rochas vulcânicas (basaltos), mas também ocorrem rochas intrusivas e vulcanoclásticas (autoclásticas e piroclásticas) e até ultrabásicas, cujas idades radiométricas Ar-Ar coincidem com o [E2] Paleogeno [/E2] ([E1] Paleoceno [/E1]    Mesoeoceno)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2360\n",
      "Token 1 =   Formação Cabiúnas --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_222\n",
      "Token 2 =   basaltos --- Class 2 =  ROCHA --- URI 2 =  #basalt\n",
      "Relation Type =  constituted_by\n",
      "A composição    vidro vulcânico constituinte     vulcanoclastos originais seria equivalente     traquitos, ou seja, distinta             rochas vulcânicas    [E1] Formação Cabiúnas [/E1] (constituídas por [E2] basaltos [/E2] toleíticos com várias texturas petrográficas) e demais rochas ígneas encontradas    Bacia de Campos (fig. 1)..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2360\n",
      "Token 1 =   Formação Cabiúnas --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_222\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "A composição    vidro vulcânico constituinte     vulcanoclastos originais seria equivalente     traquitos, ou seja, distinta             rochas vulcânicas    [E1] Formação Cabiúnas [/E1] (constituídas por basaltos toleíticos com várias texturas petrográficas) e demais rochas ígneas encontradas    [E2] Bacia de Campos [/E2] (fig. 1)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2367\n",
      "Token 1 =   Formação Ubatuba --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_289\n",
      "Token 2 =   vulcanoclastos --- Class 2 =  NÃOCONSOLID --- URI 2 =  #pyroclast\n",
      "Relation Type =  temporal_relation\n",
      "Dispersos      ação     ventos, os [E2] vulcanoclastos [/E2] acabaram por se depositar interdigitados     sedimentos marinhos    [E1] Formação Ubatuba [/E1] e de sua alteração (halmirólise) resultaram as bentonitas estudadas (fig. 3)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2399\n",
      "Token 1 =   Formação Cabiúnas --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_222\n",
      "Token 2 =   diabásio --- Class 2 =  ROCHA --- URI 2 =  #diabase\n",
      "Relation Type =  constituted_by\n",
      "Através de um reconhecimento tectono-estrutural    Faixa Colatina, entre as cidades de Vitória-ES e Nova Venécia-ES, realizado    período de 20 a 23 de outubro de 2003,              um conjunto de afloramentos de diques de [E2] diabásio [/E2] de direção geral NNW-SSE, que pode ser correlato    seqüências vulcânicas    [E1] Formação Cabiúnas [/E1]     bacias de Campos e    Espírito Santo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2399\n",
      "Token 1 =   Formação Cabiúnas --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_222\n",
      "Token 2 =   bacias de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "Através de um reconhecimento tectono-estrutural    Faixa Colatina, entre as cidades de Vitória-ES e Nova Venécia-ES, realizado    período de 20 a 23 de outubro de 2003,              um conjunto de afloramentos de diques de diabásio de direção geral NNW-SSE, que pode ser correlato    seqüências vulcânicas    [E1] Formação Cabiúnas [/E1]     [E2] bacias de Campos [/E2] e    Espírito Santo..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2399\n",
      "Token 1 =   Formação Cabiúnas --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_222\n",
      "Token 2 =   Espírito Santo --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_270\n",
      "Relation Type =  located_in\n",
      "Através de um reconhecimento tectono-estrutural    Faixa Colatina, entre as cidades de Vitória-ES e Nova Venécia-ES, realizado    período de 20 a 23 de outubro de 2003,              um conjunto de afloramentos de diques de diabásio de direção geral NNW-SSE, que pode ser correlato    seqüências vulcânicas    [E1] Formação Cabiúnas [/E1]     bacias de Campos e    [E2] Espírito Santo [/E2]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2400\n",
      "Token 1 =   Barremiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Barremian\n",
      "Token 2 =   Aptiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Aptian\n",
      "Relation Type =  temporal_relation\n",
      "A evolução tectônica    Bacia    Espírito Santo está associada   ruptura continental    Gondwana, que inclui um processo de extensão    crosta, cujo registro sedimentar possui      menos três seqüências rifte: Neocomiano, [E1] Barremiano [/E1] e [E2] Aptiano [/E2]..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2400\n",
      "Token 1 =   Aptiano --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Aptian\n",
      "Token 2 =   Barremiano --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Barremian\n",
      "Relation Type =  temporal_relation\n",
      "A evolução tectônica    Bacia    Espírito Santo está associada   ruptura continental    Gondwana, que inclui um processo de extensão    crosta, cujo registro sedimentar possui      menos três seqüências rifte: Neocomiano, [E2] Barremiano [/E2] e [E1] Aptiano [/E1]..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2420\n",
      "Token 1 =   Formação Cabiúnas --- Class 1 =  UNIDADE_LITO --- URI 1 =  #formacao_222\n",
      "Token 2 =   Bacia de Campos --- Class 2 =  BACIA --- URI 2 =  #BASE_CD_BACIA_281\n",
      "Relation Type =  located_in\n",
      "Estas análises sugerem que tal evento tenha sido contemporâneo    vulcânicas    [E1] Formação Cabiúnas [/E1]    [E2] Bacia de Campos [/E2] e    vulcanismo Serra Geral    Bacia    Paraná, que é de 127/137 Ma (Teixeira e Rodarte, 2003)..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2426\n",
      "Token 1 =   idade neocomiana --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #Valanginian\n",
      "Token 2 =   Cretáceo Inferior --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #LowerCretaceous\n",
      "Relation Type =  temporal_relation\n",
      "Mesmo com a expectativa     resultados futuros    datação isotópica de algumas amostras,         inferir uma contemporaneidade    DV com os de Santa Leopoldina, cujas datações indicam [E1] idade neocomiana [/E1] ([E2] Cretáceo Inferior [/E2])..\n",
      "-------------\n",
      "-------------\n",
      "sentence = 2426\n",
      "Token 1 =   Cretáceo Inferior --- Class 1 =  UNIDADE_CRONO --- URI 1 =  #LowerCretaceous\n",
      "Token 2 =   idade neocomiana --- Class 2 =  UNIDADE_CRONO --- URI 2 =  #Valanginian\n",
      "Relation Type =  temporal_relation\n",
      "Mesmo com a expectativa     resultados futuros    datação isotópica de algumas amostras,         inferir uma contemporaneidade    DV com os de Santa Leopoldina, cujas datações indicam [E2] idade neocomiana [/E2] ([E1] Cretáceo Inferior [/E1])..\n",
      "-------------\n",
      "Saved Json -> True\n",
      "-------------\n",
      "-------------\n",
      "Number of Jsons saved =  85\n",
      "Wall time: 43min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "numberSentences = df_filtred_sentences.iloc[-1]['sentence'] #numero de sentencas diferentes no arquivo ja filtrado\n",
    "lista_relacoes, lista_uris, lista_classes, list_sentences_dict = [], [], [], []\n",
    "df_relation, df_bert = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "countJsons=0\n",
    "for idx in range(1,len(df_group)):\n",
    "    filtred_sentence = df_group.get_group(idx)#aqui filtred_sentence é um dataframe da sentenca\n",
    "    originalSentenceNumber = filtred_sentence.iloc[0]['#sentence_original']\n",
    "    text = filtred_sentence.iloc[0]['text']\n",
    "    lista_relacoes,lista_uris,lista_classes,df_bert,\\\n",
    "    df_relation,df_entity,lista_relacoes_sentence,\\\n",
    "    from_id,to_id, is_to_save = go_through_sentence(filtred_sentence,df_relation,df_bert,originalSentenceNumber) \n",
    "    df_bert.to_csv(save_csv_name, encoding='utf-8',index=False)\n",
    "    df_relation.to_csv('df_relation_valid.csv', encoding='utf-8',index=False)\n",
    "    if is_to_save and is_to_createJsons:#Jsons somente criados para sentencas com relacao\n",
    "        countJsons+=1\n",
    "        saveJsonFiles(df_entity,from_id,to_id, \n",
    "                      lista_relacoes_sentence,filtred_sentence,originalSentenceNumber,save_folder_path)\n",
    "#     raise SystemExit(\"Stop right there!\")    \n",
    "print(\"-------------\")\n",
    "print(\"Number of Jsons saved = \", countJsons)\n",
    "\n",
    "# pickle.dump(df_relation, open('df_relation.pkl','wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "df_relation.to_csv('df_relation_valid.csv', encoding='utf-8',index=False)\n",
    "df_bert.to_csv(save_csv_name, encoding='utf-8',index=False)\n",
    "\n",
    "relacoes, numb_rel = np.unique(lista_relacoes, return_counts = True)\n",
    "pickle.dump(lista_relacoes,open('lista_relacoes_valid.pkl','wb'),protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "uris, numb_uris = np.unique(lista_uris, return_counts = True)\n",
    "pickle.dump(lista_uris,open('lista_uris_valid.pkl','wb'),protocol = pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "classes, numb_classes = np.unique(lista_classes, return_counts = True)\n",
    "pickle.dump(lista_classes,open('lista_classes_valid.pkl','wb'),protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das relações encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['constituted_by',\n",
       " 'crosses',\n",
       " 'has_age',\n",
       " 'interval_finishes',\n",
       " 'located_in',\n",
       " 'temporal_relation']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relacoes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[402, 29, 191, 1, 526, 1143]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_rel.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das classes encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BACIA',\n",
       " 'CAMPO',\n",
       " 'NÃOCONSOLID',\n",
       " 'POÇO',\n",
       " 'ROCHA',\n",
       " 'UNIDADE_CRONO',\n",
       " 'UNIDADE_LITO']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[492, 162, 7, 118, 402, 2246, 1157]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_classes.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contabilização das URIs encontradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Alagoas_Age',\n",
       " '#Albian',\n",
       " '#Aptian',\n",
       " '#Aratu_Age',\n",
       " '#Archean',\n",
       " '#Atokan_Age',\n",
       " '#BASE_CD_BACIA_020',\n",
       " '#BASE_CD_BACIA_030',\n",
       " '#BASE_CD_BACIA_051',\n",
       " '#BASE_CD_BACIA_076',\n",
       " '#BASE_CD_BACIA_080',\n",
       " '#BASE_CD_BACIA_090',\n",
       " '#BASE_CD_BACIA_096',\n",
       " '#BASE_CD_BACIA_100',\n",
       " '#BASE_CD_BACIA_106',\n",
       " '#BASE_CD_BACIA_116',\n",
       " '#BASE_CD_BACIA_210',\n",
       " '#BASE_CD_BACIA_215',\n",
       " '#BASE_CD_BACIA_230',\n",
       " '#BASE_CD_BACIA_240',\n",
       " '#BASE_CD_BACIA_250',\n",
       " '#BASE_CD_BACIA_256',\n",
       " '#BASE_CD_BACIA_260',\n",
       " '#BASE_CD_BACIA_266',\n",
       " '#BASE_CD_BACIA_270',\n",
       " '#BASE_CD_BACIA_281',\n",
       " '#BASE_CD_BACIA_300',\n",
       " '#BASE_CD_BACIA_316',\n",
       " '#BASE_CD_BACIA_381',\n",
       " '#Barremian',\n",
       " '#Bartonian',\n",
       " '#Bashkirian',\n",
       " '#Berriasian',\n",
       " '#Buracica_Age',\n",
       " '#Burdigalian',\n",
       " '#CAMP_CD_CAMPO_0003',\n",
       " '#CAMP_CD_CAMPO_0004',\n",
       " '#CAMP_CD_CAMPO_0012',\n",
       " '#CAMP_CD_CAMPO_0017',\n",
       " '#CAMP_CD_CAMPO_0027',\n",
       " '#CAMP_CD_CAMPO_0065',\n",
       " '#CAMP_CD_CAMPO_0077',\n",
       " '#CAMP_CD_CAMPO_0082',\n",
       " '#CAMP_CD_CAMPO_0093',\n",
       " '#CAMP_CD_CAMPO_0118',\n",
       " '#CAMP_CD_CAMPO_0174',\n",
       " '#CAMP_CD_CAMPO_0179',\n",
       " '#CAMP_CD_CAMPO_0199',\n",
       " '#CAMP_CD_CAMPO_0214',\n",
       " '#CAMP_CD_CAMPO_0234',\n",
       " '#CAMP_CD_CAMPO_0239',\n",
       " '#CAMP_CD_CAMPO_0247',\n",
       " '#CAMP_CD_CAMPO_0248',\n",
       " '#CAMP_CD_CAMPO_0249',\n",
       " '#CAMP_CD_CAMPO_0264',\n",
       " '#CAMP_CD_CAMPO_0279',\n",
       " '#CAMP_CD_CAMPO_0309',\n",
       " '#CAMP_CD_CAMPO_0322',\n",
       " '#CAMP_CD_CAMPO_0352',\n",
       " '#CAMP_CD_CAMPO_0362',\n",
       " '#CAMP_CD_CAMPO_0363',\n",
       " '#CAMP_CD_CAMPO_0373',\n",
       " '#CAMP_CD_CAMPO_0383',\n",
       " '#CAMP_CD_CAMPO_0388',\n",
       " '#CAMP_CD_CAMPO_0393',\n",
       " '#CAMP_CD_CAMPO_0403',\n",
       " '#CAMP_CD_CAMPO_0444',\n",
       " '#CAMP_CD_CAMPO_0477',\n",
       " '#CAMP_CD_CAMPO_0519',\n",
       " '#CAMP_CD_CAMPO_0523',\n",
       " '#CAMP_CD_CAMPO_0536',\n",
       " '#CAMP_CD_CAMPO_0545',\n",
       " '#CAMP_CD_CAMPO_0575',\n",
       " '#CAMP_CD_CAMPO_0603',\n",
       " '#CAMP_CD_CAMPO_0637',\n",
       " '#CAMP_CD_CAMPO_0668',\n",
       " '#CAMP_CD_CAMPO_0682',\n",
       " '#CAMP_CD_CAMPO_0683',\n",
       " '#CAMP_CD_CAMPO_0684',\n",
       " '#CAMP_CD_CAMPO_0718',\n",
       " '#CAMP_CD_CAMPO_0725',\n",
       " '#CAMP_CD_CAMPO_0734',\n",
       " '#CAMP_CD_CAMPO_0750',\n",
       " '#CAMP_CD_CAMPO_0760',\n",
       " '#CAMP_CD_CAMPO_0773',\n",
       " '#CAMP_CD_CAMPO_0803',\n",
       " '#CAMP_CD_CAMPO_0819',\n",
       " '#CAMP_CD_CAMPO_0830',\n",
       " '#CAMP_CD_CAMPO_0861',\n",
       " '#CAMP_CD_CAMPO_0881',\n",
       " '#CAMP_CD_CAMPO_0888',\n",
       " '#CAMP_CD_CAMPO_0912',\n",
       " '#CAMP_CD_CAMPO_0916',\n",
       " '#CAMP_CD_CAMPO_0929',\n",
       " '#CAMP_CD_CAMPO_0932',\n",
       " '#CAMP_CD_CAMPO_0951',\n",
       " '#CAMP_CD_CAMPO_0958',\n",
       " '#CAMP_CD_CAMPO_0970',\n",
       " '#CAMP_CD_CAMPO_0975',\n",
       " '#CAMP_CD_CAMPO_0995',\n",
       " '#Cambrian',\n",
       " '#Campanian',\n",
       " '#Carboniferous',\n",
       " '#Cenomanian',\n",
       " '#Cenozoic',\n",
       " '#Chattian',\n",
       " '#Coniacian',\n",
       " '#Cretaceous',\n",
       " '#Danian',\n",
       " '#Desmoinesian_Age',\n",
       " '#Devonian',\n",
       " '#Dom_Joao_Age',\n",
       " '#Eoburacica_Subage',\n",
       " '#Eocene',\n",
       " '#Eojiquia_Subage',\n",
       " '#Frasnian',\n",
       " '#Hauterivian',\n",
       " '#Holocene',\n",
       " '#Jiquia_Age',\n",
       " '#Jurassic',\n",
       " '#LowerCretaceous',\n",
       " '#LowerDevonian',\n",
       " '#LowerTriassic',\n",
       " '#Lower_Albian_Subage',\n",
       " '#Lower_Aptian_Subage',\n",
       " '#Lower_Cenomanian_Subage',\n",
       " '#Lower_Maastrichtian_Subage',\n",
       " '#Lower_Turonian_Subage',\n",
       " '#Lutetian',\n",
       " '#Maastrichtian',\n",
       " '#Mesoriodaserra_Subage',\n",
       " '#Mesozoic',\n",
       " '#MiddleJurassic',\n",
       " '#Middle_Albian_Subage',\n",
       " '#Miocene',\n",
       " '#Mississippian',\n",
       " '#Missourian_Age',\n",
       " '#Morrowan_Age',\n",
       " '#Neoburacica_Subage',\n",
       " '#Neogene',\n",
       " '#Neojiquia_Subage',\n",
       " '#Neoriodaserra_Subage',\n",
       " '#Oligocene',\n",
       " '#Oxfordian',\n",
       " '#POCO_CD_POCO_005665',\n",
       " '#POCO_CD_POCO_006088',\n",
       " '#POCO_CD_POCO_006789',\n",
       " '#POCO_CD_POCO_006870',\n",
       " '#POCO_CD_POCO_006882',\n",
       " '#POCO_CD_POCO_006960',\n",
       " '#POCO_CD_POCO_007020',\n",
       " '#POCO_CD_POCO_007040',\n",
       " '#POCO_CD_POCO_007052',\n",
       " '#POCO_CD_POCO_007076',\n",
       " '#POCO_CD_POCO_007140',\n",
       " '#POCO_CD_POCO_007553',\n",
       " '#POCO_CD_POCO_007746',\n",
       " '#POCO_CD_POCO_007748',\n",
       " '#POCO_CD_POCO_008339',\n",
       " '#POCO_CD_POCO_009032',\n",
       " '#POCO_CD_POCO_009065',\n",
       " '#POCO_CD_POCO_009422',\n",
       " '#POCO_CD_POCO_009757',\n",
       " '#POCO_CD_POCO_010471',\n",
       " '#POCO_CD_POCO_010526',\n",
       " '#POCO_CD_POCO_010643',\n",
       " '#POCO_CD_POCO_010669',\n",
       " '#POCO_CD_POCO_010670',\n",
       " '#POCO_CD_POCO_010689',\n",
       " '#POCO_CD_POCO_010691',\n",
       " '#POCO_CD_POCO_010726',\n",
       " '#POCO_CD_POCO_010831',\n",
       " '#POCO_CD_POCO_011890',\n",
       " '#POCO_CD_POCO_011894',\n",
       " '#POCO_CD_POCO_011907',\n",
       " '#POCO_CD_POCO_011911',\n",
       " '#POCO_CD_POCO_012020',\n",
       " '#POCO_CD_POCO_012040',\n",
       " '#POCO_CD_POCO_012091',\n",
       " '#POCO_CD_POCO_012097',\n",
       " '#POCO_CD_POCO_012120',\n",
       " '#POCO_CD_POCO_012153',\n",
       " '#POCO_CD_POCO_012155',\n",
       " '#POCO_CD_POCO_012186',\n",
       " '#POCO_CD_POCO_012864',\n",
       " '#POCO_CD_POCO_012914',\n",
       " '#POCO_CD_POCO_012983',\n",
       " '#POCO_CD_POCO_012996',\n",
       " '#POCO_CD_POCO_015948',\n",
       " '#POCO_CD_POCO_016511',\n",
       " '#POCO_CD_POCO_016933',\n",
       " '#POCO_CD_POCO_017402',\n",
       " '#POCO_CD_POCO_017478',\n",
       " '#POCO_CD_POCO_018470',\n",
       " '#POCO_CD_POCO_020490',\n",
       " '#POCO_CD_POCO_020848',\n",
       " '#POCO_CD_POCO_021725',\n",
       " '#POCO_CD_POCO_021906',\n",
       " '#POCO_CD_POCO_021985',\n",
       " '#POCO_CD_POCO_022660',\n",
       " '#POCO_CD_POCO_022687',\n",
       " '#POCO_CD_POCO_022866',\n",
       " '#POCO_CD_POCO_022975',\n",
       " '#POCO_CD_POCO_023049',\n",
       " '#POCO_CD_POCO_023169',\n",
       " '#POCO_CD_POCO_023172',\n",
       " '#POCO_CD_POCO_023241',\n",
       " '#POCO_CD_POCO_023376',\n",
       " '#POCO_CD_POCO_023745',\n",
       " '#POCO_CD_POCO_023746',\n",
       " '#POCO_CD_POCO_024176',\n",
       " '#POCO_CD_POCO_024384',\n",
       " '#POCO_CD_POCO_024465',\n",
       " '#POCO_CD_POCO_024505',\n",
       " '#POCO_CD_POCO_024918',\n",
       " '#POCO_CD_POCO_025010',\n",
       " '#POCO_CD_POCO_025253',\n",
       " '#Paleocene',\n",
       " '#Paleogene',\n",
       " '#Paleoproterozoic',\n",
       " '#Paleozoic',\n",
       " '#Pennsylvanian',\n",
       " '#Permian',\n",
       " '#Phanerozoic',\n",
       " '#Pleistocene',\n",
       " '#Pliensbachian',\n",
       " '#Pliocene',\n",
       " '#Priabonian',\n",
       " '#Proterozoic',\n",
       " '#Quaternary',\n",
       " '#Rupelian',\n",
       " '#Santonian',\n",
       " '#Silurian',\n",
       " '#Sinemurian',\n",
       " '#Thanetian',\n",
       " '#Tithonian',\n",
       " '#Toarcian',\n",
       " '#Triassic',\n",
       " '#Turonian',\n",
       " '#UpperCretaceous',\n",
       " '#UpperDevonian',\n",
       " '#UpperJurassic',\n",
       " '#UpperTriassic',\n",
       " '#Upper_Albian_Subage',\n",
       " '#Upper_Aptian_Subage',\n",
       " '#Upper_Campanian_Subage',\n",
       " '#Upper_Maastrichtian_Subage',\n",
       " '#Valanginian',\n",
       " '#Virgilian_Age',\n",
       " '#Ypresian',\n",
       " '#anhydrite',\n",
       " '#basalt',\n",
       " '#calciarenite',\n",
       " '#calcilutite',\n",
       " '#carnallite',\n",
       " '#clay',\n",
       " '#coal',\n",
       " '#conglomerate',\n",
       " '#diabase',\n",
       " '#diamictite',\n",
       " '#formacao_002',\n",
       " '#formacao_003',\n",
       " '#formacao_009',\n",
       " '#formacao_013',\n",
       " '#formacao_016',\n",
       " '#formacao_019',\n",
       " '#formacao_025',\n",
       " '#formacao_027',\n",
       " '#formacao_028',\n",
       " '#formacao_044',\n",
       " '#formacao_050',\n",
       " '#formacao_056',\n",
       " '#formacao_059',\n",
       " '#formacao_083',\n",
       " '#formacao_084',\n",
       " '#formacao_095',\n",
       " '#formacao_096',\n",
       " '#formacao_102',\n",
       " '#formacao_103',\n",
       " '#formacao_110',\n",
       " '#formacao_113',\n",
       " '#formacao_116',\n",
       " '#formacao_117',\n",
       " '#formacao_119',\n",
       " '#formacao_121',\n",
       " '#formacao_122',\n",
       " '#formacao_125',\n",
       " '#formacao_126',\n",
       " '#formacao_130',\n",
       " '#formacao_131',\n",
       " '#formacao_136',\n",
       " '#formacao_142',\n",
       " '#formacao_145',\n",
       " '#formacao_149',\n",
       " '#formacao_153',\n",
       " '#formacao_154',\n",
       " '#formacao_157',\n",
       " '#formacao_158',\n",
       " '#formacao_159',\n",
       " '#formacao_163',\n",
       " '#formacao_166',\n",
       " '#formacao_171',\n",
       " '#formacao_183',\n",
       " '#formacao_187',\n",
       " '#formacao_193',\n",
       " '#formacao_200',\n",
       " '#formacao_204',\n",
       " '#formacao_207',\n",
       " '#formacao_210',\n",
       " '#formacao_215',\n",
       " '#formacao_216',\n",
       " '#formacao_217',\n",
       " '#formacao_222',\n",
       " '#formacao_224',\n",
       " '#formacao_228',\n",
       " '#formacao_229',\n",
       " '#formacao_232',\n",
       " '#formacao_236',\n",
       " '#formacao_239',\n",
       " '#formacao_242',\n",
       " '#formacao_246',\n",
       " '#formacao_249',\n",
       " '#formacao_251',\n",
       " '#formacao_253',\n",
       " '#formacao_254',\n",
       " '#formacao_255',\n",
       " '#formacao_256',\n",
       " '#formacao_259',\n",
       " '#formacao_260',\n",
       " '#formacao_262',\n",
       " '#formacao_264',\n",
       " '#formacao_266',\n",
       " '#formacao_277',\n",
       " '#formacao_278',\n",
       " '#formacao_281',\n",
       " '#formacao_286',\n",
       " '#formacao_287',\n",
       " '#formacao_289',\n",
       " '#formacao_292',\n",
       " '#formacao_294',\n",
       " '#formacao_295',\n",
       " '#formacao_296',\n",
       " '#formacao_305',\n",
       " '#formacao_319',\n",
       " '#formacao_328',\n",
       " '#formacao_331',\n",
       " '#formacao_335',\n",
       " '#formacao_338',\n",
       " '#formacao_341',\n",
       " '#formacao_343',\n",
       " '#formacao_344',\n",
       " '#grupo_000',\n",
       " '#grupo_008',\n",
       " '#grupo_009',\n",
       " '#grupo_017',\n",
       " '#grupo_018',\n",
       " '#grupo_022',\n",
       " '#grupo_024',\n",
       " '#grupo_032',\n",
       " '#grupo_033',\n",
       " '#grupo_038',\n",
       " '#grupo_040',\n",
       " '#grupo_048',\n",
       " '#grupo_049',\n",
       " '#grupo_05',\n",
       " '#grupo_055',\n",
       " '#grupo_057',\n",
       " '#grupo_062',\n",
       " '#halite',\n",
       " '#igneous_rock',\n",
       " '#limestone',\n",
       " '#marlstone',\n",
       " '#membro_000',\n",
       " '#membro_002',\n",
       " '#membro_005',\n",
       " '#membro_007',\n",
       " '#membro_010',\n",
       " '#membro_013',\n",
       " '#membro_019',\n",
       " '#membro_020',\n",
       " '#membro_022',\n",
       " '#membro_025',\n",
       " '#membro_027',\n",
       " '#membro_028',\n",
       " '#membro_032',\n",
       " '#membro_036',\n",
       " '#membro_037',\n",
       " '#membro_040',\n",
       " '#membro_042',\n",
       " '#membro_044',\n",
       " '#membro_045',\n",
       " '#membro_050',\n",
       " '#membro_052',\n",
       " '#membro_058',\n",
       " '#membro_060',\n",
       " '#membro_061',\n",
       " '#membro_070',\n",
       " '#membro_071',\n",
       " '#membro_075',\n",
       " '#membro_078',\n",
       " '#pyroclast',\n",
       " '#sand',\n",
       " '#sandstone',\n",
       " '#shale',\n",
       " '#siltstone',\n",
       " '#tachyhydrite']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uris.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 129,\n",
       " 112,\n",
       " 31,\n",
       " 6,\n",
       " 40,\n",
       " 2,\n",
       " 12,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 35,\n",
       " 49,\n",
       " 4,\n",
       " 111,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 55,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 26,\n",
       " 27,\n",
       " 75,\n",
       " 28,\n",
       " 22,\n",
       " 4,\n",
       " 19,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 45,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 46,\n",
       " 135,\n",
       " 51,\n",
       " 47,\n",
       " 36,\n",
       " 18,\n",
       " 36,\n",
       " 98,\n",
       " 10,\n",
       " 16,\n",
       " 35,\n",
       " 29,\n",
       " 18,\n",
       " 28,\n",
       " 2,\n",
       " 2,\n",
       " 14,\n",
       " 52,\n",
       " 46,\n",
       " 30,\n",
       " 94,\n",
       " 2,\n",
       " 2,\n",
       " 17,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 120,\n",
       " 2,\n",
       " 36,\n",
       " 2,\n",
       " 5,\n",
       " 13,\n",
       " 4,\n",
       " 8,\n",
       " 24,\n",
       " 26,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 20,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 48,\n",
       " 16,\n",
       " 4,\n",
       " 56,\n",
       " 4,\n",
       " 58,\n",
       " 2,\n",
       " 54,\n",
       " 6,\n",
       " 3,\n",
       " 12,\n",
       " 14,\n",
       " 8,\n",
       " 14,\n",
       " 59,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 24,\n",
       " 45,\n",
       " 34,\n",
       " 6,\n",
       " 49,\n",
       " 4,\n",
       " 6,\n",
       " 29,\n",
       " 2,\n",
       " 10,\n",
       " 26,\n",
       " 4,\n",
       " 14,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 15,\n",
       " 3,\n",
       " 19,\n",
       " 1,\n",
       " 1,\n",
       " 20,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 27,\n",
       " 12,\n",
       " 2,\n",
       " 4,\n",
       " 20,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 19,\n",
       " 1,\n",
       " 11,\n",
       " 17,\n",
       " 19,\n",
       " 20,\n",
       " 1,\n",
       " 17,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 19,\n",
       " 17,\n",
       " 11,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 19,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 46,\n",
       " 29,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 18,\n",
       " 15,\n",
       " 5,\n",
       " 6,\n",
       " 30,\n",
       " 4,\n",
       " 20,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 22,\n",
       " 25,\n",
       " 12,\n",
       " 7,\n",
       " 25,\n",
       " 5,\n",
       " 6,\n",
       " 27,\n",
       " 11,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 22,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 14,\n",
       " 3,\n",
       " 10,\n",
       " 52,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 14,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 10,\n",
       " 5,\n",
       " 8,\n",
       " 42,\n",
       " 4,\n",
       " 9,\n",
       " 10,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 4,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 198,\n",
       " 109,\n",
       " 19,\n",
       " 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numb_uris.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação de pares de entidades por tipo de relação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of types of relations -> 6\n"
     ]
    }
   ],
   "source": [
    "# df_filtred = pickle.load(open('df_relation.pkl', 'rb'))\n",
    "df_relations = pd.read_csv('df_relation.csv')\n",
    "df_grp = df_relations.groupby('Relation')\n",
    "relations_groups = df_grp.groups\n",
    "relations = list(relations_groups)\n",
    "lista_pares = []\n",
    "for relation in relations:\n",
    "    df_rel = df_grp.get_group(relation)\n",
    "    list_rel = []\n",
    "    for idx_rel in range(0,len(df_rel)):\n",
    "        par = df_rel.iloc[idx_rel]['Ent1'] + ' + ' + df_rel.iloc[idx_rel]['Ent2']\n",
    "        list_rel.append(par)\n",
    "    lista_pares.append(list_rel)\n",
    "print('Number of types of relations ->', len(lista_pares))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliar idx_pair de 0 ao tamanho apresentado acima para verificar os pares de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation ->  constituted_by\n",
      "Entities pair ->  ['UNIDADE_LITO + ROCHA']\n",
      "Number of ocorrences ->  [402]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "pares, numb_pares = np.unique(lista_pares[idx], return_counts = True)\n",
    "print('Relation -> ',relations[idx])\n",
    "print('Entities pair -> ',pares.tolist())\n",
    "print('Number of ocorrences -> ',numb_pares.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
