{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078fcb30-410b-4440-9ede-25b4ef2f30e9",
   "metadata": {},
   "source": [
    "### Notebook to adjust PetroNER for Entity Linking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6439c4b0-1acf-4ac2-92bd-220683de9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "import gensim\n",
    "from conllu import parse_incr, parse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250b4a1-35c0-4083-9eb8-938fb0bedddd",
   "metadata": {},
   "source": [
    "Load ontology and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03dae845-46ce-4da9-a742-75da0848e08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OntoGeoLógica populada (OntoGeoLogicaPopulada.owl)\n",
    "onto = get_ontology(\"../../KnowledgeGraph/OntoGeoLogicaPovoadaInstanciasRelacoes.owl\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d13e485f-2baa-41a1-b9ed-124d3911601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo OWL2Vec - \n",
    "PetroOntoVec = gensim.models.Word2Vec.load(\"../../Embeddings/PetroOntoVec/PetroOntoVec_simples/outputontology.embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5aa8d7-a627-4fcb-843f-40df6e335af5",
   "metadata": {},
   "source": [
    "Load PetroNER (file in CONLLU format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d64c69d0-b3e2-4e57-b485-a2ac681cae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONLLU parser\n",
    "\n",
    "# Corpora treino\n",
    "PetroNER_treino = open(\"../PetroNER/petroner-Treino-uri-2022-03-07.conllu\", \"r\", encoding=\"utf-8\")\n",
    "PetroNER_treino_sentences = parse_incr(PetroNER_treino)\n",
    "\n",
    "# Corpora validação\n",
    "PetroNER_valid = open(\"../PetroNER/petroner-Validação-uri-2022-03-07.conllu\", \"r\", encoding=\"utf-8\")\n",
    "PetroNER_valid_sentences = parse_incr(PetroNER_valid)\n",
    "\n",
    "# Corpora teste\n",
    "PetroNER_teste = open(\"../PetroNER/petroner-Teste-uri-2022-03-07.conllu\", \"r\", encoding=\"utf-8\")\n",
    "PetroNER_teste_sentences = parse_incr(PetroNER_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46b866-644c-4d16-b65d-d965ed8952a0",
   "metadata": {},
   "source": [
    "### Preparing and processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9351dbe-ce9c-403b-a96f-1d6c64cacc35",
   "metadata": {},
   "source": [
    "Função que recebe o texto anotado em formato CONLLU e processa para o treinamento. Tem como saída as sentenças acrescida das tags para indicar as entidades, bem como com a entidade no início do texto; lista com as entidades (instâncias extraídas do texto); lista com as classes que as entidades pertencem; e lista com as URI referente às entidades. O texto sai com o seguinte formato:  \n",
    "\"[Nome da classe] Nome da entidade | blablabla blablabla blablabla [E] Nome da entidade [/E] blablabla blablabla.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "909bcddc-094b-4ac7-a1dd-6095e52df38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe\n",
    "def preparar_dataset(tokenlist):\n",
    "\n",
    "    #sent = TokenList([])\n",
    "    sent_orig = ''   # String para compor a sentença original\n",
    "    sents_NER = []   # Lista para armazenar as sentenças com indicação das entidades\n",
    "    NER_on = False   # Variável para indicar se está iterando por token de entidades\n",
    "    NER_tok = ''     # string para armazenar os tokens das entidades que estão sendo iteradas\n",
    "    MW_on = False    # Variável para indicar se está iterando por tolkens multiword\n",
    "    MW_tok = ''      # string para armazenar o termo multiword\n",
    "    MW_end = 0       # ID final do token multiword\n",
    "    ENT = []         # Lista para armazenar as entidades encontradas no texto\n",
    "    ENT_class = []   # Lista para armazenar as classes das entidades encontradas no texto\n",
    "    ENT_URI = []     # Lista para armazenar as URI das entidades encontradas no texto\n",
    "\n",
    "    #Iterando por todos os tokens de uma sentença\n",
    "    for tok in tokenlist:\n",
    "        # ignorando id não inteiro (tuplas), ou seja token multiword\n",
    "        if type(tok['id']) == int:\n",
    "\n",
    "            # Verifica se o token inicia uma entidade (\"B\")\n",
    "            if tok['deps'][0] == 'B':\n",
    "                \n",
    "                # Verifica se a variável NER_on está ativado (No caso de um tok \"B\" seguido de outro)\n",
    "                if NER_on == True:\n",
    "                    \n",
    "                    NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                    # Para sentença mais recente da lista sents_NER, inclui a entidade no início e o marcador [/E] no final \n",
    "                    sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                    # Incluir o NER_tok na lista ENT\n",
    "                    ENT.append(NER_tok.strip())\n",
    "\n",
    "                    NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "                NER_on = True  # Ativa a variável NER_on\n",
    "                # Acrescenta uma sentença com o marcador [E] na listas de sentenças com NER\n",
    "                sents_NER.append(sent_orig + ' [E]')\n",
    "                # Incluir classe na lista ENT_class\n",
    "                ENT_class.append(tok['deps'][2:])\n",
    "                # Incluir URI da entidade na lista ENT_URI. Caso não haja URI, incluir \"None\". \n",
    "                try:\n",
    "                    ENT_URI.append(tok['misc']['grafo'])\n",
    "                except:\n",
    "                    ENT_URI.append(None)\n",
    "\n",
    "            # Identifica o primeiro token \"O\" após uma sequência de entidades\n",
    "            if (tok['deps'][0] == 'O') & NER_on:\n",
    "                \n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "                \n",
    "            # Identifica se o último token da sequência tem o marcador \"B\" ou \"I\".    \n",
    "            if (tokenlist[-1]['id'] == tok['id']) & ((tok['deps'][0] == 'B') | (tok['deps'][0] == 'I')):\n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "            # Verifica se está iterando por uma multiword ou não\n",
    "            if not MW_on:\n",
    "\n",
    "                # Acrecenta o token à string da entidade\n",
    "                if NER_on:\n",
    "                    NER_tok = NER_tok + tok['form'] + ' '\n",
    "\n",
    "                # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                if tok['upos'] == 'PUNCT':\n",
    "                    # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                    sent_orig = sent_orig + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + tok['form']\n",
    "                else:\n",
    "                    sent_orig = sent_orig + ' ' + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + ' ' + tok['form']\n",
    "\n",
    "            else:\n",
    "                # Se o token for o último termo da multiword, desativamos a variável MW_on\n",
    "                if tok['id'] == MW_end:\n",
    "                    MW_on = False\n",
    "\n",
    "                    # Acrecenta a multiword à string da entidade\n",
    "                    if NER_on:\n",
    "                        NER_tok = NER_tok + MW_tok + ' '\n",
    "\n",
    "                    #Ao invés de incluir nas senteças o token, vamos incluir o MW_tok \n",
    "                    # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                    if tok['upos'] == 'PUNCT':\n",
    "                        # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                        sent_orig = sent_orig + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + MW_tok\n",
    "                    else:\n",
    "                        sent_orig = sent_orig + ' ' + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + ' ' + MW_tok\n",
    "\n",
    "        # Se a ID do token for referente a uma multiword, ativamos a variável MW_on, \n",
    "        # armazenamos o termo MW_tok e o valor da 'id' final\n",
    "        else:\n",
    "            MW_on = True\n",
    "            MW_tok = tok['form']\n",
    "            MW_end = tok['id'][-1]\n",
    "    \n",
    "    return(sents_NER, ENT, ENT_class, ENT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af655dc7-c5cb-44c4-81d3-e0e0b945f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_class_URI(sentences):\n",
    "\n",
    "    # Separando as listas de sentenças, entidades, classes e URI\n",
    "    text = []\n",
    "    entities = []\n",
    "    classes_NER = [] \n",
    "    ENT_URI = []\n",
    "    entities_sem_URI = []\n",
    "\n",
    "    # Iterando por todas as sentenças em formato CONLLU para preparar o dataset\n",
    "    n = 0\n",
    "    m = 0\n",
    "    \n",
    "    for tokenlist in sentences:\n",
    "        # contador de sentenças\n",
    "        n = n + 1\n",
    "        # processando cada sentenças\n",
    "        text_n, entities_n, classes_NER_n, ENT_URI_n = preparar_dataset(tokenlist)\n",
    "        # Contador de sentenãs com entidades\n",
    "        if len(text_n) > 0:\n",
    "            m = m + 1\n",
    "        \n",
    "        text = text + text_n\n",
    "        entities = entities + entities_n\n",
    "        classes_NER = classes_NER + classes_NER_n\n",
    "        ENT_URI = ENT_URI + ENT_URI_n\n",
    "\n",
    "    print('Total de sentenças no arquivo: ', n)\n",
    "    print('N° de sentenças com entidades: ', m, 'que equivale a ', (m/n)*100, '% do total')\n",
    "    print ('N° de entidades: ', len(entities))\n",
    "    print('N° de classes: ', len(classes_NER))\n",
    "    print('Média de ', len(entities)/m, 'entidades por sentença (das sentenças que possuem entidades)')\n",
    "    \n",
    "    #Verificando entidades sem URI\n",
    "    for i in range(len(ENT_URI)):\n",
    "        if ENT_URI[i] == None:\n",
    "            entities_sem_URI.append(entities[i])\n",
    "        \n",
    "    print('N° de entities com URI: ', len(ENT_URI) - len(entities_sem_URI))\n",
    "    print('N° de entities sem URI: ', len(entities_sem_URI))\n",
    "    print((len(entities_sem_URI)/len(ENT_URI))*100, '% das entidades não possuem URI.')\n",
    "    \n",
    "    return (text, entities, classes_NER, ENT_URI, entities_sem_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea44256-d583-4c9d-a950-88bbe93d1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PetroNER - Treino\n"
     ]
    }
   ],
   "source": [
    "print('\\nPetroNER - Treino')\n",
    "treino_text, treino_entities, treino_classes_NER, treino_ENT_URI, treino_entities_sem_URI = ent_class_URI(PetroNER_treino_sentences)\n",
    "\n",
    "print('\\nPetroNER - Validação')\n",
    "valid_text, valid_entities, valid_classes_NER, valid_ENT_URI, valid_entities_sem_URI = ent_class_URI(PetroNER_valid_sentences)\n",
    "\n",
    "print('\\nPetroNER - Teste')\n",
    "teste_text, teste_entities, teste_classes_NER, teste_ENT_URI, teste_entities_sem_URI = ent_class_URI(PetroNER_teste_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c3eea-0b7a-4061-828c-1fa5851d604b",
   "metadata": {},
   "source": [
    "### Buscando vetores do PetroOntoVec para cada URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9d43b-7113-429e-b5b2-7ee1f9d51f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscando_URI_vec(text, entities, classes_NER, ENT_URI):\n",
    "\n",
    "    # Separando as listas de sentenças, entidades, classes, URI e vetores\n",
    "    text_new = []\n",
    "    entities_new = []\n",
    "    classes_NER_new = [] \n",
    "    ENT_URI_new = []\n",
    "    URI_Vec_new = []\n",
    "\n",
    "    URI_ausente_Onto = []\n",
    "\n",
    "    n = 0 \n",
    "    #m = 0\n",
    "    #Iterando por todas as sentenças, desconsiderando aquelas cujas entidades não possuem URI\n",
    "    for i in range(len(text)):\n",
    "        n = n + 1\n",
    "        if ENT_URI[i] != None:\n",
    "            # Quebrando as entidades que possuem mais de um URI (ex: \"#Aptian,#Miocene\" e \"#Cenozoic,#Mesozoic\")\n",
    "            ENT_URI_n = ENT_URI[i].split(',#')\n",
    "\n",
    "            # Iterando pelas ENT_URI após serem quebradas e acrescentando '#\" naquelas que perderam na operação de split \n",
    "            for ent in ENT_URI_n:\n",
    "                if ent[0] != '#':\n",
    "                    ent = '#' + ent\n",
    "                try:\n",
    "                    #Acrescentar a URI da entidade e o vetor da URI nas listas\n",
    "                    URI_Vec_new.append(PetroOntoVec['http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2' + ent])\n",
    "                    ENT_URI_new.append(ent)\n",
    "\n",
    "                    # O texto, a entidade no texto e a classe são repetidas quando existem multiplas URI para uma mesma entidade\n",
    "                    text_new.append(text[i])\n",
    "                    entities_new.append(entities[i])\n",
    "                    classes_NER_new.append(classes_NER[i])\n",
    "                except:\n",
    "                    #print(\"URI presente no arquivo CONLLU mas ausente na Ontologia: \", ent)\n",
    "                    URI_ausente_Onto.append(ent)\n",
    "\n",
    "    # Transformando as listas em Numpy array\n",
    "    text = np.array(text_new)\n",
    "    entities = np.array(entities_new)\n",
    "    classes_NER = np.array(classes_NER_new) \n",
    "    ENT_URI = np.array(ENT_URI_new)\n",
    "    URI_Vec = np.array(URI_Vec_new)\n",
    "    URI_ausente_Onto = np.array(URI_ausente_Onto)\n",
    "\n",
    "    print('Total de sentenças anotadas: ', n)\n",
    "    print('N° de sentenças: ', len(text))\n",
    "    print ('N° de entidades: ', len(entities))\n",
    "    print('N° de classes: ', len(classes_NER))\n",
    "    print('N° de entidades_ID: ', len(ENT_URI))       \n",
    "    print('N° de vetores de URI: ', len(URI_Vec))       \n",
    "    \n",
    "    return(text, entities, classes_NER, ENT_URI, URI_Vec, URI_ausente_Onto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4468c8-4ee1-4e8d-b46f-373c13bb464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "(treino_text,\n",
    " treino_entities,\n",
    " treino_classes_NER,\n",
    " treino_ENT_URI,\n",
    " treino_URI_Vec,\n",
    " treino_URI_ausente_Onto) = buscando_URI_vec(treino_text,\n",
    "                                             treino_entities,\n",
    "                                             treino_classes_NER,\n",
    "                                             treino_ENT_URI)\n",
    "\n",
    "#Treino\n",
    "(valid_text,\n",
    " valid_entities,\n",
    " valid_classes_NER,\n",
    " valid_ENT_URI,\n",
    " valid_URI_Vec,\n",
    " valid_URI_ausente_Onto) = buscando_URI_vec(valid_text,\n",
    "                                            valid_entities,\n",
    "                                            valid_classes_NER,\n",
    "                                            valid_ENT_URI)\n",
    "\n",
    "#Treino\n",
    "(teste_text,\n",
    " teste_entities,\n",
    " teste_classes_NER,\n",
    " teste_ENT_URI,\n",
    " teste_URI_Vec,\n",
    " teste_URI_ausente_Onto) = buscando_URI_vec(teste_text,\n",
    "                                            teste_entities,\n",
    "                                            teste_classes_NER,\n",
    "                                            teste_ENT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0436958d-53f9-4e12-90f2-58cf5d03b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('URI no PetroNER_Treino ausentes da ontologia: ')\n",
    "print(set(treino_URI_ausente_Onto))\n",
    "print('')\n",
    "print('URI no PetroNER_Validação ausentes da ontologia: ')\n",
    "print(set(valid_URI_ausente_Onto))\n",
    "print('')\n",
    "print('URI no PetroNER_Teste ausentes da ontologia: ')\n",
    "print(set(teste_URI_ausente_Onto))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767b6c2-03de-4ef6-b7b5-40d80604b83a",
   "metadata": {},
   "source": [
    "### Salvando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add17e53-0c52-444f-8f92-d1cda5a27f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "\n",
    "with open('treino - sentences.npy', 'wb') as f:\n",
    "    np.save(f, treino_text)\n",
    "with open('treino - entities.npy', 'wb') as f:\n",
    "    np.save(f, treino_entities)\n",
    "with open('treino - classes.npy', 'wb') as f:\n",
    "    np.save(f, treino_classes_NER)\n",
    "with open('treino - URI.npy', 'wb') as f:\n",
    "    np.save(f, treino_ENT_URI)\n",
    "with open('treino - URI_vectors.npy', 'wb') as f:\n",
    "    np.save(f, treino_URI_Vec)\n",
    "with open('treino - URI_ausente_Ont.npy', 'wb') as f:\n",
    "    np.save(f, treino_URI_ausente_Onto)\n",
    "    \n",
    "#Validação\n",
    "\n",
    "with open('valid - sentences.npy', 'wb') as f:\n",
    "    np.save(f, valid_text)\n",
    "with open('valid - entities.npy', 'wb') as f:\n",
    "    np.save(f, valid_entities)\n",
    "with open('valid - classes.npy', 'wb') as f:\n",
    "    np.save(f, valid_classes_NER)\n",
    "with open('valid - URI.npy', 'wb') as f:\n",
    "    np.save(f, valid_ENT_URI)\n",
    "with open('valid - URI_vectors.npy', 'wb') as f:\n",
    "    np.save(f, valid_URI_Vec)\n",
    "with open('valid - URI_ausente_Ont.npy', 'wb') as f:\n",
    "    np.save(f, valid_URI_ausente_Onto)\n",
    "    \n",
    "#Teste\n",
    "\n",
    "with open('teste - sentences.npy', 'wb') as f:\n",
    "    np.save(f, teste_text)\n",
    "with open('teste - entities.npy', 'wb') as f:\n",
    "    np.save(f, teste_entities)\n",
    "with open('teste - classes.npy', 'wb') as f:\n",
    "    np.save(f, teste_classes_NER)\n",
    "with open('teste - URI.npy', 'wb') as f:\n",
    "    np.save(f, teste_ENT_URI)\n",
    "with open('teste - URI_vectors.npy', 'wb') as f:\n",
    "    np.save(f, teste_URI_Vec)\n",
    "with open('teste - URI_ausente_Ont.npy', 'wb') as f:\n",
    "    np.save(f, teste_URI_ausente_Onto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab92689-14c7-4a53-b5a6-a8fe2bff6b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
