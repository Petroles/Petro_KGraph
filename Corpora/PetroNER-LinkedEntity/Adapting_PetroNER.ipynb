{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078fcb30-410b-4440-9ede-25b4ef2f30e9",
   "metadata": {},
   "source": [
    "### Notebook to adjust PetroNER for Entity Linking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6439c4b0-1acf-4ac2-92bd-220683de9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "import gensim\n",
    "from conllu import parse_incr, parse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250b4a1-35c0-4083-9eb8-938fb0bedddd",
   "metadata": {},
   "source": [
    "Load ontology and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03dae845-46ce-4da9-a742-75da0848e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#has_beginning\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#has_end\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_contains\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_during\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_in\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_finished_by\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_finishes\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_started_by\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_starts\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#temporal_reference_system_used\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OntoGeoLógica populada (OntoGeoLogicaPopulada.owl)\n",
    "onto = get_ontology(\"../../KnowledgeGraph/OntoGeoLogicaPovoadaInstanciasRelacoes.owl\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13e485f-2baa-41a1-b9ed-124d3911601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo OWL2Vec - \n",
    "PetroOntoVec = gensim.models.Word2Vec.load(\"../../Embeddings/PetroOntoVec/PetroOntoVec_simples/outputontology.embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5aa8d7-a627-4fcb-843f-40df6e335af5",
   "metadata": {},
   "source": [
    "Load PetroNER (file in CONLLU format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d64c69d0-b3e2-4e57-b485-a2ac681cae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONLLU parser\n",
    "boleltins = open(\"../PetroNER/petroner-2022-12-19.conllu\", \"r\", encoding=\"utf-8\")\n",
    "sentences = parse_incr(boleltins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46b866-644c-4d16-b65d-d965ed8952a0",
   "metadata": {},
   "source": [
    "### Preparing and processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9351dbe-ce9c-403b-a96f-1d6c64cacc35",
   "metadata": {},
   "source": [
    "Função que recebe o texto anotado em formato CONLLU e processa para o treinamento. Tem como saída as sentenças acrescida das tags para indicar as entidades, bem como com a entidade no início do texto; lista com as entidades (instâncias extraídas do texto); lista com as classes que as entidades pertencem; e lista com as URI referente às entidades. O texto sai com o seguinte formato:  \n",
    "\"[Nome da classe] Nome da entidade | blablabla blablabla blablabla [E] Nome da entidade [/E] blablabla blablabla.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "909bcddc-094b-4ac7-a1dd-6095e52df38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe\n",
    "def preparar_dataset(tokenlist):\n",
    "\n",
    "    #sent = TokenList([])\n",
    "    sent_orig = ''   # String para compor a sentença original\n",
    "    sents_NER = []   # Lista para armazenar as sentenças com indicação das entidades\n",
    "    NER_on = False   # Variável para indicar se está iterando por token de entidades\n",
    "    NER_tok = ''     # string para armazenar os tokens das entidades que estão sendo iteradas\n",
    "    MW_on = False    # Variável para indicar se está iterando por tolkens multiword\n",
    "    MW_tok = ''      # string para armazenar o termo multiword\n",
    "    MW_end = 0       # ID final do token multiword\n",
    "    ENT = []         # Lista para armazenar as entidades encontradas no texto\n",
    "    ENT_class = []   # Lista para armazenar as classes das entidades encontradas no texto\n",
    "    ENT_URI = []     # Lista para armazenar as URI das entidades encontradas no texto\n",
    "\n",
    "    #Iterando por todos os tokens de uma sentença\n",
    "    for tok in tokenlist:\n",
    "        # ignorando id não inteiro (tuplas), ou seja token multiword\n",
    "        if type(tok['id']) == int:\n",
    "\n",
    "            # Verifica se o token inicia uma entidade (\"B\")\n",
    "            if tok['deps'][0] == 'B':\n",
    "                \n",
    "                # Verifica se a variável NER_on está ativado (No caso de um tok \"B\" seguido de outro)\n",
    "                if NER_on == True:\n",
    "                    \n",
    "                    NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                    # Para sentença mais recente da lista sents_NER, inclui a entidade no início e o marcador [/E] no final \n",
    "                    sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                    # Incluir o NER_tok na lista ENT\n",
    "                    ENT.append(NER_tok.strip())\n",
    "\n",
    "                    NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "                NER_on = True  # Ativa a variável NER_on\n",
    "                # Acrescenta uma sentença com o marcador [E] na listas de sentenças com NER\n",
    "                sents_NER.append(sent_orig + ' [E]')\n",
    "                # Incluir classe na lista ENT_class\n",
    "                ENT_class.append(tok['deps'][2:])\n",
    "                # Incluir URI da entidade na lista ENT_URI. Caso não haja URI, incluir \"None\". \n",
    "                try:\n",
    "                    ENT_URI.append(tok['misc']['grafo'])\n",
    "                except:\n",
    "                    ENT_URI.append(None)\n",
    "\n",
    "            # Identifica o primeiro token \"O\" após uma sequência de entidades\n",
    "            if (tok['deps'][0] == 'O') & NER_on:\n",
    "                \n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "                \n",
    "            # Identifica se o último token da sequência tem o marcador \"B\" ou \"I\".    \n",
    "            if (tokenlist[-1]['id'] == tok['id']) & ((tok['deps'][0] == 'B') | (tok['deps'][0] == 'I')):\n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "            # Verifica se está iterando por uma multiword ou não\n",
    "            if not MW_on:\n",
    "\n",
    "                # Acrecenta o token à string da entidade\n",
    "                if NER_on:\n",
    "                    NER_tok = NER_tok + tok['form'] + ' '\n",
    "\n",
    "                # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                if tok['upos'] == 'PUNCT':\n",
    "                    # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                    sent_orig = sent_orig + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + tok['form']\n",
    "                else:\n",
    "                    sent_orig = sent_orig + ' ' + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + ' ' + tok['form']\n",
    "\n",
    "            else:\n",
    "                # Se o token for o último termo da multiword, desativamos a variável MW_on\n",
    "                if tok['id'] == MW_end:\n",
    "                    MW_on = False\n",
    "\n",
    "                    # Acrecenta a multiword à string da entidade\n",
    "                    if NER_on:\n",
    "                        NER_tok = NER_tok + MW_tok + ' '\n",
    "\n",
    "                    #Ao invés de incluir nas senteças o token, vamos incluir o MW_tok \n",
    "                    # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                    if tok['upos'] == 'PUNCT':\n",
    "                        # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                        sent_orig = sent_orig + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + MW_tok\n",
    "                    else:\n",
    "                        sent_orig = sent_orig + ' ' + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + ' ' + MW_tok\n",
    "\n",
    "        # Se a ID do token for referente a uma multiword, ativamos a variável MW_on, \n",
    "        # armazenamos o termo MW_tok e o valor da 'id' final\n",
    "        else:\n",
    "            MW_on = True\n",
    "            MW_tok = tok['form']\n",
    "            MW_end = tok['id'][-1]\n",
    "    \n",
    "    return(sents_NER, ENT, ENT_class, ENT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af3ccd53-2acc-4e58-a95e-b74bd6051dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de sentenças no arquivo:  24035\n",
      "N° de sentenças com entidades:  18820\n",
      "N° de entidades:  18820\n",
      "N° de classes:  18820\n",
      "N° de classes:  18820\n"
     ]
    }
   ],
   "source": [
    "# Separando as listas de sentenças, entidades, classes e URI\n",
    "text = []\n",
    "entities = []\n",
    "classes_NER = [] \n",
    "ENT_URI = []\n",
    "\n",
    "# Iterando por todas as sentenças em formato CONLLU para preparar o dataset\n",
    "n = 0\n",
    "for tokenlist in sentences:\n",
    "    n = n + 1\n",
    "\n",
    "    text_n, entities_n, classes_NER_n, ENT_URI_n = preparar_dataset(tokenlist)\n",
    "    \n",
    "    text = text + text_n\n",
    "    entities = entities + entities_n\n",
    "    classes_NER = classes_NER + classes_NER_n\n",
    "    ENT_URI = ENT_URI + ENT_URI_n\n",
    "    \n",
    "print('Total de sentenças no arquivo: ', n)\n",
    "print('N° de sentenças com entidades: ', len(text))\n",
    "print ('N° de entidades: ', len(entities))\n",
    "print('N° de classes: ', len(classes_NER))\n",
    "print('N° de classes: ', len(ENT_URI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b809a0a-d39e-4378-8657-857248c8556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entidades sem URI:  9172\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in ENT_URI:\n",
    "    if i == None:\n",
    "        count = count + 1\n",
    "        \n",
    "print('Número de entidades sem URI: ', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c3eea-0b7a-4061-828c-1fa5851d604b",
   "metadata": {},
   "source": [
    "### Buscando vetores do PetroOntoVec para cada URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11d9d43b-7113-429e-b5b2-7ee1f9d51f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #gipsita\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #gipsita\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #gipsita\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #dry_hole\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #gipsita\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #dry_hole\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #carbonatos\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #grupo_05\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #dry_hole\n",
      "URI presente no arquivo CONLLU mas ausente na Ontologia:  #dry_hole\n",
      "Total de sentenças anotadas:  18820\n",
      "N° de sentenças:  9844\n",
      "N° de entidades:  9844\n",
      "N° de classes:  9844\n",
      "N° de entidades_ID:  9844\n",
      "N° de vetores de URI:  9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Separando as listas de sentenças, entidades, classes, URI e vetores\n",
    "text_new = []\n",
    "entities_new = []\n",
    "classes_NER_new = [] \n",
    "ENT_URI_new = []\n",
    "URI_Vec_new = []\n",
    "\n",
    "n = 0 \n",
    "#m = 0\n",
    "#Iterando por todas as sentenças, desconsiderando aquelas cujas entidades não possuem URI\n",
    "for i in range(len(text)):\n",
    "    n = n + 1\n",
    "    if ENT_URI[i] != None:\n",
    "        # Quebrando as entidades que possuem mais de um URI (ex: \"#Aptian,#Miocene\" e \"#Cenozoic,#Mesozoic\")\n",
    "        ENT_URI_n = ENT_URI[i].split(',#')\n",
    "        \n",
    "        # Iterando pelas ENT_URI após serem quebradas e acrescentando '#\" naquelas que perderam na operação de split \n",
    "        for ent in ENT_URI_n:\n",
    "            if ent[0] != '#':\n",
    "                ent = '#' + ent\n",
    "            try:\n",
    "                #Acrescentar a URI da entidade e o vetor da URI nas listas\n",
    "                URI_Vec_new.append(PetroOntoVec['http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2' + ent])\n",
    "                ENT_URI_new.append(ent)\n",
    "               \n",
    "                # O texto, a entidade no texto e a classe são repetidas quando existem multiplas URI para uma mesma entidade\n",
    "                text_new.append(text[i])\n",
    "                entities_new.append(entities[i])\n",
    "                classes_NER_new.append(classes_NER[i])\n",
    "            except:\n",
    "                print(\"URI presente no arquivo CONLLU mas ausente na Ontologia: \", ent)\n",
    "\n",
    "# Transformando as listas em Numpy array\n",
    "text = np.array(text_new)\n",
    "entities = np.array(entities_new)\n",
    "classes_NER = np.array(classes_NER_new) \n",
    "ENT_URI = np.array(ENT_URI_new)\n",
    "URI_Vec = np.array(URI_Vec_new)\n",
    "            \n",
    "print('Total de sentenças anotadas: ', n)\n",
    "print('N° de sentenças: ', len(text))\n",
    "print ('N° de entidades: ', len(entities))\n",
    "print('N° de classes: ', len(classes_NER))\n",
    "print('N° de entidades_ID: ', len(ENT_URI))       \n",
    "print('N° de vetores de URI: ', len(URI_Vec))       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767b6c2-03de-4ef6-b7b5-40d80604b83a",
   "metadata": {},
   "source": [
    "### Salvando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add17e53-0c52-444f-8f92-d1cda5a27f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentences.npy', 'wb') as f:\n",
    "    np.save(f, text)\n",
    "with open('entities.npy', 'wb') as f:\n",
    "    np.save(f, entities)\n",
    "with open('classes.npy', 'wb') as f:\n",
    "    np.save(f, classes_NER)\n",
    "with open('URI.npy', 'wb') as f:\n",
    "    np.save(f, ENT_URI)\n",
    "with open('URI_vectors.npy', 'wb') as f:\n",
    "    np.save(f, URI_Vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
