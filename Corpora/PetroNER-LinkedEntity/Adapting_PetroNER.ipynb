{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078fcb30-410b-4440-9ede-25b4ef2f30e9",
   "metadata": {},
   "source": [
    "### Notebook to adjust PetroNER for Entity Linking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6439c4b0-1acf-4ac2-92bd-220683de9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from conllu import parse_incr, parse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5aa8d7-a627-4fcb-843f-40df6e335af5",
   "metadata": {},
   "source": [
    "Load PetroNER (file in CONLLU format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d64c69d0-b3e2-4e57-b485-a2ac681cae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONLLU parser\n",
    "\n",
    "# Corpora treino\n",
    "PetroNER_treino = open(\"../PetroNER/petroner-Treino-uri-2022-03-07.conllu\", \"r\", encoding=\"utf-8\")\n",
    "PetroNER_treino_sentences = parse_incr(PetroNER_treino)\n",
    "\n",
    "# Corpora validação\n",
    "PetroNER_valid = open(\"../PetroNER/petroner-Validação-uri-2022-03-07.conllu\", \"r\", encoding=\"utf-8\")\n",
    "PetroNER_valid_sentences = parse_incr(PetroNER_valid)\n",
    "\n",
    "# Corpora teste\n",
    "PetroNER_teste = open(\"../PetroNER/petroner-Teste-uri-2022-03-07.conllu\", \"r\", encoding=\"utf-8\")\n",
    "PetroNER_teste_sentences = parse_incr(PetroNER_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46b866-644c-4d16-b65d-d965ed8952a0",
   "metadata": {},
   "source": [
    "### Preparing and processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9351dbe-ce9c-403b-a96f-1d6c64cacc35",
   "metadata": {},
   "source": [
    "Função que recebe o texto anotado em formato CONLLU e processa para o treinamento. Tem como saída as sentenças acrescida das tags para indicar as entidades, bem como com a entidade no início do texto; lista com as entidades (instâncias extraídas do texto); lista com as classes que as entidades pertencem; e lista com as URI referente às entidades. O texto sai com o seguinte formato:  \n",
    "\"[Nome da classe] Nome da entidade | blablabla blablabla blablabla [E] Nome da entidade [/E] blablabla blablabla.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "909bcddc-094b-4ac7-a1dd-6095e52df38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe\n",
    "def preparar_dataset(tokenlist):\n",
    "\n",
    "    #sent = TokenList([])\n",
    "    sent_orig = ''   # String para compor a sentença original\n",
    "    sents_NER = []   # Lista para armazenar as sentenças com indicação das entidades\n",
    "    NER_on = False   # Variável para indicar se está iterando por token de entidades\n",
    "    NER_tok = ''     # string para armazenar os tokens das entidades que estão sendo iteradas\n",
    "    MW_on = False    # Variável para indicar se está iterando por tolkens multiword\n",
    "    MW_tok = ''      # string para armazenar o termo multiword\n",
    "    MW_end = 0       # ID final do token multiword\n",
    "    ENT = []         # Lista para armazenar as entidades encontradas no texto\n",
    "    ENT_class = []   # Lista para armazenar as classes das entidades encontradas no texto\n",
    "    ENT_URI = []     # Lista para armazenar as URI das entidades encontradas no texto\n",
    "\n",
    "    #Iterando por todos os tokens de uma sentença\n",
    "    for tok in tokenlist:\n",
    "        # ignorando id não inteiro (tuplas), ou seja token multiword\n",
    "        if type(tok['id']) == int:\n",
    "\n",
    "            # Verifica se o token inicia uma entidade (\"B\")\n",
    "            if tok['deps'][0] == 'B':\n",
    "                \n",
    "                # Verifica se a variável NER_on está ativado (No caso de um tok \"B\" seguido de outro)\n",
    "                if NER_on == True:\n",
    "                    \n",
    "                    NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                    # Para sentença mais recente da lista sents_NER, inclui a entidade no início e o marcador [/E] no final \n",
    "                    sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                    # Incluir o NER_tok na lista ENT\n",
    "                    ENT.append(NER_tok.strip())\n",
    "\n",
    "                    NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "                NER_on = True  # Ativa a variável NER_on\n",
    "                # Acrescenta uma sentença com o marcador [E] na listas de sentenças com NER\n",
    "                sents_NER.append(sent_orig + ' [E]')\n",
    "                # Incluir classe na lista ENT_class\n",
    "                ENT_class.append(tok['deps'][2:])\n",
    "                # Incluir URI da entidade na lista ENT_URI. Caso não haja URI, incluir \"None\". \n",
    "                try:\n",
    "                    ENT_URI.append(tok['misc']['grafo'])\n",
    "                except:\n",
    "                    ENT_URI.append(None)\n",
    "\n",
    "            # Identifica o primeiro token \"O\" após uma sequência de entidades\n",
    "            if (tok['deps'][0] == 'O') & NER_on:\n",
    "                \n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "                \n",
    "            # Identifica se o último token da sequência tem o marcador \"B\" ou \"I\".    \n",
    "            if (tokenlist[-1]['id'] == tok['id']) & ((tok['deps'][0] == 'B') | (tok['deps'][0] == 'I')):\n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "            # Verifica se está iterando por uma multiword ou não\n",
    "            if not MW_on:\n",
    "\n",
    "                # Acrecenta o token à string da entidade\n",
    "                if NER_on:\n",
    "                    NER_tok = NER_tok + tok['form'] + ' '\n",
    "\n",
    "                # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                if tok['upos'] == 'PUNCT':\n",
    "                    # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                    sent_orig = sent_orig + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + tok['form']\n",
    "                else:\n",
    "                    sent_orig = sent_orig + ' ' + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + ' ' + tok['form']\n",
    "\n",
    "            else:\n",
    "                # Se o token for o último termo da multiword, desativamos a variável MW_on\n",
    "                if tok['id'] == MW_end:\n",
    "                    MW_on = False\n",
    "\n",
    "                    # Acrecenta a multiword à string da entidade\n",
    "                    if NER_on:\n",
    "                        NER_tok = NER_tok + MW_tok + ' '\n",
    "\n",
    "                    #Ao invés de incluir nas senteças o token, vamos incluir o MW_tok \n",
    "                    # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                    if tok['upos'] == 'PUNCT':\n",
    "                        # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                        sent_orig = sent_orig + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + MW_tok\n",
    "                    else:\n",
    "                        sent_orig = sent_orig + ' ' + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + ' ' + MW_tok\n",
    "\n",
    "        # Se a ID do token for referente a uma multiword, ativamos a variável MW_on, \n",
    "        # armazenamos o termo MW_tok e o valor da 'id' final\n",
    "        else:\n",
    "            MW_on = True\n",
    "            MW_tok = tok['form']\n",
    "            MW_end = tok['id'][-1]\n",
    "    \n",
    "    return(sents_NER, ENT, ENT_class, ENT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af655dc7-c5cb-44c4-81d3-e0e0b945f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_class_URI(sentences):\n",
    "\n",
    "    # Separando as listas de sentenças, entidades, classes e URI\n",
    "    text = []\n",
    "    entities = []\n",
    "    classes_NER = [] \n",
    "    ENT_URI = []\n",
    "    entities_sem_URI = []\n",
    "\n",
    "    # Iterando por todas as sentenças em formato CONLLU para preparar o dataset\n",
    "    n = 0\n",
    "    m = 0\n",
    "    \n",
    "    for tokenlist in sentences:\n",
    "        # contador de sentenças\n",
    "        n = n + 1\n",
    "        # processando cada sentenças\n",
    "        text_n, entities_n, classes_NER_n, ENT_URI_n = preparar_dataset(tokenlist)\n",
    "        # Contador de senteças com entidades\n",
    "        if len(text_n) > 0:\n",
    "            m = m + 1\n",
    "        \n",
    "        text = text + text_n\n",
    "        entities = entities + entities_n\n",
    "        classes_NER = classes_NER + classes_NER_n\n",
    "        ENT_URI = ENT_URI + ENT_URI_n\n",
    "    \n",
    "    #Verificando e Excluindo entidades sem URI\n",
    "    new_text = []\n",
    "    new_entities = []\n",
    "    new_classes_NER = [] \n",
    "    new_ENT_URI = []\n",
    "    \n",
    "    for i in range(len(ENT_URI)):\n",
    "        if ENT_URI[i] == None:\n",
    "            entities_sem_URI.append(entities[i])\n",
    "        else:    \n",
    "            new_text.append(text[i])\n",
    "            new_entities.append(entities[i])\n",
    "            new_classes_NER.append(classes_NER[i])\n",
    "            new_ENT_URI.append(ENT_URI[i])            \n",
    "            \n",
    "    print('Total de sentenças no arquivo: ', n)\n",
    "    print('N° de sentenças com entidades: ', m, 'que equivale a ', (m/n)*100, '% do total')\n",
    "    print ('N° de entidades: ', len(entities))\n",
    "    print('N° de classes: ', len(classes_NER))\n",
    "    print('Média de ', len(entities)/m, 'entidades por sentença (das sentenças que possuem entidades)')     \n",
    "    \n",
    "    print('N° de entities com URI: ', len(ENT_URI) - len(entities_sem_URI))\n",
    "    print('N° de entities sem URI: ', len(entities_sem_URI))\n",
    "    print((len(entities_sem_URI)/len(ENT_URI))*100, '% das entidades não possuem URI.')\n",
    "     \n",
    "    return (new_text, new_entities, new_classes_NER, new_ENT_URI, entities_sem_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ea44256-d583-4c9d-a950-88bbe93d1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PetroNER - Treino\n",
      "Total de sentenças no arquivo:  17987\n",
      "N° de sentenças com entidades:  6526 que equivale a  36.28175904820148 % do total\n",
      "N° de entidades:  13904\n",
      "N° de classes:  13904\n",
      "Média de  2.1305547042598834 entidades por sentença (das sentenças que possuem entidades)\n",
      "N° de entities com URI:  9642\n",
      "N° de entities sem URI:  4262\n",
      "30.653049482163407 % das entidades não possuem URI.\n",
      "\n",
      "PetroNER - Validação\n",
      "Total de sentenças no arquivo:  2467\n",
      "N° de sentenças com entidades:  892 que equivale a  36.15727604377787 % do total\n",
      "N° de entidades:  1754\n",
      "N° de classes:  1754\n",
      "Média de  1.9663677130044843 entidades por sentença (das sentenças que possuem entidades)\n",
      "N° de entities com URI:  1344\n",
      "N° de entities sem URI:  410\n",
      "23.3751425313569 % das entidades não possuem URI.\n",
      "\n",
      "PetroNER - Teste\n",
      "Total de sentenças no arquivo:  3581\n",
      "N° de sentenças com entidades:  1339 que equivale a  37.39179000279252 % do total\n",
      "N° de entidades:  3091\n",
      "N° de classes:  3091\n",
      "Média de  2.308439133681852 entidades por sentença (das sentenças que possuem entidades)\n",
      "N° de entities com URI:  2116\n",
      "N° de entities sem URI:  975\n",
      "31.54318990617923 % das entidades não possuem URI.\n"
     ]
    }
   ],
   "source": [
    "print('\\nPetroNER - Treino')\n",
    "(treino_text,\n",
    " treino_entities,\n",
    " treino_classes_NER,\n",
    " treino_ENT_URI,\n",
    " treino_entities_sem_URI) = ent_class_URI(PetroNER_treino_sentences)\n",
    "\n",
    "print('\\nPetroNER - Validação')\n",
    "(valid_text,\n",
    " valid_entities, \n",
    " valid_classes_NER,\n",
    " valid_ENT_URI,\n",
    " valid_entities_sem_URI) = ent_class_URI(PetroNER_valid_sentences)\n",
    "\n",
    "print('\\nPetroNER - Teste')\n",
    "(teste_text, \n",
    " teste_entities,\n",
    " teste_classes_NER,\n",
    " teste_ENT_URI,\n",
    " teste_entities_sem_URI) = ent_class_URI(PetroNER_teste_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6767b6c2-03de-4ef6-b7b5-40d80604b83a",
   "metadata": {},
   "source": [
    "### Salvando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "add17e53-0c52-444f-8f92-d1cda5a27f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "\n",
    "with open('treino - sentences.npy', 'wb') as f:\n",
    "    np.save(f, np.array(treino_text))\n",
    "with open('treino - entities.npy', 'wb') as f:\n",
    "    np.save(f, np.array(treino_entities))\n",
    "with open('treino - classes.npy', 'wb') as f:\n",
    "    np.save(f, np.array(treino_classes_NER))\n",
    "with open('treino - URI.npy', 'wb') as f:\n",
    "    np.save(f, np.array(treino_ENT_URI))\n",
    "    \n",
    "#Validação\n",
    "\n",
    "with open('valid - sentences.npy', 'wb') as f:\n",
    "    np.save(f, np.array(valid_text))\n",
    "with open('valid - entities.npy', 'wb') as f:\n",
    "    np.save(f, np.array(valid_entities))\n",
    "with open('valid - classes.npy', 'wb') as f:\n",
    "    np.save(f, np.array(valid_classes_NER))\n",
    "with open('valid - URI.npy', 'wb') as f:\n",
    "    np.save(f, np.array(valid_ENT_URI))\n",
    "    \n",
    "#Teste\n",
    "\n",
    "with open('teste - sentences.npy', 'wb') as f:\n",
    "    np.save(f, np.array(teste_text))\n",
    "with open('teste - entities.npy', 'wb') as f:\n",
    "    np.save(f, np.array(teste_entities))\n",
    "with open('teste - classes.npy', 'wb') as f:\n",
    "    np.save(f, np.array(teste_classes_NER))\n",
    "with open('teste - URI.npy', 'wb') as f:\n",
    "    np.save(f, np.array(teste_ENT_URI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dea7f-4f08-4afc-b323-efef8bf6079d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
