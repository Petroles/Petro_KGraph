{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078fcb30-410b-4440-9ede-25b4ef2f30e9",
   "metadata": {},
   "source": [
    "### Notebook to adjust PetroNER for Entity Linking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6439c4b0-1acf-4ac2-92bd-220683de9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "import gensim\n",
    "from conllu import parse_incr, parse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250b4a1-35c0-4083-9eb8-938fb0bedddd",
   "metadata": {},
   "source": [
    "Load ontology and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "03dae845-46ce-4da9-a742-75da0848e08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OntoGeoLógica populada (OntoGeoLogicaPopulada.owl)\n",
    "onto = get_ontology(\"../../KnowledgeGraph/OntoGeoLogicaPovoadaInstanciasRelacoes.owl\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d13e485f-2baa-41a1-b9ed-124d3911601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo OWL2Vec - \n",
    "PetroOntoVec = gensim.models.Word2Vec.load(\"../../Embeddings/PetroOntoVec/PetroOntoVec_simples/outputontology.embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5aa8d7-a627-4fcb-843f-40df6e335af5",
   "metadata": {},
   "source": [
    "Load PetroNER (file in CONLLU format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d64c69d0-b3e2-4e57-b485-a2ac681cae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONLLU parser\n",
    "boleltins = open(\"../PetroNER/petroner-2022-12-19.conllu\", \"r\", encoding=\"utf-8\")\n",
    "sentences = parse_incr(boleltins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46b866-644c-4d16-b65d-d965ed8952a0",
   "metadata": {},
   "source": [
    "### Preparing and processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9351dbe-ce9c-403b-a96f-1d6c64cacc35",
   "metadata": {},
   "source": [
    "Função que recebe o texto anotado em formato CONLLU e processa para o treinamento. Tem como saída as sentenças acrescida das tags para indicar as entidades, bem como com a entidade no início do texto; lista com as entidades (instâncias extraídas do texto); e lista com as classes que as entidades pertencem. O texto sai com o seguinte formato:  \n",
    "\"[Nome da classe] Nome da entidade | blablabla blablabla blablabla [E] Nome da entidade [/E] blablabla blablabla.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "909bcddc-094b-4ac7-a1dd-6095e52df38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe\n",
    "def preparar_dataset(tokenlist):\n",
    "\n",
    "    #sent = TokenList([])\n",
    "    sent_orig = ''   # String para compor a sentença original\n",
    "    sents_NER = []   # Lista para armazenar as sentenças com indicação das entidades\n",
    "    NER_on = False   # Variável para indicar se está iterando por token de entidades\n",
    "    NER_tok = ''     # string para armazenar os tokens das entidades que estão sendo iteradas\n",
    "    MW_on = False    # Variável para indicar se está iterando por tolkens multiword\n",
    "    MW_tok = ''      # string para armazenar o termo multiword\n",
    "    MW_end = 0       # ID final do token multiword\n",
    "    ENT = []\n",
    "    ENT_class = []\n",
    "    ENT_ID = []\n",
    "\n",
    "    for tok in tokenlist:\n",
    "        # ignorando id não inteiro (tuplas), ou seja token multiword\n",
    "        if type(tok['id']) == int:\n",
    "\n",
    "            # Verifica se o token inicia uma entidade (\"B\")\n",
    "            if tok['deps'][0] == 'B':\n",
    "                \n",
    "                # Verifica se a variável NER_on está ativado (No caso de um tok \"B\" seguido de outro)\n",
    "                if NER_on == True:\n",
    "                    \n",
    "                    NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                    # Para sentença mais recente da lista sents_NER, inclui a entidade no início e o marcador [/E] no final \n",
    "                    sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                    # Incluir o NER_tok na lista ENT\n",
    "                    ENT.append(NER_tok.strip())\n",
    "\n",
    "                    NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "                NER_on = True  # Ativa a variável NER_on\n",
    "                # Acrescenta uma sentença com o marcador [E] na listas de sentenças com NER\n",
    "                sents_NER.append(sent_orig + ' [E]')\n",
    "                # Incluir classe na lista ENT_class\n",
    "                ENT_class.append(tok['deps'][2:])\n",
    "                try:\n",
    "                    ENT_ID.append(tok['misc']['grafo'])\n",
    "                except:\n",
    "                    ENT_ID.append(None)\n",
    "\n",
    "            # Identifica o primeiro token \"O\" após uma sequência de entidades\n",
    "            if (tok['deps'][0] == 'O') & NER_on:\n",
    "                \n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "                \n",
    "            # Identifica se o último token da sequência tem o marcador \"B\" ou \"I\".    \n",
    "            if (tokenlist[-1]['id'] == tok['id']) & ((tok['deps'][0] == 'B') | (tok['deps'][0] == 'I')):\n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "            # Verifica se está iterando por uma multiword ou não\n",
    "            if not MW_on:\n",
    "\n",
    "                # Acrecenta o token à string da entidade\n",
    "                if NER_on:\n",
    "                    NER_tok = NER_tok + tok['form'] + ' '\n",
    "\n",
    "                # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                if tok['upos'] == 'PUNCT':\n",
    "                    # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                    sent_orig = sent_orig + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + tok['form']\n",
    "                else:\n",
    "                    sent_orig = sent_orig + ' ' + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + ' ' + tok['form']\n",
    "\n",
    "            else:\n",
    "                # Se o token for o último termo da multiword, desativamos a variável MW_on\n",
    "                if tok['id'] == MW_end:\n",
    "                    MW_on = False\n",
    "\n",
    "                    # Acrecenta a multiword à string da entidade\n",
    "                    if NER_on:\n",
    "                        NER_tok = NER_tok + MW_tok + ' '\n",
    "\n",
    "                    #Ao invés de incluir nas senteças o token, vamos incluir o MW_tok \n",
    "                    # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                    if tok['upos'] == 'PUNCT':\n",
    "                        # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                        sent_orig = sent_orig + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + MW_tok\n",
    "                    else:\n",
    "                        sent_orig = sent_orig + ' ' + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + ' ' + MW_tok\n",
    "\n",
    "        # Se a ID do token for referente a uma multiword, ativamos a variável MW_on, \n",
    "        # armazenamos o termo MW_tok e o valor da 'id' final\n",
    "        else:\n",
    "            MW_on = True\n",
    "            MW_tok = tok['form']\n",
    "            MW_end = tok['id'][-1]\n",
    "    \n",
    "    return(sents_NER, ENT, ENT_class, ENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4a7d00c8-bc17-4215-984a-aa04cd616a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor tokenlist in sentences:\\n    for tok in tokenlist:\\n        try:\\n            if tok['deps'][0] == 'B':\\n                #print(tok['misc'])\\n                print(tok['misc']['grafo'])\\n        except:\\n            pass\\n    break  \\n    \\n\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for tokenlist in sentences:\n",
    "    for tok in tokenlist:\n",
    "        try:\n",
    "            if tok['deps'][0] == 'B':\n",
    "                #print(tok['misc'])\n",
    "                print(tok['misc']['grafo'])\n",
    "        except:\n",
    "            pass\n",
    "    break  \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "af3ccd53-2acc-4e58-a95e-b74bd6051dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de sentenças anotadas:  24035\n",
      "N° de sentenças:  18820\n",
      "N° de entidades:  18820\n",
      "N° de classes:  18820\n",
      "N° de classes:  18820\n"
     ]
    }
   ],
   "source": [
    "# Separando as listas de sentenças, entidades e classes\n",
    "text = []\n",
    "entities = []\n",
    "classes_NER = [] \n",
    "ENT_ID = []\n",
    "\n",
    "# Iterando por todas as sentenças em formato CONLLU para preparar o dataset\n",
    "n = 0\n",
    "for tokenlist in sentences:\n",
    "    n = n + 1\n",
    "\n",
    "    text_n, entities_n, classes_NER_n, ENT_ID_n = preparar_dataset(tokenlist)\n",
    "    \n",
    "    text = text + text_n\n",
    "    entities = entities + entities_n\n",
    "    classes_NER = classes_NER + classes_NER_n\n",
    "    ENT_ID = ENT_ID + ENT_ID_n\n",
    "    \n",
    "print('Total de sentenças anotadas: ', n)\n",
    "print('N° de sentenças: ', len(text))\n",
    "print ('N° de entidades: ', len(entities))\n",
    "print('N° de classes: ', len(classes_NER))\n",
    "print('N° de classes: ', len(ENT_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "3b809a0a-d39e-4378-8657-857248c8556b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entidades sem ID:  9172\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in ENT_ID:\n",
    "    if i == None:\n",
    "        count = count + 1\n",
    "        \n",
    "print('Número de entidades sem ID: ', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c3eea-0b7a-4061-828c-1fa5851d604b",
   "metadata": {},
   "source": [
    "### Buscando vetores do PetroOntoVec para cada ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "11d9d43b-7113-429e-b5b2-7ee1f9d51f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#gipsita\n",
      "#gipsita\n",
      "#gipsita\n",
      "#grupo_05\n",
      "#carbonatos\n",
      "#dry_hole\n",
      "#grupo_05\n",
      "#carbonatos\n",
      "#grupo_05\n",
      "#grupo_05\n",
      "#carbonatos\n",
      "#carbonatos\n",
      "#carbonatos\n",
      "#carbonatos\n",
      "#grupo_05\n",
      "#gipsita\n",
      "#grupo_05\n",
      "#dry_hole\n",
      "#grupo_05\n",
      "#grupo_05\n",
      "#grupo_05\n",
      "#grupo_05\n",
      "#grupo_05\n",
      "#grupo_05\n",
      "#carbonatos\n",
      "#carbonatos\n",
      "#carbonatos\n",
      "#carbonatos\n",
      "#grupo_05\n",
      "#grupo_05\n",
      "#dry_hole\n",
      "#dry_hole\n",
      "Total de sentenças anotadas:  18820\n",
      "N° de sentenças:  9844\n",
      "N° de entidades:  9844\n",
      "N° de classes:  9844\n",
      "N° de entidades_ID:  9844\n",
      "N° de vetores de URI:  9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "text_new = []\n",
    "entities_new = []\n",
    "classes_NER_new = [] \n",
    "ENT_ID_new = []\n",
    "URI_Vec_new = []\n",
    "\n",
    "n = 0 \n",
    "#m = 0\n",
    "#Iterando por todas as sentenças, desconsiderando aquelas cujas entidades não possuem ENT_ID\n",
    "for i in range(len(text)):\n",
    "    n = n + 1\n",
    "    if ENT_ID[i] != None:\n",
    "        # Quebrando as entidades que possuem mais de um ENT_ID (ex: \"#Aptian,#Miocene\" e \"#Cenozoic,#Mesozoic\")\n",
    "        ENT_ID_n = ENT_ID[i].split(',#')\n",
    "        \n",
    "        # Iterando pelas ENT_ID após serem quebradas e acrescentando '#\" naquelas que perderam na operação de split \n",
    "        for ent in ENT_ID_n:\n",
    "            if ent[0] != '#':\n",
    "                ent = '#' + ent\n",
    "            try:\n",
    "                #Acrescentar o ID da entidade e o vetor da URI\n",
    "                URI_Vec_new.append(PetroOntoVec['http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2' + ent])\n",
    "                ENT_ID_new.append(ent)\n",
    "               \n",
    "                # O texto, a entidade no texto e a classe são repetidas\n",
    "                text_new.append(text[i])\n",
    "                entities_new.append(entities[i])\n",
    "                classes_NER_new.append(classes_NER[i])\n",
    "            except:\n",
    "                print(ent)\n",
    "            \n",
    "text = np.array(text_new)\n",
    "entities = np.array(entities_new)\n",
    "classes_NER = np.array(classes_NER_new) \n",
    "ENT_ID = np.array(ENT_ID_new)\n",
    "URI_Vec = np.array(URI_Vec_new)\n",
    "            \n",
    "print('Total de sentenças anotadas: ', n)\n",
    "print('N° de sentenças: ', len(text))\n",
    "print ('N° de entidades: ', len(entities))\n",
    "print('N° de classes: ', len(classes_NER))\n",
    "print('N° de entidades_ID: ', len(ENT_ID))       \n",
    "print('N° de vetores de URI: ', len(URI_Vec))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c0ee47bc-81ad-4f5e-a5da-352c5139889e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#LowerCretaceous', '#BASE_CD_BACIA_270', '#Carboniferous',\n",
       "       '#BASE_CD_BACIA_030', '#CAMP_CD_CAMPO_0760', '#BASE_CD_BACIA_281',\n",
       "       '#Mesozoic', '#BASE_CD_BACIA_100',\n",
       "       '#TEFR_CD_TIPO_EST_FISICA_ROCHA_036',\n",
       "       '#TEFR_CD_TIPO_EST_FISICA_ROCHA_036'], dtype='<U34')"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ENT_ID[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1b549d90-2fac-45fb-82dd-286647a2198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.6703877 ,  0.265335  ,  0.95278156,  0.89755875,  0.2324965 ,\n",
       "       -0.0926315 , -0.4794778 , -0.19787806, -0.5810278 , -0.31740925,\n",
       "        0.20098737, -0.36909622, -0.62432104, -0.35961992, -0.5799979 ,\n",
       "       -1.1427058 , -2.135309  ,  0.8737656 ,  0.73145604, -0.5567418 ,\n",
       "       -0.9594028 , -1.4623563 ,  0.40491855,  1.8565482 , -0.111449  ,\n",
       "        0.29665458, -1.8804556 , -0.83291215, -1.0132178 ,  0.15205827,\n",
       "       -1.0875425 , -0.5876696 ,  0.50690794, -0.35811982, -1.1714823 ,\n",
       "       -0.78757334, -0.6718937 ,  0.28364375, -0.767629  ,  1.32649   ,\n",
       "       -1.0079952 ,  0.6938932 , -0.07394186,  0.12490686, -1.1915737 ,\n",
       "       -0.27666104, -0.06619169, -0.74382967, -1.0040956 , -1.2803016 ,\n",
       "        0.13112156,  0.95597464,  0.38763887, -0.30659407,  0.12257597,\n",
       "       -0.3563015 ,  1.300516  , -0.14993899,  0.16064867, -0.51136756,\n",
       "        1.2480568 ,  0.9804533 , -0.02366812, -0.85186   , -0.38977754,\n",
       "        0.5635437 ,  1.5994214 ,  0.5695297 ,  0.82635206, -2.0595148 ,\n",
       "       -0.42740917,  0.7954938 , -0.2172601 , -0.23373005,  0.13165176,\n",
       "       -0.08711659,  0.24395436,  0.4820344 ,  0.26026094, -0.66965806,\n",
       "       -0.21266258,  0.3407575 ,  0.5138505 ,  0.4083621 , -0.17023143,\n",
       "       -0.45432252, -0.23096816, -1.3186911 , -0.38996342, -0.4482927 ,\n",
       "        0.4489038 ,  0.27280316,  0.1270219 ,  1.08464   ,  0.46138585,\n",
       "        0.52049434, -0.92882323,  0.8341284 ,  0.09670306, -0.5711604 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PetroOntoVec['http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2' + '#LowerCretaceous']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
