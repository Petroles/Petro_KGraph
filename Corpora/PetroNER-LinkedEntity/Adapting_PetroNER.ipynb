{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "078fcb30-410b-4440-9ede-25b4ef2f30e9",
   "metadata": {},
   "source": [
    "### Notebook to adjust PetroNER for Entity Linking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6439c4b0-1acf-4ac2-92bd-220683de9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "import gensim\n",
    "from conllu import parse_incr, parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250b4a1-35c0-4083-9eb8-938fb0bedddd",
   "metadata": {},
   "source": [
    "Load ontology and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03dae845-46ce-4da9-a742-75da0848e08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#has_beginning\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#has_end\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_contains\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_during\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_in\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_finished_by\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_finishes\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_started_by\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#interval_starts\n",
      "\n",
      "* Owlready2 * Warning: ignoring cyclic subclass of/subproperty of, involving:\n",
      "  http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#temporal_reference_system_used\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OntoGeoLógica populada (OntoGeoLogicaPopulada.owl)\n",
    "onto = get_ontology(\"../../KnowledgeGraph/OntoGeoLogicaPovoadaInstanciasRelacoes.owl\")\n",
    "onto.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e485f-2baa-41a1-b9ed-124d3911601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo OWL2Vec - \n",
    "model_owl2v = gensim.models.Word2Vec.load(\"../../Embeddings/PetroOntoVec/PetroOntoVec_simples/outputontology.embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5aa8d7-a627-4fcb-843f-40df6e335af5",
   "metadata": {},
   "source": [
    "Load PetroNER (file in CONLLU format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d64c69d0-b3e2-4e57-b485-a2ac681cae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONLLU parser\n",
    "boleltins = open(\"../PetroNER/petroner-2022-12-19.conllu\", \"r\", encoding=\"utf-8\")\n",
    "sentences = parse_incr(boleltins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46b866-644c-4d16-b65d-d965ed8952a0",
   "metadata": {},
   "source": [
    "### Preparing and processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9351dbe-ce9c-403b-a96f-1d6c64cacc35",
   "metadata": {},
   "source": [
    "Função que recebe o texto anotado em formato CONLLU e processa para o treinamento. Tem como saída as sentenças acrescida das tags para indicar as entidades, bem como com a entidade no início do texto; lista com as entidades (instâncias extraídas do texto); e lista com as classes que as entidades pertencem. O texto sai com o seguinte formato:  \n",
    "\"[Nome da classe] Nome da entidade | blablabla blablabla blablabla [E] Nome da entidade [/E] blablabla blablabla.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "909bcddc-094b-4ac7-a1dd-6095e52df38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe\n",
    "def preparar_dataset(tokenlist):\n",
    "\n",
    "    #sent = TokenList([])\n",
    "    sent_orig = ''   # String para compor a sentença original\n",
    "    sents_NER = []   # Lista para armazenar as sentenças com indicação das entidades\n",
    "    NER_on = False   # Variável para indicar se está iterando por token de entidades\n",
    "    NER_tok = ''     # string para armazenar os tokens das entidades que estão sendo iteradas\n",
    "    MW_on = False    # Variável para indicar se está iterando por tolkens multiword\n",
    "    MW_tok = ''      # string para armazenar o termo multiword\n",
    "    MW_end = 0       # ID final do token multiword\n",
    "    ENT = []\n",
    "    ENT_class = []\n",
    "\n",
    "    for tok in tokenlist:\n",
    "        # ignorando id não inteiro (tuplas), ou seja token multiword\n",
    "        if type(tok['id']) == int:\n",
    "\n",
    "            # Verifica se o token inicia uma entidade (\"B\")\n",
    "            if tok['deps'][0] == 'B':\n",
    "                \n",
    "                # Verifica se a variável NER_on está ativado (No caso de um tok \"B\" seguido de outro)\n",
    "                if NER_on == True:\n",
    "                    \n",
    "                    NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                    # Para sentença mais recente da lista sents_NER, inclui a entidade no início e o marcador [/E] no final \n",
    "                    sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                    # Incluir o NER_tok na lista ENT\n",
    "                    ENT.append(NER_tok.strip())\n",
    "\n",
    "                    NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "                NER_on = True  # Ativa a variável NER_on\n",
    "                # Acrescenta uma sentença com o marcador [E] na listas de sentenças com NER\n",
    "                sents_NER.append(sent_orig + ' [E]')\n",
    "                # Incluir classe na lista ENT_class\n",
    "                ENT_class.append(tok['deps'][2:])\n",
    "\n",
    "            # Identifica o primeiro token \"O\" após uma sequência de entidades\n",
    "            if (tok['deps'][0] == 'O') & NER_on:\n",
    "                \n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "                \n",
    "            # Identifica se o último token da sequência tem o marcador \"B\" ou \"I\".    \n",
    "            if (tokenlist[-1]['id'] == tok['id']) & ((tok['deps'][0] == 'B') | (tok['deps'][0] == 'I')):\n",
    "                NER_on = False  # Desativa a variável NER_on\n",
    "\n",
    "                # Para sentença mais recente da lista sents_NER, \n",
    "                # inclui a classe e a entidade no início e o marcador [/E] no final \n",
    "                sents_NER[-1] = '[' + ENT_class[-1] + '] ' + NER_tok + '| ' + sents_NER[-1].strip() + ' [/E]'\n",
    "\n",
    "                # Incluir o NER_tok na lista ENT\n",
    "                ENT.append(NER_tok.strip())\n",
    "\n",
    "                NER_tok = '' # Apaga a string NER_tok\n",
    "\n",
    "            # Verifica se está iterando por uma multiword ou não\n",
    "            if not MW_on:\n",
    "\n",
    "                # Acrecenta o token à string da entidade\n",
    "                if NER_on:\n",
    "                    NER_tok = NER_tok + tok['form'] + ' '\n",
    "\n",
    "                # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                if tok['upos'] == 'PUNCT':\n",
    "                    # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                    sent_orig = sent_orig + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + tok['form']\n",
    "                else:\n",
    "                    sent_orig = sent_orig + ' ' + tok['form']\n",
    "                    for i in range(len(sents_NER)):\n",
    "                        sents_NER[i] = sents_NER[i] + ' ' + tok['form']\n",
    "\n",
    "            else:\n",
    "                # Se o token for o último termo da multiword, desativamos a variável MW_on\n",
    "                if tok['id'] == MW_end:\n",
    "                    MW_on = False\n",
    "\n",
    "                    # Acrecenta a multiword à string da entidade\n",
    "                    if NER_on:\n",
    "                        NER_tok = NER_tok + MW_tok + ' '\n",
    "\n",
    "                    #Ao invés de incluir nas senteças o token, vamos incluir o MW_tok \n",
    "                    # Se o token for uma pontuação, não inclui espaço entre o token anterior \n",
    "                    if tok['upos'] == 'PUNCT':\n",
    "                        # O token é incluído na senteça original e em todas as sentenças da lista sents_NER\n",
    "                        sent_orig = sent_orig + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + MW_tok\n",
    "                    else:\n",
    "                        sent_orig = sent_orig + ' ' + MW_tok\n",
    "                        for i in range(len(sents_NER)):\n",
    "                            sents_NER[i] = sents_NER[i] + ' ' + MW_tok\n",
    "\n",
    "        # Se a ID do token for referente a uma multiword, ativamos a variável MW_on, \n",
    "        # armazenamos o termo MW_tok e o valor da 'id' final\n",
    "        else:\n",
    "            MW_on = True\n",
    "            MW_tok = tok['form']\n",
    "            MW_end = tok['id'][-1]\n",
    "    \n",
    "    return(sents_NER, ENT, ENT_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af3ccd53-2acc-4e58-a95e-b74bd6051dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenList<O, Boletim, tem, servido, como, um, instrumento, de, divulgação, de, novas, idéias, e, conceitos, para, profissionais, que, atuam, em, mais, de, 600, instituições, nacionais, e, internacionais, ,, contribuindo, para, a, expansão, do, de, o, conhecimento, das, de, as, bacias, sedimentares, brasileiras, ., ., metadata={text: \"O Boletim tem servido como um instrumento de divulgação de novas idéias e conceitos para profissionais que atuam em mais de 600 instituições nacionais e internacionais, contribuindo para a expansão do conhecimento das bacias sedimentares brasileiras..\", sent_id: \"boletins-000001-28\"}>\n",
      "TokenList<Com, a, nova, política, do, de, o, setor, petróleo, ,, a, expectativa, é, que, o, Boletim, passe, a, contar, com, a, contribuição, de, geocientistas, de, outras, companhias, que, venham, a, atuar, no, em, o, território, brasileiro, ., ., metadata={text: \"Com a nova política do setor petróleo, a expectativa é que o Boletim passe a contar com a contribuição de geocientistas de outras companhias que venham a atuar no território brasileiro..\", sent_id: \"boletins-000001-29\"}>\n",
      "Total de sentenças anotadas:  2\n",
      "N° de sentenças:  1\n",
      "N° de entidades:  1\n",
      "N° de classes:  1\n"
     ]
    }
   ],
   "source": [
    "# Separando as listas de sentenças, entidades e classes\n",
    "text = []\n",
    "entities = []\n",
    "classes_NER = [] \n",
    "\n",
    "# Iterando por todas as sentenças em formato CONLLU para preparar o dataset\n",
    "n = 0\n",
    "for tokenlist in sentences:\n",
    "    print(tokenlist)\n",
    "    n = n + 1\n",
    "\n",
    "    text_n, entities_n, classes_NER_n = preparar_dataset(tokenlist)\n",
    "    \n",
    "    text = text + text_n\n",
    "    entities = entities + entities_n\n",
    "    classes_NER = classes_NER + classes_NER_n\n",
    "    if n > 1:\n",
    "        break\n",
    "    \n",
    "print('Total de sentenças anotadas: ', n)\n",
    "print('N° de sentenças: ', len(text))\n",
    "print ('N° de entidades: ', len(entities))\n",
    "print('N° de classes: ', len(classes_NER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b809a0a-d39e-4378-8657-857248c8556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[BACIA] bacias | O Boletim tem servido como um instrumento de divulgação de novas idéias e conceitos para profissionais que atuam em mais de 600 instituições nacionais e internacionais, contribuindo para a expansão do conhecimento das [E] bacias [/E] sedimentares brasileiras..']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
